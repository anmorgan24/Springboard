{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636e1c9a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "070c5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe REGULAR\n",
    "#parse datetime column\n",
    "df=pd.read_csv('COVID19_modeling.csv', parse_dates=[0])\n",
    "df.set_index('date', inplace= True)\n",
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69223781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe OHE\n",
    "#parse datetime column\n",
    "df_ohe = pd.read_csv('ohe_data.csv', parse_dates=['date'])\n",
    "df_ohe.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_ohe.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1d07b",
   "metadata": {},
   "source": [
    "## Using the mean as a baseline prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe3858",
   "metadata": {},
   "source": [
    "Previously, we determined the R2 score of using the mean to predict COVID19 cases for each individual state. Let's do the same thing now that we have all the states in one DataFrame, so that we will have a baseline \"dummy\" model to compare our future optimized model to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23135da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score of using the mean to predict COVID19 cases in our states is: -0.0019588491283020204\n"
     ]
    }
   ],
   "source": [
    "# Create features\n",
    "X, y = df_ohe.drop(columns=['Conf_Cases', 'new_case_percent_pop*']), df_ohe['new_case_percent_pop*']\n",
    "# Make test and train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "dummy_mean = DummyRegressor()\n",
    "# \"Train\" dummy regressor\n",
    "dummy_mean.fit(X_train, y_train)\n",
    "# Get R2 score\n",
    "score_dummy = dummy_mean.score(X_test, y_test)\n",
    "print(\"The R2 score of using the mean to predict COVID19 cases in our states is:\", score_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a342e",
   "metadata": {},
   "source": [
    "## Tuning the top performing models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50fec1",
   "metadata": {},
   "source": [
    "In the pre-processing step, we determined (with the help of Pycaret) that our top performing models were **CatBoost Regressor**, **Random Forest Regressor**, and **Gradient Boosting Regressor**. Let's now fine tune the hyperparameters of each of these models, in preparation for feeding them into the pipeline of the Voting Regressor. \n",
    "\n",
    "**NOTE TO SELF: Determine hyperparameters for each model, but pass unfitted (tuned) models to the VotingRegressor**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360dc274",
   "metadata": {},
   "source": [
    "#### CatBoost Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ed1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a4a1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07bf4188",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor\n",
    "With a few exceptions, a RandomForestClassifier has all the hyperparameters of a DecisionTreeClassifier (to control how trees are grown), plus all the hyperparameters of a BaggingClassifier to control the ensemble itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfcc958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = df_ohe.drop(columns=['Conf_Cases', 'new_case_percent_pop*']), df_ohe['new_case_percent_pop*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d427462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6fc003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Define parameters to search for GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "              'max_depth': [3, 5, 7, 9],\n",
    "              }\n",
    "# Instantiate RandomForestClassifier\n",
    "rf = RandomForestRegressor()\n",
    "cv_rf = GridSearchCV(rf, param_grid, cv = 10)\n",
    "cv_rf_fit = cv_rf.fit(X_train, y_train)\n",
    "\n",
    "#Print the best parameter\n",
    "print(cv_rf_fit.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00722e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal max_depth for the RandomForestRegressor is: 9\n",
      "The optimal n_estimators for the RandomForestRegressor is: 400\n"
     ]
    }
   ],
   "source": [
    "print('The optimal max_depth for the RandomForestRegressor is: {}'.format(cv_rf_fit.best_params_['max_depth']))\n",
    "print('The optimal n_estimators for the RandomForestRegressor is: {}'.format(cv_rf_fit.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6607b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "rf = RandomForestRegressor(max_depth = 9, n_estimators = 400)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6585d28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for the RandomForestRegressor is 0.8327308664092816\n"
     ]
    }
   ],
   "source": [
    "# Determine R2 score\n",
    "print('The R2 score for the RandomForestRegressor is {}'.format(r2_score(y_test, rf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81898a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c3892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11035b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b741e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
