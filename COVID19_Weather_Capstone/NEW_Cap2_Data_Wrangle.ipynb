{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d1bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa13e8",
   "metadata": {},
   "source": [
    "## Weather dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a342dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token= 'kwWGVZlNuVYFUheaHYiAxIsIRYCDEzvl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39b6129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 2020\n",
      "working on year 2021\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#create empty lists to store CT data\n",
    "ct_dates_temp = []\n",
    "ct_dates_prcp = []\n",
    "ct_temps = []\n",
    "ct_prcp = []\n",
    "\n",
    "#for each year from 2020-2021 ...\n",
    "for year in range(2020, 2022):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=TAVG&datatypeid=PRCP&limit=1000&stationid=GHCND:USW00014740&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are average temperature readings\n",
    "    ct_avg_temps = [item for item in d['results'] if item['datatype']=='TAVG']\n",
    "    #get the date field from all average temperature readings\n",
    "    ct_dates_temp += [item['date'] for item in ct_avg_temps]\n",
    "    #get the actual average temperature from all average temperature readings\n",
    "    ct_temps += [item['value'] for item in ct_avg_temps]\n",
    "    #get all items in the response which are average precipitation readings\n",
    "    ct_avg_prcp = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average precipitation readings\n",
    "    ct_dates_prcp += [item['date'] for item in ct_avg_prcp]\n",
    "    #get the actual average precipitation from all average precipitation readings\n",
    "    ct_prcp += [item['value'] for item in ct_avg_prcp]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dfa0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 2020\n",
      "working on year 2021\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Create empty lists to store ME data\n",
    "#Note: avg temp not available for Maine, so will use temp min and temp max instead\n",
    "me_dates_temp_min = []\n",
    "me_dates_temp_max = []\n",
    "me_dates_prcp = []\n",
    "me_temps_min = []\n",
    "me_temps_max = []\n",
    "me_prcp = []\n",
    "\n",
    "#for each year from 2020-2021 ...\n",
    "for year in range(2020, 2022):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&&datatypeid=TMAX&datatypeid=TMIN&limit=1000&stationid=GHCND:USW00094626&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are MIN temp readings\n",
    "    me_min_temps_item = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "    #get the date field from all MIN temperature readings\n",
    "    me_dates_temp_min += [item['date'] for item in me_min_temps_item]\n",
    "    #get the actual min temperature from all MIN temperature readings\n",
    "    me_temps_min += [item['value'] for item in me_min_temps_item]\n",
    "    #get all items in the response which are MAX temperature readings\n",
    "    me_max_temp_item = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "    #get the date field from all MAX temperature readings\n",
    "    me_dates_temp_max += [item['date'] for item in me_max_temp_item]\n",
    "    #get the actual average temperature from all MAX temperature readings\n",
    "    me_temps_max += [item['value'] for item in me_max_temp_item]\n",
    "    #get all items in the response which are average PRCP readings\n",
    "    me_avg_prcp = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average PRCP readings\n",
    "    me_dates_prcp += [item['date'] for item in me_avg_prcp]\n",
    "    #get the actual average precipitation from all average PRCP readings\n",
    "    me_prcp += [item['value'] for item in me_avg_prcp]\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbc0c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on year 2020\n",
      "working on year 2021\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Create empty lists to store VT data\n",
    "#Note: avg temp not available for Vermont, so will use temp min and temp max instead\n",
    "vt_dates_temp_min = []\n",
    "vt_dates_temp_max = []\n",
    "vt_dates_prcp = []\n",
    "vt_temps_min = []\n",
    "vt_temps_max = []\n",
    "vt_prcp = []\n",
    "\n",
    "#for each year from 2020-2021 ...\n",
    "for year in range(2020, 2022):\n",
    "    year = str(year)\n",
    "    print('working on year '+year)\n",
    "    \n",
    "    #make the api call\n",
    "    r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&&datatypeid=TMAX&datatypeid=TMIN&limit=1000&stationid=GHCND:USW00014742&startdate='+year+'-01-01&enddate='+year+'-12-31', headers={'token':Token})\n",
    "    #load the api response as a json\n",
    "    d = json.loads(r.text)\n",
    "    #get all items in the response which are MIN temp readings\n",
    "    vt_min_temps_item = [item for item in d['results'] if item['datatype']=='TMIN']\n",
    "    #get the date field from all MIN temperature readings\n",
    "    vt_dates_temp_min += [item['date'] for item in vt_min_temps_item]\n",
    "    #get the actual min temperature from all MIN temperature readings\n",
    "    vt_temps_min += [item['value'] for item in vt_min_temps_item]\n",
    "    #get all items in the response which are MAX temperature readings\n",
    "    vt_max_temp_item = [item for item in d['results'] if item['datatype']=='TMAX']\n",
    "    #get the date field from all MAX temperature readings\n",
    "    vt_dates_temp_max += [item['date'] for item in vt_max_temp_item]\n",
    "    #get the actual average temperature from all MAX temperature readings\n",
    "    vt_temps_max += [item['value'] for item in vt_max_temp_item]\n",
    "    #get all items in the response which are average PRCP readings\n",
    "    vt_avg_prcp = [item for item in d['results'] if item['datatype']=='PRCP']\n",
    "    #get the date field from all average PRCP readings\n",
    "    vt_dates_prcp += [item['date'] for item in vt_avg_prcp]\n",
    "    #get the actual average precipitation from all average PRCP readings\n",
    "    vt_prcp += [item['value'] for item in vt_avg_prcp]\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&&datatypeid=TMAX&datatypeid=TMIN&limit=1000&stationid=GHCND:USC00170814&startdate=2020-09-07&enddate=2020-09-07', headers={'token':Token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee3053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf82e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&datatypeid=PRCP&&datatypeid=TMAX&datatypeid=TMIN&limit=1000&stationid=GHCND:USC00170814&startdate=2021-09-23&enddate=2021-09-23', headers={'token':Token})\n",
    "d = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e1d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b2fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad64c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f12f4d9",
   "metadata": {},
   "source": [
    "### Put data into dataframes by state:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00afb01",
   "metadata": {},
   "source": [
    "#### Connecticut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip dates together with respective values per state:\n",
    "#convert all date values to datetime objects:\n",
    "\n",
    "#Connecticut:\n",
    "df_ct_temps = pd.DataFrame(list(zip(ct_dates_temp, ct_temps)), columns = ['ct_date', 'ct_avg_temp'])\n",
    "df_ct_temps['ct_date']=pd.to_datetime(df_ct_temps['ct_date'])\n",
    "df_ct_prcp = pd.DataFrame(list(zip(ct_dates_prcp, ct_prcp)), columns = ['ct_date', 'ct_prcp'])\n",
    "df_ct_prcp['ct_date']=pd.to_datetime(df_ct_prcp['ct_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we already have avg_temp for CT, inner join with prcp:\n",
    "DF_ct = pd.merge(df_ct_temps, df_ct_prcp, how = 'inner', on= ['ct_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5aa77",
   "metadata": {},
   "source": [
    "#### Maine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd312737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maine:\n",
    "df_me_temp_min = pd.DataFrame(list(zip(me_dates_temp_min, me_temps_min)), columns = ['me_date', 'me_temp_min'])\n",
    "df_me_temp_min['me_date'] = pd.to_datetime(df_me_temp_min['me_date'])\n",
    "df_me_temp_max = pd.DataFrame(list(zip(me_dates_temp_max, me_temps_max)), columns = ['me_date', 'me_temp_max'])\n",
    "df_me_temp_max['me_date'] = pd.to_datetime(df_me_temp_max['me_date'])\n",
    "df_me_prcp = pd.DataFrame(list(zip(me_dates_prcp, me_prcp)), columns = ['me_date', 'me_prcp'])\n",
    "df_me_prcp['me_date']=pd.to_datetime(df_me_prcp['me_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b47bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge min max ME temp dfs to compute avg_temp:\n",
    "DF_me_temp_both = pd.merge(df_me_temp_max, df_me_temp_min, how = 'inner', on= ['me_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39375d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create avg_temp column for Maine:\n",
    "DF_me_temp_both['me_avg_temp'] = (DF_me_temp_both['me_temp_min'] + DF_me_temp_both['me_temp_max']) // 2\n",
    "#Drop min max temp columns:\n",
    "DF_me_temp_avg = DF_me_temp_both.drop(columns=['me_temp_max', 'me_temp_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge temp df with prcp df:\n",
    "DF_me = pd.merge(DF_me_temp_avg, df_me_prcp, how = 'inner', on= ['me_date'])\n",
    "DF_me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823bd1e",
   "metadata": {},
   "source": [
    "#### Vermont:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176bcc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vermont:\n",
    "df_vt_temp_min = pd.DataFrame(list(zip(vt_dates_temp_min, vt_temps_min)), columns = ['vt_date', 'vt_temp_min'])\n",
    "df_vt_temp_min['vt_date'] = pd.to_datetime(df_vt_temp_min['vt_date'])\n",
    "df_vt_temp_max = pd.DataFrame(list(zip(vt_dates_temp_max, vt_temps_max)), columns = ['vt_date', 'vt_temp_max'])\n",
    "df_vt_temp_max['vt_date'] = pd.to_datetime(df_vt_temp_max['vt_date'])\n",
    "df_vt_prcp = pd.DataFrame(list(zip(vt_dates_prcp, vt_prcp)), columns = ['vt_date', 'vt_prcp'])\n",
    "df_vt_prcp['vt_date']=pd.to_datetime(df_vt_prcp['vt_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge min max VT temp dfs to compute avg_temp:\n",
    "DF_vt_temp_both = pd.merge(df_vt_temp_max, df_vt_temp_min, how = 'inner', on= ['vt_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc828d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create avg_temp column for Vermont:\n",
    "DF_vt_temp_both['vt_avg_temp_t'] = (DF_vt_temp_both['vt_temp_min'] + DF_vt_temp_both['vt_temp_max']) // 2\n",
    "#Drop min max temp columns:\n",
    "DF_vt_temp_avg = DF_vt_temp_both.drop(columns=['vt_temp_max', 'vt_temp_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2773da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge temp df with prcp df:\n",
    "DF_vt = pd.merge(DF_vt_temp_avg, df_vt_prcp, how = 'inner', on= ['vt_date'])\n",
    "DF_vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a946fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge states to same df:\n",
    "df_vt_me = pd.merge(DF_vt, DF_me, how = 'left', left_on= ['vt_date'], right_on= ['me_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e83c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather= pd.merge(df_vt_me, DF_ct, how = 'left', left_on= ['vt_date'], right_on= ['ct_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather2 = df_weather.drop(columns=['me_date', 'ct_date'])\n",
    "df_weather2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17356caa",
   "metadata": {},
   "source": [
    "## COVID data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import COVID dataset:\n",
    "cov = pd.read_csv('time_series_covid19_confirmed_US.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd6850",
   "metadata": {},
   "source": [
    "COVID19 data source: \"COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University\" or \"JHU CSSE COVID-19 Data\" [link here](https://github.com/CSSEGISandData/COVID-19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54435ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate data for 3 locations closest to weather dataset:\n",
    "towns = cov[cov['Admin2'].isin(['Piscataquis', 'Hartford', 'Essex'])]\n",
    "cov_state = towns[towns['Province_State'].isin(['Connecticut', 'Maine', 'Vermont'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec124136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns and transpose\n",
    "cov_state2 = cov_state.drop(columns=['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Lat', 'Long_', 'Combined_Key', 'Country_Region', 'Admin2']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3684dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Headers with first row\n",
    "new_header = cov_state2.iloc[0] #grab the first row for the header\n",
    "cov_state2 = cov_state2[1:] #take the data less the header row\n",
    "cov_state2.columns = new_header #set the header row as the df header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f107bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index \n",
    "cov_state2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update column names in preparation for merge with weather dataset\n",
    "cov_state3=cov_state2.rename(columns={'index': 'date','Connecticut': 'CT_conf_cases', 'Maine': 'ME_conf_cases', 'Vermont': 'VT_conf_cases'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove index axis name\n",
    "cov_state3.rename_axis('', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0dd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_state3['date']=pd.to_datetime(cov_state3['date'])\n",
    "cov_state3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193c581",
   "metadata": {},
   "source": [
    "### Merge datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check null values \n",
    "cov_state3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename weather date column in preparation for merge\n",
    "df_weather2=df_weather2.rename(columns={'vt_date':'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge COVID dataset with weather data set and take a look:\n",
    "cov_weather = pd.merge(cov_state3, df_weather2, how = 'inner', on= ['date'])\n",
    "cov_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8bb80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Any remaining missing values?\n",
    "cov_weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cf1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_weather[pd.isnull(cov_weather).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773e6cf",
   "metadata": {},
   "source": [
    "### Create a Pandas Profiling Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(cov_weather, title=\"Cov_Weather Pandas Profiling Report\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540da03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ba874",
   "metadata": {},
   "source": [
    "__Save to csv file:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a new csv file\n",
    "cov_weather.to_csv('cleaned_cov_weather.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dbb8ab",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67f3e3",
   "metadata": {},
   "source": [
    "The daily climate data was to be retrieved from https://www.ncei.noaa.gov (the National Centers for Environmental Information website). This is a very large dataset that contains weather data collected from thousands of international weather stations, daily since 1880. \n",
    "\n",
    "First, empty lists were created to store the soon-to-be-retrieved-data. Three API calls were made to retrieve only the relevant climate data for the three US states of interest: Connecticut, Vermont, and Maine. A for loop was created within each API call in order to limit the data to those from 2020-2021. Within each for loop, only the specifically relevant climate data for each state was appended to the previously-created empty lists. For Connecticut, this relevant information included: Date, Average Temp, and Precipitation. The Vermont and Maine weather stations did not have \"Average Temperature\" data, so instead, for these two states we collected: Date, Min Temp, Max Temp, and Precipitation. \n",
    "\n",
    "Related lists were zipped together and merged into (3) dataframes of climate information by state. The 'Date' columns for each state DataFrame were converted to datetime objects. Next, \"Average Daily Temperature\" columns were created for the Vermont and Maine dataframes by created a new column that averaged each state's min and max temperature per day. The min and max temperature columns were then dropped. Each state's dataframe now contained 3 columns: 'Date', 'Average Temperature', and 'Precipitation.' The three states were merged together with an inner join on the date columns to form a single climate dataset. \n",
    "\n",
    "Next an API call was made to retrieve the COVID data from the csv file 'time_series_covid19_confirmed_US.csv'. Data concerning confirmed cases was retrieved from:\n",
    "\n",
    "1. Hartford, Connecticut\n",
    "2. Essex, Vermont \n",
    "3. Piscataquis, Maine\n",
    "\n",
    "These were chosen as they were the the closest geographical locations to those from the climate dataset. The exact locations of the weather stations, along with their distances from the COVID locations are listed below:\n",
    "\n",
    "1. Hartford, Connecticut: 0 miles\n",
    "2. Burlington, Vermont: 7.1 miles\n",
    "3. Greenville, Maine: 25.7 miles\n",
    "\n",
    "Next, irrelevant columns were removed, so that only state and dates columns remained. \n",
    "\n",
    "The data was at this point in very wide format, so the dataframe was transposed into long format. Now the indices were the dates and each column pertained to a different state. The column headers were replaced with each respective state name and the indices were reset, so that date once again became its own column. The columns were renamed in preparation for the dataframe's upcoming merge with the weather dataset. The index name was removed and the date column was converted to datetime objects.\n",
    "\n",
    "Both DataFrames were now ready to be merged together. A quick check on null values revealed that neither data set had any missing values. The name of the date column in the weather data set was changed to match that of the date column in the COVID data set and they merged on an inner join on the date column. A final check on null values revealed there was now 1 missing value in me_avg_temp and 1 missing value in me_prcp. Both these values appear to be from the same date: 2020-09-07. For now, the null values are left in the dataframe. Lastly A pandas profiling profile is created for the cov_weather DataFrame.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
