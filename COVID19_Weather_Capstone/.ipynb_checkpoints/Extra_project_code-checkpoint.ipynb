{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e8a9ca",
   "metadata": {},
   "source": [
    "# Extra project code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b771b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me3['pop_per_100sqmi'] = 1362359/30843\n",
    "df_ma3['pop_per_100sqmi'] = 7029917/7800\n",
    "df_ct3['pop_per_100sqmi'] = 3605944/4842\n",
    "df_vt3['pop_per_100sqmi'] = 643077/9217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff908a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ma3 = df_ma2[df_ma2['date']< '2021-03-01']\n",
    "#df_ct3 = df_ct2[df_ct2['date']< '2021-03-01']\n",
    "#df_me3 = df_me2[df_me2['date']< '2021-03-01']\n",
    "#df_vt3 = df_vt2[df_vt2['date']< '2021-03-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {\n",
    "                            \"descriptions\":{\n",
    "                                'date' : 'Date of confirmed cases and weather conditions.',\n",
    "                                'vt_avg_temp' : 'Average temperature in Vermont on a given date in tenths of a degree Celsius.',\n",
    "                                'vt_prcp' : 'Total precipitation in Vermont on a given date in tenths of a milimeter.',\n",
    "                                'me_avg_temp' : 'Average temperature in Maine on a given date in tenths of a degree Celsius.',\n",
    "                                'me_prcp' : 'Total precipitation in Maine on a given date in tenths of a milimeter.',\n",
    "                                'ct_avg_temp' : 'Average temperature in Connecticut on a given date in tenths of a degree Celsius.',\n",
    "                                'ct_prcp' : 'Total precipitation in Connecticut on a given date in tenths of a milimeter.',\n",
    "                                'ma_avg_temp' : 'Average temperature in Massachusetts on a given date in tenths of a degree Celsius.', \n",
    "                                'ma_prcp' : 'Total precipitation in Massachusetts on a given date in tenths of a milimeter.',\n",
    "                                'CT_conf_cases' : 'Total number of confirmed cases in Connecticut as of given date.',\n",
    "                                'ME_conf_cases' : 'Total number of confirmed cases in Maine as of given date.',\n",
    "                                'MA_conf_cases' : 'Total number of confirmed cases in Massachusetts as of given date.',\n",
    "                                'VT_conf_cases' : 'Total number of confirmed cases in Vermont as of given date.',\n",
    "                        }}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15c3c8",
   "metadata": {},
   "source": [
    "We might not expect the temperature in a given state to directly affect reported COVID cases from that very same day, we may want to explore correlations between COVID cases and lagged temperature values. Does the average temperature in a state, for example, have a hgher correlation with COVID cases that are detected one week after the temperature was recorded? How about one month later? Currently, many scientists believe that the incumbation period for the COVID19 virus is about 10-14 days. Let's do a cross-validation of time lags to determine the optimal lag to place on temperatures, ranging from one week to one month, and including both 10 and 14 day lags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "all_results=[]\n",
    "df_subset = df_ma3\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'new_case_percent_pop*', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'MA_Conf_Cases', 'MA_PRCP(mm)'],\n",
    "            numeric_features = ['day_of_year', 'Year', 'MA_Avg_Temp(F)', 'pop_per_100sqmi'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=False)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'R2', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"MA\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e38d9",
   "metadata": {},
   "source": [
    "From the above data, it looks like [Massachusetts](https://www.mass.gov/info-details/covid-19-response-reporting) and [Connecticut](https://www.mass.gov/info-details/covid-19-response-reporting) have similar Monday-Friday reporting schedules. It also seems that [Maine](https://www.maine.gov/dhhs/mecdc/infectious-disease/epi/airborne/coronavirus/data.shtml) reports cases Tuesday-Saturday and Vermont may report cases 7 days a week.\n",
    "\n",
    "From the data above, it would seem Vermont reports cases every day, but according to this [Associated Press article](https://apnews.com/article/health-coronavirus-pandemic-vermont-c781aa063d30e8f665500deaf8902ab9), Vermont only began reporting cases daily as of 2021-08-23, due to a large surge in cases. Prior to 2021-08-23, [Vermont](https://www.healthvermont.gov/covid-19) was also reporting cases Monday-Friday (like Connecticut and Massachusetts). Let's do a quick check and plot our data to make sure our data reflects this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "(https://www.mass.gov/info-details/covid-19-response-reporting)\n",
    "(https://www.mass.gov/info-details/covid-19-response-reporting)\n",
    "(https://www.maine.gov/dhhs/mecdc/infectious-disease/epi/airborne/coronavirus/data.shtml) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "model = RandomForestRegressor()\n",
    "def train_model(train, test, fold_no):\n",
    "    X = ['Retail_Price','Discount']\n",
    "    y = ['Returned_Units']\n",
    "    X_train = train[X]\n",
    "    y_train = train[y]\n",
    "    X_test = test[X]\n",
    "    y_test = test[y]\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('Fold',str(fold_no),'R2:',r2_score(y_test,predictions))\n",
    "fold_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(df_ohe, df_ohe['new_case_percent_pop*']):\n",
    "    train = df_ohe.loc[train_index,:]\n",
    "    test = df_ohe.loc[test_index,:]\n",
    "    train_model(train,test,fold_no)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "target = df.loc[:,'Returned_Units']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression()\n",
    "def train_model(train, test, fold_no):\n",
    "X = ['Retail_Price','Discount']\n",
    "y = ['Returned_Units']\n",
    "X_train = train[X]\n",
    "y_train = train[y]\n",
    "X_test = test[X]\n",
    "y_test = test[y]\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print('Fold',str(fold_no),'Accuracy:',accuracy_score(y_test,predictions))\n",
    "fold_no = 1\n",
    "for train_index, test_index in skf.split(df, target):\n",
    "    train = df.loc[train_index,:]\n",
    "    test = df.loc[test_index,:]\n",
    "    train_model(train,test,fold_no)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f618141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3c173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4281e399",
   "metadata": {},
   "source": [
    "We can see that the last time Vermont reported 0 cases was 2021-08-16. The above zero values all correspond to weekend days (and one Monday holiday), so we can confirmed that Vermont had the same reporting schedule as Massachusetts and Connecticut prior to 2021-08-23 (after which Vermont reported cases 7 days a week).\n",
    "\n",
    "Each respective state government webpage also indicates that on the day following a two-day weekend period (whether Saturday-Sunday or Sunday-Monday) the value reported is the cumulative sum of weekend cases and the the following weekday's cases (in other words, three days' worth of cases). Please see hyperlinks above for more details.\n",
    "\n",
    "We could leave all zero case counts as is, but this would skew the data. We could also drop all weekend values, but this isn't ideal either. If we drop all Saturday-Sunday periods, we're losing Maine's Saturday data and Vermont's Saturday-Sunday data from 2021-08-23 onwards. Additionally, Maine will still have missing values every Monday. There are three different reporting schedules, so we would be losing a lot of useful data if we dropped an entire row each time a state had a \"non-reporting\" day. Because the Monday (or Tuesday, in the case of Maine) case count is a cumulative sum of Saturday-Monday (or, in the case of Maine, Sunday-Tuesday), those cumulative Monday (or, Tuesday) counts will also skew the data.\n",
    "\n",
    "A much better alternative would be to take the Monday (or Tuesday, in the case of Maine) cumulative counts, divide by three, and replace weekend and Monday (or Tuesday) values with one third of the original cumulative count. We can also remove dates at the beginning of the pandemic before any of these states had seen their first COVID case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for 0 values in VT_Conf_Cases from just prior to 2021-08-23, onwards:\n",
    "df6[(df6['VT_Conf_Cases'] == 0) & (df6.index >= '2021-08-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a5882",
   "metadata": {},
   "source": [
    "It looks like [Massachusetts](https://www.mass.gov/info-details/covid-19-response-reporting) and [Connecticut](https://www.mass.gov/info-details/covid-19-response-reporting) have similar Monday-Friday reporting schedules. It also seems that [Maine](https://www.maine.gov/dhhs/mecdc/infectious-disease/epi/airborne/coronavirus/data.shtml) reports cases Tuesday-Saturday. See hyperlinks to each state governments' web page with more detailed COVID19 reporting schedule information. \n",
    "\n",
    "From the data above, it would seem Vermont reports cases every day, but according to this [Associated Press article](https://apnews.com/article/health-coronavirus-pandemic-vermont-c781aa063d30e8f665500deaf8902ab9), Vermont only began reporting cases daily as of 2021-08-23, due to a large surge in cases. Prior to 2021-08-23, [Vermont](https://www.healthvermont.gov/covid-19) was also reporting cases Monday-Friday (like Connecticut and Massachusetts). Let's do a quick check and plot our data to make sure our data reflects this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885d2e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d8194299a9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconcat_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconcat_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "concat_results = pd.concat(all_results,axis=0)\n",
    "concat_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a85cc",
   "metadata": {},
   "source": [
    "[Census Bureau state areas in sq mi](https://www.census.gov/geographies/reference-files/2010/geo/state-area.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cede199",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ME_index_list:\n",
    "    (df9.loc[i]['ME_Conf_Cases'])=((df9.loc[i]['ME_Conf_Cases'])/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_counter =0\n",
    "for row in df5[df5['MA_Conf_Cases']<0]:\n",
    "    ma_counter+=1\n",
    "print(\"MA has\", ma_counter/len(df5.columns), \"negative Conf_Cases value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_counter =0\n",
    "for row in df5[df5['VT_Conf_Cases']<0]:\n",
    "    vt_counter+=1\n",
    "print(\"VT has\", vt_counter/len(df5.columns), \"negative Conf_Cases value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2946460",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_counter =0\n",
    "for row in df5[df5['CT_Conf_Cases']<0]:\n",
    "    ct_counter+=1\n",
    "print(\"CT has\", ct_counter/len(df5.columns), \"negative Conf_Cases value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc698c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "me_counter =0\n",
    "for row in df5[df5['ME_Conf_Cases']<0]:\n",
    "    me_counter+=1\n",
    "print(\"ME has\", me_counter/len(df5.columns), \"negative Conf_Cases value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for row in df5[df5['CT_Conf_Cases']<0]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a94c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e00ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecab26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train-test set\n",
    "#train_me = df_me2[(df_me2['Year'] < 2021) | ((df_me2['Year']==2021) & (df_me2['Month']<=7))]\n",
    "#test_me = df_me2[(df_me2['Year']==2021) & (df_me2['Month']>7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_me.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regression module\n",
    "#from pycaret.regression import *\n",
    "# initialize setup\n",
    "#s = setup(data = train_me, test_data = test_me, target = 'MA_Conf_Cases', fold_strategy = 'timeseries', numeric_features = ['Month', 'Year', 'Series'], fold = 3, transform_target = True, session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9515775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best = compare_models(sort = 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3532bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train-test set\n",
    "train_ma = df_ma[df_ma.index < '2021-06-01']\n",
    "test_ma = df_ma[df_ma.index >= '2021-06-01']\n",
    "# check shape\n",
    "train_ma.shape, test_ma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcad0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize setup\n",
    "s = setup(data = train_ma, test_data = test_ma, target = 'MA_Conf_Cases', fold_strategy = 'timeseries', numeric_features = ['Year', 'Series'], fold = 3, transform_target = True, session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6adcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize setup\n",
    "s = setup(data = train_ma, test_data = test_ma, target = 'MA_Conf_Cases', fold_strategy = 'timeseries', numeric_features = ['Year', 'Series'], fold = 3, transform_target = True, session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8438590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regression module\n",
    "from pycaret.regression import *\n",
    "# initialize setup\n",
    "s = setup(data = train_ma, test_data = test_ma, target = 'MA_Conf_Cases', fold_strategy = 'timeseries', numeric_features = df_ma.index, fold = 3, transform_target = True, session_id = 123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF test for confirmation\n",
    "(test from second row on, as .diff() creates a NaN in the first row):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(df_vt['VT_Conf_Cases_stationary']['2020-01-23':])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# extract day, month, and year from dates\n",
    "df_me2['Year'] =[i.year for i in df_me2['date']]\n",
    "df_me2['Month'] = [i.month for i in df_me2['date']]\n",
    "df_me2['Day'] = [i.day for i in df_me2['date']]\n",
    "# drop unnecessary columns and re-arrange\n",
    "#df_me2.drop(['date'], axis=1, inplace=True)\n",
    "df_me2 = df_me2[['date', 'Series', 'Year', 'Month', 'Day', 'MA_Avg_Temp(F)', 'MA_PRCP(mm)', 'MA_Conf_Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0fdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vt2 = df_vt2[['date', 'Year', 'Month', 'Day', 'day_of_week', 'day_of_year', 'VT_Avg_Temp(F)', 'VT_PRCP(mm)', 'VT_Conf_Cases']]\n",
    "#df_ct2 = df_ct2[['date', 'Year', 'Month', 'Day', 'day_of_week', 'day_of_year', 'CT_Avg_Temp(F)', 'CT_PRCP(mm)', 'CT_Conf_Cases']]\n",
    "#df_me2 = df_me2[['date', 'Year', 'Month', 'Day', 'day_of_week', 'day_of_year', 'ME_Avg_Temp(F)', 'ME_PRCP(mm)', 'ME_Conf_Cases']]\n",
    "#df_ma2 = df_ma2[['date', 'Year', 'Month', 'Day', 'day_of_week', 'day_of_year', 'MA_Avg_Temp(F)', 'MA_PRCP(mm)', 'MA_Conf_Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a18034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vt3 = df_vt.reset_index()\n",
    "df_ct3 = df_ct.reset_index()\n",
    "df_me3 = df_me.reset_index()\n",
    "df_ma3 = df_ma.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "df_subset = df_me2\n",
    "all_results=[]\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'MA_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'Series', 'MA_PRCP(mm)'],\n",
    "            numeric_features = ['day_of_year', 'Year', 'MA_Avg_Temp(F)'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=True)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'MAE', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"ME\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = pd.concat(all_results,axis=0)\n",
    "concat_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6337bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results=[]\n",
    "df_subset = df_me2\n",
    "\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'ME_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'ME_PRCP(mm)'],\n",
    "            numeric_features = ['day_of_year', 'Year', 'ME_Avg_Temp(F)'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=True)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'MAE', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"ME\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb99c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = pd.concat([pd.concat(all_results, axis=0), concat_results], axis=0)\n",
    "concat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246234c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb05ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(concat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(all_results), concat_results], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ea306",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(all_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5047799",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ac4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = pd.concat([results_df, results_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d502ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d377ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all rows where at least one state reports a COVID case:\n",
    "filter = (df6.CT_Conf_Cases + df6.VT_Conf_Cases + df6.ME_Conf_Cases + df6.MA_Conf_Cases) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe so that any rows where every state has 0 COVID cases becomes NaN and drop NaNs\n",
    "x=(df6.where(filter).dropna())\n",
    "# Find earliest date where there is at least one COVID case reported\n",
    "min(x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430011d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows before 2020-01-29 \n",
    "df6 = df6.loc['2020-01-29':]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f882b57",
   "metadata": {},
   "source": [
    "Let's take a look at Maine first \n",
    "According to [Maine.gov](https://www.maine.gov/covid19/timeline), Maine's first COVID19 case was recorded on March 12th, 2020. We don't need to fill in any zero values before that date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31227669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7[(df7['weekday']==6)&(df7['ME_Conf_Cases']==0)&(df7.index>'2020-11-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.ME_Conf_Cases[(df7['weekday']==6)&(df7.index>'2020-04-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "& (df7.index > '2020-03-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[(df6['VT_Conf_Cases'] == 0) & (df.index >= '2021-08-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace cases negative values with np.nan\n",
    "df5.MA_Conf_Cases['2020-09-03'] = np.nan\n",
    "df5.CT_Conf_Cases[['2020-05-27', '2020-08-18']] = np.nan\n",
    "df5.VT_Conf_Cases[['2020-05-11', '2020-06-17']] = np.nan\n",
    "df5.ME_Conf_Cases[['2020-03-15','2020-07-22', '2020-09-09', '2021-08-09']]= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df7['ME_Conf_Cases']:\n",
    "    if df7['weekday'] == 5:\n",
    "        df7['ME_Third'] = (df7['ME_Conf_Cases']//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec259fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through NaNs and fill with average of previous and following cell values \n",
    "state_col_list=['CT_Conf_Cases', 'VT_Conf_Cases', 'ME_Conf_Cases', 'MA_Conf_Cases']\n",
    "for col in state_col_list:\n",
    "    df5[col] = df5[col].fillna((df5[col].shift() + df5[col].shift(-1))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3482480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6= df5\n",
    "df6[\"weekday\"] = df5.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.loc[(df6[\"weekday\" == 0]) & (df6['ME_Conf_Cases']==0) & (df6['MA_Conf_Cases']==0) & (df6['VT_Conf_Cases']==0) & (df6['CT_Conf_Cases']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216336f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[(df6['weekday'] == 0) & (df6['MA_Conf_Cases']==0)& (df6['ME_Conf_Cases']==0) & (df6['VT_Conf_Cases']==0) & (df6['CT_Conf_Cases']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c76a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((df6[(df6['weekday'] == 0) & ((df6['MA_Conf_Cases']==0))]).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e5105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[(df6['weekday'] == 0) & ((df6['ME_Conf_Cases']==0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e261b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.loc['2021-09-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6= df5\n",
    "df6[\"weekday\"] = df5.index.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deffb38",
   "metadata": {},
   "source": [
    "It looks like, for every five days of values for `Conf_Cases`, there are two days of zero values. A quick calendar check confirms that the dates corresponding to zero values are weekend dates (besides 09/06/21, which was Labor Day- a bank holiday in the US). Because there is only data for weekdays, I'll remove weekend data, as it can only skew our summary statistics and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column to designate day of week:\n",
    "df6= df5\n",
    "df6[\"weekday\"] = df6.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter DataFrame to only include weekdays (days 0-4)\n",
    "df6 = df6[(df6.weekday != 5) & (df6.weekday != 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(list1, list2):\n",
    "    merged_list = [(p1, p2) for idx1, p1 in enumerate(list1) \n",
    "    for idx2, p2 in enumerate(list2) if idx1 == idx2]\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = merge(ME_case_list, ME_case_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk2 =dict(zip(ME_index_list, idk))\n",
    "idk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in idk2.items():\n",
    "    (df9.loc[key]['ME_Conf_Cases']).replace(value[0], value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c31596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d57fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_vals_dict=dict(zip(ME_case_list, ME_case_list_new))\n",
    "rep_vals_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8876c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in ME_index_list:\n",
    "    df9.loc[index].ME_Conf_Cases.replace(rep_vals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ME_index_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indexes:\n",
    "    to_modify[indexes[index]] = replacements[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d52072",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in ME_index_list:\n",
    "    print(df9['ME_Conf_Cases'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ca5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ME_index_list:\n",
    "    df9.loc[i].ME_Conf_Cases = (df9.loc[i].ME_Conf_Cases/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab22a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ME_index_list:\n",
    "    (df9.loc[i]['ME_Conf_Cases'])=((df9.loc[i]['ME_Conf_Cases'])/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de6489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ME_index_list:\n",
    "    (df9.loc[i]['ME_Conf_Cases'])=((df9.loc[i]['ME_Conf_Cases'])/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa02d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.loc['2021-07-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06872219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.loc['2021-07-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023f2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if index >= pd.Timestamp('2021-07-01'):\n",
    "        if row['weekday'] == 1:\n",
    "            if row['ME_Conf_Cases'] != 0:\n",
    "                df9.index['ME_Conf_Cases'] /= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(df9[['CT_Conf_Cases', 'MA_Conf_Cases', 'ME_Conf_Cases', \n",
    "                            'VT_Conf_Cases', 'weekday']].tail(25)).style.applymap(highlight_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b89254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_counter =0\n",
    "for row in df5[df5['CT_Conf_Cases']<0]:\n",
    "    ct_counter+=1\n",
    "print(\"CT has\", ct_counter/len(df5.columns), \"negative Conf_Cases value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df9:\n",
    "    if df9.weekday == 1:\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df9:\n",
    "    if row.index == '2021-07-01':\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row['c1'], row['c2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b62544",
   "metadata": {},
   "source": [
    "I'll replace all zero values with `NaN`s so we can replace them using the `.fillna()` method. Once we've filled all appropriate `NaN`s, any remaining `NaN`s can be reset to zero as actual zero case counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a396e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over indices, rows and if row corresponds to a Tuesday after 2021-07-01 with a non-zero value for \n",
    "# ME_Conf_Cases, append index, case value, to corresponding lists\n",
    "ME_tuesday_index_list = []\n",
    "ME_tuesday_case_list =[]\n",
    "for index, row in df9.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01'))&(row['weekday'] == 1)&(row['ME_Conf_Cases'] != 0):\n",
    "        ME_tuesday_index_list.append(index)\n",
    "        ME_tuesday_case_list.append(row['ME_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db36c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each Tuesday non-zero ME case count by three and round to nearest integer; append to new list\n",
    "ME_case_list_new=[]\n",
    "for i in ME_tuesday_case_list:\n",
    "    ME_case_list_new.append(round(i/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of indices and new case count value \n",
    "ME_tuesday_case_dict= dict(zip(ME_tuesday_index_list, ME_case_list_new))\n",
    "ME_tuesday_case_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ab40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each ME_Conf_Case at index/key, with corresponding value\n",
    "for key, value in ME_tuesday_case_dict.items():\n",
    "    df9['ME_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10=df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_monday_index_list = []\n",
    "ME_monday_case_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01')):\n",
    "        if (row['weekday'] == 0):\n",
    "            if row['ME_Conf_Cases']==0:\n",
    "                ME_monday_index_list.append(index)\n",
    "                ME_monday_case_list.append(row['ME_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_monday_case_dict= dict(zip(ME_monday_index_list, ME_case_list_new))\n",
    "ME_monday_case_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee99cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each ME_Conf_Case at index/key, with corresponding value\n",
    "for key, value in ME_monday_case_dict.items():\n",
    "    df10['ME_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_sunday_index_list = []\n",
    "ME_sunday_case_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01')):\n",
    "        if (row['weekday'] == 6):\n",
    "            if row['ME_Conf_Cases']==0:\n",
    "                ME_sunday_index_list.append(index)\n",
    "                ME_sunday_case_list.append(row['ME_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948828d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_sunday_index_list = []\n",
    "ME_sunday_case_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01')):\n",
    "        if (row['weekday'] == 6):\n",
    "            if row['ME_Conf_Cases']==0:\n",
    "                ME_sunday_index_list.append(index)\n",
    "                ME_sunday_case_list.append(row['ME_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_sunday_case_dict= dict(zip(ME_sunday_index_list, ME_case_list_new))\n",
    "len(ME_sunday_case_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each ME_Conf_Case at index/key, with corresponding value\n",
    "for key, value in ME_sunday_case_dict.items():\n",
    "    df10['ME_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3e568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a167958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2a254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5da9bc6",
   "metadata": {},
   "source": [
    "#### Analyzing time series data checklist:\n",
    "$\\times$ 1) Convert index to datetime object \\\n",
    "$\\times$ 2) Plot the data \\\n",
    "$\\times$ 3) Run Augmented Dickey Fuller Test to see whether the data is a random walk \\\n",
    "$\\times$ 4) Take first differences of the data to transform it into a stationary series \\\n",
    "5) Compute ACF (Autocorrelation Function) and PACF (Partial Autocorrelation Funcion) \\\n",
    "6) Using that as a guide, fit a few AR, MA, and ARMA models to the data \\\n",
    "7) Use information criterion to choose the best model \\\n",
    "8) Forecast "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4080db0",
   "metadata": {},
   "source": [
    "can you please try XGBOOST\n",
    "\n",
    "for this dataset\n",
    "\n",
    "separately\n",
    "\n",
    "and not use pycaret\n",
    "\n",
    "\n",
    "Raghunandan, 11:10 PM\n",
    "one last observation, please combine data from all 4 states and use pycaret and let me know the results\n",
    "\n",
    "Good night!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a1ca0",
   "metadata": {},
   "source": [
    "## Connecticut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c92749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over indices, rows and if row corresponds to a Monday after 2020-07-01 with a non-zero value for \n",
    "# CT_Conf_Cases, append index, case value, to corresponding lists\n",
    "CT_monday_index_list = []\n",
    "CT_monday_case_list =[]\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2020-07-01'))&(row['weekday'] == 0)&(row['CT_Conf_Cases'] != 0):\n",
    "        CT_monday_index_list.append(index)\n",
    "        CT_monday_case_list.append(row['CT_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each Tuesday non-zero ME case count by three and round to nearest integer; append to new list\n",
    "CT_case_list_new=[]\n",
    "for i in CT_monday_case_list:\n",
    "    CT_case_list_new.append(round(i/3))\n",
    "len(CT_case_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each Tuesday non-zero ME case count by three and round to nearest integer; append to new list\n",
    "CT_case_list_new=[]\n",
    "for i in CT_monday_case_list:\n",
    "    CT_case_list_new.append(round(i/3))\n",
    "len(CT_case_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of indices and new case count value \n",
    "CT_monday_case_dict= dict(zip(CT_monday_index_list, CT_case_list_new))\n",
    "len(CT_monday_case_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679833e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each CT_Conf_Case at index/key, with corresponding value\n",
    "for key, value in CT_monday_case_dict.items():\n",
    "    df10['CT_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_sunday_index_list = []\n",
    "CT_sunday_case_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2020-07-01')):\n",
    "        if (row['weekday'] == 6):\n",
    "            if row['CT_Conf_Cases']== 0:\n",
    "                CT_sunday_index_list.append(index)\n",
    "                CT_sunday_case_list.append(row['CT_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_sunday_case_dict= dict(zip(CT_sunday_index_list, CT_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each CT_Conf_Case at index/key, with corresponding value\n",
    "for key, value in CT_sunday_case_dict.items():\n",
    "    df10['CT_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_saturday_index_list = []\n",
    "CT_saturday_case_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2020-07-01')):\n",
    "        if (row['weekday'] == 5):\n",
    "            if row['CT_Conf_Cases']==0:\n",
    "                CT_saturday_index_list.append(index)\n",
    "                CT_saturday_case_list.append(row['CT_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a52dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_saturday_case_dict= dict(zip(CT_saturday_index_list, CT_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b45f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each ME_Conf_Case at index/key, with corresponding value\n",
    "for key, value in CT_saturday_case_dict.items():\n",
    "    df10['CT_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415362a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over indices, rows and if row corresponds to a Monday after 2021-07-01 with a non-zero value for \n",
    "# MA_Conf_Cases, append index, case value, to corresponding lists\n",
    "MA_monday_index_list = []\n",
    "MA_monday_case_list =[]\n",
    "for index, row in df9.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01'))&(row['weekday'] == 0)&(row['MA_Conf_Cases'] != 0):\n",
    "        MA_monday_index_list.append(index)\n",
    "        MA_monday_case_list.append(row['MA_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each Tuesday non-zero ME case count by three and round to nearest integer; append to new list\n",
    "MA_case_list_new=[]\n",
    "for i in MA_monday_case_list:\n",
    "    MA_case_list_new.append(round(i/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of indices and new case count value \n",
    "MA_monday_case_dict= dict(zip(MA_monday_index_list, MA_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each CT_Conf_Case at index/key, with corresponding value\n",
    "for key, value in MA_monday_case_dict.items():\n",
    "    df10['MA_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded208cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_sunday_index_list = []\n",
    "MA_sunday_case_list =[]\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01')):\n",
    "        if (row['weekday'] == 6):\n",
    "            if row['MA_Conf_Cases']== 0:\n",
    "                MA_sunday_index_list.append(index)\n",
    "                MA_sunday_case_list.append(row['MA_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_sunday_case_dict= dict(zip(MA_sunday_index_list, MA_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each CT_Conf_Case at index/key, with corresponding value\n",
    "for key, value in MA_sunday_case_dict.items():\n",
    "    df10['MA_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_saturday_index_list = []\n",
    "MA_saturday_case_list =[]\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01')):\n",
    "        if (row['weekday'] == 5):\n",
    "            if row['MA_Conf_Cases']==0:\n",
    "                MA_saturday_index_list.append(index)\n",
    "                MA_saturday_case_list.append(row['ME_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afce6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_saturday_case_dict= dict(zip(MA_saturday_index_list, MA_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f62880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each ME_Conf_Case at index/key, with corresponding value\n",
    "for key, value in MA_saturday_case_dict.items():\n",
    "    df10['MA_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through NaNs and fill with average of previous and following cell values \n",
    "state_col_list=['CT_Conf_Cases', 'VT_Conf_Cases', 'ME_Conf_Cases', 'MA_Conf_Cases']\n",
    "for col in state_col_list:\n",
    "    df5[col] = df5[col].fillna((df5[col].shift() + df5[col].shift(-1))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace cases negative values with np.nan\n",
    "df5.MA_Conf_Cases['2020-09-03'] = np.nan\n",
    "df5.CT_Conf_Cases[['2020-05-27', '2020-08-18']] = np.nan\n",
    "df5.VT_Conf_Cases[['2020-05-11', '2020-06-17']] = np.nan\n",
    "df5.ME_Conf_Cases[['2020-03-15','2020-07-22', '2020-09-09', '2021-08-09']]= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721077cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.ME_Conf_Cases.shift(-1) = df9.ME_Conf_Cases / 3\n",
    "            df9.ME_Conf_Cases.shift(-2) = df9.ME_Conf_Cases / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e21d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through NaNs and fill with average of previous and following cell values \n",
    "state_col_list=['CT_Conf_Cases', 'VT_Conf_Cases', 'ME_Conf_Cases', 'MA_Conf_Cases']\n",
    "for col in state_col_list:\n",
    "    df5[col] = df5[col].fillna((df5[col].shift() + df5[col].shift(-1))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fe929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.ME_Conf_Cases.shift(-1).replace(0,1)\n",
    "            df9.ME_Conf_Cases.shift(-2).replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ddaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df9['2021-07-01':]:\n",
    "    if df9[df9['weekday']] == 2: # Tuesday \n",
    "        if df9.ME_Conf_Cases != 0: # Don't impute missing values if this is a bank holiday \n",
    "            df9.ME_Conf_Cases /= 3\n",
    "            #df9.ME_Conf_Casas.fillna(how='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e746ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_col_list=['CT_Conf_Cases', 'VT_Conf_Cases', 'ME_Conf_Cases', 'MA_Conf_Cases']\n",
    "for col in state_col_list:\n",
    "    df11[col] = df5[col].fillna((df5[col].shift() + df5[col].shift(-1))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fa2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df11.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01')):\n",
    "        if (row['weekday']==0) | (row['weekday'] ==6):\n",
    "            df11['ME_Conf_Cases'].replace(0, np.nan, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce625177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9.ME_Conf_Cases.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zero values after 2021-07-01 with np.nan\n",
    "#for index, row in df9.iterrows():\n",
    "    #if (index>=pd.Timestamp('2021-07-01'))&((row['weekday']==6)|(row['weekday']== 6))&(row['ME_Conf_Cases']==0):\n",
    "        #df9['ME_Conf_Cases'].replace(0, np.nan, inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9['ME_Conf_Cases'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(18,8)})\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df10.index, df10['ME_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Maine COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_me:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in monday_ind_me:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_me:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Maine COV cases', fontsize=20)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_me=(df10[(df10.weekday == 6)&(df10.ME_Conf_Cases==0)& (df10.index >'2020-01-29')]).index # Sunday zero values\n",
    "monday_ind_me=(df10[(df10.weekday == 0)&(df10.ME_Conf_Cases==0)&(df10.index>'2020-01-29')]).index # Monday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_me=(df10[(df10.weekday != 0)& (df10.weekday != 6)&(df10.ME_Conf_Cases==0)& (df10.index >'2020-01-29')]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800acd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_sunday_index_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-07-01')):\n",
    "        if (row['weekday'] == 6):\n",
    "            if row['ME_Conf_Cases']==0:\n",
    "                ME_sunday_index_list.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in ME_monday_index_list:\n",
    "    if df10['weekday'].loc[index] == 0:\n",
    "        df10['ME_Conf_Cases'] = df10['ME_Conf_Cases'].fillna(df10['ME_Conf_Cases'].shift())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df10.replace({'ME_Conf_Cases':{0:np.nan}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79df4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df10.index, df10['VT_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Vermont COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_vt:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_vt:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_vt:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Vermont COV cases', fontsize=16)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_vt=(df10[(df10.weekday == 6)&(df10.VT_Conf_Cases==0)]).index # Sunday zero values\n",
    "saturday_ind_vt=(df10[(df10.weekday == 5)&(df10.VT_Conf_Cases==0)]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_vt=(df10[(df10.weekday != 5)& (df10.weekday != 6)&(df10.VT_Conf_Cases==0)]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each ME_Conf_Case at index/key, with corresponding value\n",
    "for key, value in VT_saturday_case_dict.items():\n",
    "    df10['VT_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_saturday_case_dict= dict(zip(VT_saturday_index_list, VT_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_saturday_index_list = []\n",
    "VT_saturday_case_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-06-01')):\n",
    "        if (row['weekday'] == 5):\n",
    "            if row['VT_Conf_Cases']==0:\n",
    "                VT_saturday_index_list.append(index)\n",
    "                VT_saturday_case_list.append(row['VT_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each CT_Conf_Case at index/key, with corresponding value\n",
    "for key, value in VT_sunday_case_dict.items():\n",
    "    df10['VT_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_sunday_case_dict= dict(zip(VT_sunday_index_list, VT_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_sunday_index_list = []\n",
    "VT_sunday_case_list = []\n",
    "for index, row in df10.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-06-01')):\n",
    "        if (row['weekday'] == 6):\n",
    "            if row['VT_Conf_Cases']== 0:\n",
    "                VT_sunday_index_list.append(index)\n",
    "                VT_sunday_case_list.append(row['VT_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dictionary keys, values, and replace each CT_Conf_Case at index/key, with corresponding value\n",
    "for key, value in VT_monday_case_dict.items():\n",
    "    df10['VT_Conf_Cases'].loc[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of indices and new case count value \n",
    "VT_monday_case_dict= dict(zip(VT_monday_index_list, VT_case_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each Tuesday non-zero ME case count by three and round to nearest integer; append to new list\n",
    "VT_case_list_new=[]\n",
    "for i in VT_monday_case_list:\n",
    "    VT_case_list_new.append(round(i/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea34d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_monday_case_list =[]\n",
    "VT_monday_case_list.append(row['ME_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over indices, rows and if row corresponds to a Monday after 2021-07-01 with a non-zero value for \n",
    "# VT_Conf_Cases, append index, case value, to corresponding lists\n",
    "VT_monday_index_list = []\n",
    "VT_monday_case_list =[]\n",
    "for index, row in df9.iterrows():\n",
    "    if (index >= pd.Timestamp('2021-06-01'))&(index <= pd.Timestamp('2021-08-24'))&(row['weekday'] == 0)&(row['VT_Conf_Cases'] != 0):\n",
    "        VT_monday_index_list.append(index)\n",
    "        VT_monday_case_list.append(row['ME_Conf_Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbdc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_states = [MA, ME, CT, VT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolated_features = pd.DataFrame()\n",
    "#cols = [ , , , , ]\n",
    "#shift_dict = {'2w_ks': 14, '4wks':28, '6wks':42}\n",
    "#for col in cols:\n",
    "    #for key in shift_dict.keys():\n",
    "        #periods = shift_dict[key]\n",
    "        #temp[col+'_'+key] = temp[col].shift(periods=periods).copy().fillna(method='bfill')\n",
    "        #temp = temp.resample('W').mean()\n",
    "        #interpolated_features = pd.concat([site_interpolated, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA2 = MA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['SPX_Ret'] = df['SPX_Prices'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ab149",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA2['temp_change'] =MA2['MA_Avg_Temp(F)'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db443f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA2=MA2.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(MA2.corr(), square=True, annot=True)\n",
    "plt.yticks(rotation =45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc845013",
   "metadata": {},
   "source": [
    "AUTOCORRELATION: Correlation of a series with a lagged copy of itself (usually we mean lag 1)\n",
    "* For daily data, lag 1 would be the series lagged by one day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70756122",
   "metadata": {},
   "source": [
    "__Note:__ Not all bank holidays listed in the above resources appear in my `US_bank_holidays` list. I used the resources above as a general guide of dates that might not contain any data, and then checked each of the dates individually to make sure I wasn't deleting any significant data from the set. I found that data __was__ recorded for some of the bank holidays listed in the resources; whenever this was the case, I did __not__ drop that row of data. The dates listed in `US_bank_holidays` reflect only those bank holidays listed in these resources that I was __also__ able to confirm did not have any significant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc2ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of US bank holidays in 2020-2021:\n",
    "#Please refer to note below, explaining how this list of dates was put together.\n",
    "#US_bank_holidays = ['2020-02-17', '2020-12-25', '2020-11-26', '2020-12-25', '2021-01-01', '2021-05-31', '2021-09-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check rows have been dropped:\n",
    "#print(len(df6.index))\n",
    "#print(len(df7.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d48810",
   "metadata": {},
   "source": [
    "Valid palettes:\n",
    "  'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from pycaret.regression import *\n",
    "all_results=[]\n",
    "df_subset = df_ma3\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'MA_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'MA_PRCP(mm)', 'MA_Avg_Temp(F)'],\n",
    "            numeric_features = ['day_of_year', 'Year'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=False)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'R2', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"MA\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_results = pd.concat(all_results,axis=0)\n",
    "#concat_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4352ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_results=[]\n",
    "df_subset = df_ct3\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'CT_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'CT_PRCP(mm)', 'CT_Avg_Temp(F)'],\n",
    "            numeric_features = ['day_of_year', 'Year'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=True)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'R2', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"CT\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10783c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_results = pd.concat([pd.concat(all_results, axis=0), concat_results], axis=0)\n",
    "#concat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_results=[]\n",
    "df_subset = df_vt3\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'VT_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'VT_PRCP(mm)', 'VT_Avg_Temp(F)'],\n",
    "            numeric_features = ['day_of_year', 'Year'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=True)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'R2', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"VT\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a78145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_results = pd.concat([pd.concat(all_results, axis=0), concat_results], axis=0)\n",
    "#concat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243708a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_results=[]\n",
    "df_subset = df_me3\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'ME_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'ME_PRCP(mm)', 'ME_Avg_Temp(F)'],\n",
    "            numeric_features = ['day_of_year', 'Year'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=True)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'R2', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"ME\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_results = pd.concat([pd.concat(all_results, axis=0), concat_results], axis=0)\n",
    "#concat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_ma = df_ma['MA_Conf_Cases'].autocorr()\n",
    "autocorrelation_ma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_vt = df_vt['VT_Conf_Cases'].autocorr()\n",
    "autocorrelation_vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0fef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_ct = df_ct['CT_Conf_Cases'].autocorr()\n",
    "autocorrelation_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_features = pd.DataFrame()\n",
    "cols = [ , , , , ]\n",
    "shift_dict = {'2wks': 14, '4wks':28, '6wks':42}\n",
    "for col in cols:\n",
    "    for key in shift_dict.keys():\n",
    "        periods = shift_dict[key]\n",
    "        temp[col+'_'+key] = temp[col].shift(periods=periods).copy().fillna(method='bfill')\n",
    "        temp = temp.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfca812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95a9201e",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f8a5b",
   "metadata": {},
   "source": [
    "# CORRECT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc16aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me2 = df_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73bf76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sequence of numbers\n",
    "df_me2['Series'] = np.arange(1,len(df_me2)+1)\n",
    "# extract day, month, and year from dates\n",
    "df_me2['Year'] =[i.year for i in df_me2['date']]\n",
    "df_me2['Month'] = [i.month for i in df_me2['date']]\n",
    "df_me2['Day'] = [i.day for i in df_me2['date']]\n",
    "# drop unnecessary columns and re-arrange\n",
    "#df_me2.drop(['date'], axis=1, inplace=True)\n",
    "df_me2 = df_me2[['date', 'Series', 'Year', 'Month', 'Day', 'MA_Avg_Temp(F)', 'MA_PRCP(mm)', 'MA_Conf_Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db053da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me2['day_of_week'] = [i.dayofweek for i in df_me2['date']]\n",
    "df_me2['day_of_year'] = [i.dayofyear for i in df_me2['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "df_subset = df_me2\n",
    "all_results=[]\n",
    "\n",
    "# initialize setup from pycaret.regression\n",
    "s = setup(df_subset, target = 'MA_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'Series', 'MA_PRCP(mm)'],\n",
    "            numeric_features = ['day_of_year', 'Year', 'MA_Avg_Temp(F)'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=True)\n",
    "    \n",
    "# compare all models and select best one based on MAE\n",
    "best_model = compare_models(sort = 'MAE', verbose=False)\n",
    "    \n",
    "# capture the compare result grid and store best model in list\n",
    "p = pull().iloc[0:1]\n",
    "p['time_series'] = str(\"ME\")\n",
    "all_results.append(p)\n",
    "    \n",
    "# finalize model i.e. fit on entire data including test set\n",
    "f = finalize_model(best_model)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = pd.concat(all_results,axis=0)\n",
    "concat_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9268b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf595fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4162477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "all_results=[]\n",
    "for df in df_list:\n",
    "    county_df = df\n",
    "    s = setup(county_df, target = 'MA_Conf_Cases', train_size = 0.8,\n",
    "            data_split_shuffle = True, fold = 3,\n",
    "            ignore_features = ['date', 'Series', 'MA_PRCP(mm)'],\n",
    "            numeric_features = ['day_of_year', 'Year', 'MA_Avg_Temp(F)'],\n",
    "            categorical_features = ['Month', 'day_of_week'],\n",
    "            silent = True, verbose = False, session_id = 123,\n",
    "            normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9791c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.loc[(df9.index >= pd.Timestamp('2021-07-01'))&(df9.weekday == 1)&(df9.ME_Conf_Cases==0) , 'ME_Conf_Cases'] /= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002e53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLaggedFeatures(s,lag=2,dropna=True):\n",
    "'''\n",
    "Builds a new DataFrame to facilitate regressing over all possible lagged features\n",
    "'''\n",
    "if type(s) is pd.DataFrame:\n",
    "    new_dict={}\n",
    "    for col_name in s:\n",
    "        new_dict[col_name]=s[col_name]\n",
    "        # create lagged Series\n",
    "        for l in range(1,lag+1):\n",
    "            new_dict['%s_lag%d' %(col_name,l)]=s[col_name].shift(l)\n",
    "    res=pd.DataFrame(new_dict,index=s.index)\n",
    "\n",
    "elif type(s) is pd.Series:\n",
    "    the_range=range(lag+1)\n",
    "    res=pd.concat([s.shift(i) for i in the_range],axis=1)\n",
    "    res.columns=['lag_%d' %i for i in the_range]\n",
    "else:\n",
    "    print 'Only works for DataFrame or Series'\n",
    "    return None\n",
    "if dropna:\n",
    "    return res.dropna()\n",
    "else:\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
