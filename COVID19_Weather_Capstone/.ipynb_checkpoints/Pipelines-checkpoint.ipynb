{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f06886",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0195230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, RepeatedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error as mse, mean_absolute_error as mae, SCORERS\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from catboost import Pool, CatBoostRegressor, cv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import fmin, tpe, hp, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe REGULAR\n",
    "#parse datetime column\n",
    "#df=pd.read_csv('COVID19_modeling.csv', parse_dates=[0])\n",
    "#df.set_index('date', inplace= True)\n",
    "#df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b9ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe OHE\n",
    "#parse datetime column\n",
    "df_ohe = pd.read_csv('ohe_data.csv', parse_dates=['date'])\n",
    "df_ohe.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_ohe.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2cc3981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Temp(F)</th>\n",
       "      <th>Conf_Cases</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>new_case_percent_pop*</th>\n",
       "      <th>state_id_CT</th>\n",
       "      <th>state_id_MA</th>\n",
       "      <th>state_id_ME</th>\n",
       "      <th>state_id_VT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-01</th>\n",
       "      <td>26.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-02</th>\n",
       "      <td>36.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-03</th>\n",
       "      <td>55.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-04</th>\n",
       "      <td>46.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.028450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-05</th>\n",
       "      <td>42.98</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.113799</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Avg_Temp(F)  Conf_Cases  day_of_week  day_of_year  Year  Month  \\\n",
       "date                                                                         \n",
       "2020-03-01        26.42         1.0            6           61  2020      3   \n",
       "2020-03-02        36.50         1.0            0           62  2020      3   \n",
       "2020-03-03        55.94         1.0            1           63  2020      3   \n",
       "2020-03-04        46.94         2.0            2           64  2020      3   \n",
       "2020-03-05        42.98         8.0            3           65  2020      3   \n",
       "\n",
       "            Day  new_case_percent_pop*  state_id_CT  state_id_MA  state_id_ME  \\\n",
       "date                                                                            \n",
       "2020-03-01    1               0.014225            0            1            0   \n",
       "2020-03-02    2               0.014225            0            1            0   \n",
       "2020-03-03    3               0.014225            0            1            0   \n",
       "2020-03-04    4               0.028450            0            1            0   \n",
       "2020-03-05    5               0.113799            0            1            0   \n",
       "\n",
       "            state_id_VT  \n",
       "date                     \n",
       "2020-03-01            0  \n",
       "2020-03-02            0  \n",
       "2020-03-03            0  \n",
       "2020-03-04            0  \n",
       "2020-03-05            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4584343",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e7fdc",
   "metadata": {},
   "source": [
    "Before training any models on the data, let's do a train-test split to keep training and testing data consistent and separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e0f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "#X, y = df_ohe.drop(columns=['Conf_Cases', 'new_case_percent_pop*']), df_ohe['new_case_percent_pop*']\n",
    "# Make test and train split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c90156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2224"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9efd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 2224, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef91333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "X, y = df_ohe.drop(columns=['Conf_Cases', 'new_case_percent_pop*']), df_ohe['new_case_percent_pop*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa38faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binned = np.digitize(y, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4f1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y_binned, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test and train split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify =y_binned, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bb775",
   "metadata": {},
   "source": [
    "## Using the mean as a baseline prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfedbf61",
   "metadata": {},
   "source": [
    "Previously, we determined the R2 score of using the mean to predict COVID19 cases for each individual state. Let's do the same thing now that we have all the states in one DataFrame, so that we will have a baseline \"dummy\" model to compare our future optimized models to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6a3b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_mean = DummyRegressor()\n",
    "# \"Train\" dummy regressor\n",
    "dummy_mean.fit(X_train, y_train)\n",
    "# Get R2 score\n",
    "score_dummy = dummy_mean.score(X_test, y_test)\n",
    "print(\"The R2 score of using the mean to predict COVID19 cases in our states is:\", score_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69401f7b",
   "metadata": {},
   "source": [
    "Let's store the evaluation metric values for the dummy regressor so we can compare them with our future models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pred = dummy_mean.predict(X_test)\n",
    "dummy_r2 = r2_score(y_test, dummy_pred)\n",
    "dummy_mse = mse(y_test, dummy_pred)\n",
    "dummy_rmse = np.sqrt(mse(y_test, dummy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ca28d",
   "metadata": {},
   "source": [
    "## Tuning the top performing models for ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfcff3",
   "metadata": {},
   "source": [
    "In the pre-processing step, we determined (with the help of Pycaret) that our top performing models were **CatBoost Regressor**, **Random Forest Regressor**, and **Extra Trees Regressor**. Let's now fine tune the hyperparameters of each of these models, in preparation for feeding them into the pipeline of the Voting Regressor. \n",
    "\n",
    "**NOTE TO SELF: Determine hyperparameters for each model, but pass unfitted (tuned) models to the VotingRegressor**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c46073",
   "metadata": {},
   "source": [
    "### 1. Random Forest Regressor\n",
    "With a few exceptions, a RandomForestClassifier has all the hyperparameters of a DecisionTreeClassifier (to control how trees are grown), plus all the hyperparameters of a BaggingClassifier to control the ensemble itself. I'll explore a couple different ways to determine optimal hyperparameters and will choose those that produce the best R2 and MSE for the final ensemble model (a VotingRegressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd07755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to search for GridSearchCV\n",
    "basic_param_grid = {'n_estimators': [100, 300, 500, 900, 1200],\n",
    "              'max_depth': [3, 5, 20, 50, 100],\n",
    "              }\n",
    "# Instantiate RandomForestRegressor\n",
    "basic_rf = RandomForestRegressor(random_state=42)\n",
    "cv_rf = GridSearchCV(basic_rf, basic_param_grid, cv = 5)\n",
    "cv_rf_fit = cv_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The optimal max_depth for the RandomForestRegressor is: {}'.format(cv_rf_fit.best_params_['max_depth']))\n",
    "print('The optimal n_estimators for the RandomForestRegressor is: {}'.format(cv_rf_fit.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8da5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "basic_rf = RandomForestRegressor(max_depth = 50, n_estimators = 300, random_state=42)\n",
    "basic_rf.fit(X_train, y_train)\n",
    "basic_rf_pred = basic_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e557250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics on basic_rf\n",
    "basic_rf_r2 = r2_score(y_test, basic_rf_pred)\n",
    "basic_rf_mse = mse(y_test, basic_rf_pred)\n",
    "basic_rf_rmse = np.sqrt(basic_rf_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954aa316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results = pd.DataFrame({'Model':['dummy_reg', 'basic_rf'], 'R2': [dummy_r2, basic_rf_r2], 'MSE':[dummy_mse, basic_rf_mse], 'RMSE':[dummy_rmse, basic_rf_rmse]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600825df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744795d6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1d56d",
   "metadata": {},
   "source": [
    "#### Using RandomSearchCV to find optimal hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 120, num = 11)]\n",
    "max_depth.append(None)\n",
    "#max_depth.append(9)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, n_jobs=-1, random_state=42)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "rf2 = RandomForestRegressor(n_estimators= 900,\n",
    "                             min_samples_split= 2,\n",
    "                             min_samples_leaf= 2,\n",
    "                             max_features= 'auto',\n",
    "                             max_depth= 90,\n",
    "                             bootstrap= True, \n",
    "                             random_state=42)\n",
    "rf2.fit(X_train, y_train)\n",
    "rf_pred2 = rf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_r2 = r2_score(y_test, rf_pred2)\n",
    "rf_random_mse = mse(y_test, rf_pred2)\n",
    "rf_random_rmse = np.sqrt(mse(y_test, rf_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results.loc[len(rf_results)]= ['rf_randomCV', \n",
    "                                 r2_score(y_test, rf_pred2),\n",
    "                                 mse(y_test, rf_pred2),\n",
    "                                 np.sqrt(mse(y_test, rf_pred2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf22d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de6aea",
   "metadata": {},
   "source": [
    "### Using GridSearchCV to find the optimal hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09454aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "GS_param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [70, 80, 90, 100, 110],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'n_estimators': [700, 800, 900, 1000, 1100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e616be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = GS_param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94759d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb24a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "rf3 = RandomForestRegressor(n_estimators= 800,\n",
    "                             min_samples_split= 3,\n",
    "                             min_samples_leaf= 2,\n",
    "                             max_features= 'auto',\n",
    "                             max_depth= 90,\n",
    "                             bootstrap= True)\n",
    "rf3.fit(X_train, y_train)\n",
    "rf_pred3 = rf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71edeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine R2 score\n",
    "print('The R2 score for the RandomForestRegressor with GSCV tuning is {}'.format(r2_score(y_test, rf_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The MSE of the RandomForestRegressor with GSCV tuning is {}'.format(mse(y_test, rf_pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfb838",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results.loc[len(rf_results)]= ['rf_gridCV', \n",
    "                                 r2_score(y_test, rf_pred3),\n",
    "                                 mse(y_test, rf_pred3),\n",
    "                                 np.sqrt(mse(y_test, rf_pred3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec586b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf29e29",
   "metadata": {},
   "source": [
    "### Bayesian Optimization with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b00b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff154ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400]),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 30, 120, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define objective function\n",
    "\n",
    "def hyperparameter_tuning(params):\n",
    "    rf_reg = RandomForestRegressor(**params,n_jobs=-1)\n",
    "    r2 = cross_val_score(rf_reg, X_train, y_train ,scoring=\"r2\").mean()\n",
    "    return -r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f06fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=100, \n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "rf4 = RandomForestRegressor(n_estimators= 400,\n",
    "                             max_depth= 80)\n",
    "                             \n",
    "rf4.fit(X_train, y_train)\n",
    "rf_pred4 = rf4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results.loc[len(rf_results)]= ['rf_bayes_hyperopt', \n",
    "                                 r2_score(y_test, rf_pred4),\n",
    "                                 mse(y_test, rf_pred4),\n",
    "                                 np.sqrt(mse(y_test, rf_pred4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb273873",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f546a68",
   "metadata": {},
   "source": [
    "**?** $\\star$ It looks like the optimal hyperparameters chosen by RandomSearchCV performed the best, both in terms of the R2 and mean squared error, so we'll use those hyperparameters (as defined in `rf2`) in our final Voting Regressor ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef09a0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a68369",
   "metadata": {},
   "source": [
    "## 2. Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9cf67",
   "metadata": {},
   "source": [
    "### Using basic hyperparameter tuning only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to search for GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 300, 500, 900, 1200],\n",
    "              'max_depth': [3, 5, 20, 50, 100],\n",
    "              }\n",
    "# Instantiate ExtraTreesRegressor\n",
    "et = ExtraTreesRegressor(random_state=42)\n",
    "cv_et = GridSearchCV(et, param_grid, cv = 5)\n",
    "cv_et_fit = cv_et.fit(X_train, y_train)\n",
    "\n",
    "#Print the best parameter\n",
    "print(cv_et_fit.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0edcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The optimal max_depth for the ExtraTreesRegressor is: {}'.format(cv_et_fit.best_params_['max_depth']))\n",
    "print('The optimal n_estimators for the ExtraTreesRegressor is: {}'.format(cv_et_fit.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e526ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate ETR with optimal hyperparameters\n",
    "et_basic = RandomForestRegressor(max_depth = 50, n_estimators = 1200)\n",
    "et_basic.fit(X_train, y_train)\n",
    "et_basic_pred = et_basic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine R2 score\n",
    "print('The R2 score for the basic Extra Trees Regressor is {}'.format(r2_score(y_test, et_basic_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb346517",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The MSE of the basic ExtraTreesRegressor is {}'.format(mse(y_test, et_basic_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_et_r2 = r2_score(y_test, et_basic_pred)\n",
    "basic_et_mse = mse(y_test, et_basic_pred)\n",
    "basic_et_rmse = np.sqrt(mse(y_test, et_basic_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_results = pd.DataFrame({'Model':['dummy_reg', 'basic_et'], 'R2': [dummy_r2, basic_et_r2], 'MSE':[dummy_mse, basic_et_mse], 'RMSE':[dummy_rmse, basic_et_rmse]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a610b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "et_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0721cf75",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b2e6c2",
   "metadata": {},
   "source": [
    "### Using RandomSearchCV to find optimal hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(30, 140, num = 12)]\n",
    "max_depth.append(None)\n",
    "#max_depth.append(9)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid_et = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa09662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "et = ExtraTreesRegressor(random_state=42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "et2 = RandomizedSearchCV(estimator = et, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "et2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "et2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee5c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "et_random = ExtraTreesRegressor(n_estimators= 300,\n",
    "                             min_samples_split= 2,\n",
    "                             min_samples_leaf= 1,\n",
    "                             max_features= 'auto',\n",
    "                             max_depth= 120,\n",
    "                             bootstrap= True)\n",
    "et_random.fit(X_train, y_train)\n",
    "et_random_pred = et_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53656ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine R2 score\n",
    "print('The R2 score for the ExtraTreesRegressor with RSCV tuning is {}'.format(r2_score(y_test, et_random_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4796b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The MSE of the ExtraTreesRegressor with RSCV tuning is {}'.format(mse(y_test, et_random_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e315521",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_results.loc[len(et_results)]= ['et_randomCV', \n",
    "                                 r2_score(y_test, et_random_pred),\n",
    "                                 mse(y_test, et_random_pred),\n",
    "                                 np.sqrt(mse(y_test, et_random_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dfa218",
   "metadata": {},
   "source": [
    "#### Using GridSearchCV to find the optimal hyperparamter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92dbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "GS_param_grid_et = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': np.linspace(40, 150, 12),\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [2, 3],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': [300, 500, 800, 1000, 1200, 1600]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2299472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model\n",
    "et = ExtraTreesRegressor()\n",
    "# Instantiate the grid search model\n",
    "et3 = GridSearchCV(estimator = et, param_grid = GS_param_grid_et, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "et3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "et3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "et_grid = ExtraTreesRegressor(n_estimators= 500,\n",
    "                             min_samples_split= 4,\n",
    "                             min_samples_leaf= 2,\n",
    "                             max_features= 'auto',\n",
    "                             max_depth= 70,\n",
    "                             bootstrap= True)\n",
    "et_grid.fit(X_train, y_train)\n",
    "et_grid_pred = et_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine R2 score\n",
    "print('The R2 score for the Extra Trees Regressor with GSCV is {}'.format(r2_score(y_test, et_grid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The MSE of the ExtraTreesRegressor with GSCV is {}'.format(mse(y_test, et_grid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_results.loc[len(et_results)]= ['et_gridCV', \n",
    "                                 r2_score(y_test, et_grid_pred),\n",
    "                                 mse(y_test, et_grid_pred),\n",
    "                                 np.sqrt(mse(y_test, et_grid_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01353bd",
   "metadata": {},
   "source": [
    "### Bayestian Optimization with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_et = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eaed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_et = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [400, 500, 600, 700, 800, 900, 1000, 1100, 1200]),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 30, 120, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_et = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space_et, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=100, \n",
    "    trials=trials_et\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566bf890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate RFR with optimal hyperparameters\n",
    "et4 = ExtraTreesRegressor(n_estimators= 400,\n",
    "                             max_depth= 80)\n",
    "                             \n",
    "et4.fit(X_train, y_train)\n",
    "et_pred4 = et4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02156a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_results.loc[len(rf_results)]= ['et_bayes_hyperopt', \n",
    "                                 r2_score(y_test, et_pred4),\n",
    "                                 mse(y_test, et_pred4),\n",
    "                                 np.sqrt(mse(y_test, et_pred4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b46743",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f25e2",
   "metadata": {},
   "source": [
    "It seems that here the parameters suggested by RandomizedSearchCV (stored in `et_randomCV`) produced the best MSE and R2, so we'll use the hyperparameters from `et_randomCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c491c4",
   "metadata": {},
   "source": [
    "## 3. CatBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985ef0f",
   "metadata": {},
   "source": [
    "CatBoost is an open-sourced gradient boosting library. \n",
    "* 1. run CatBoost without tuning any hyperparameters to get baseline mse and r2\n",
    "* 2. RandomizedSearchCV for hyperparameters\n",
    "* 3. GridSearchCV for hyperparameters\n",
    "\n",
    "* [Pool documentation](https://catboost.ai/en/docs/concepts/python-reference_pool)\n",
    "* [CatboostRegressor documentation](https://catboost.ai/en/docs/concepts/python-reference_catboostregressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f54dc",
   "metadata": {},
   "source": [
    "### WITHOUT POOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_names = ['Month', 'day_of_week', 'state_id_MA', 'state_id_CT', 'state_id_VT', 'state_id_ME'] # here we specify names of categorical features\n",
    "cat_features = [X.columns.get_loc(col) for col in cat_features_names]\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7ada9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'loss_function':'RMSE',\n",
    "          'eval_metric':'R2',\n",
    "          'cat_features': cat_features,\n",
    "          'verbose': 200,\n",
    "          'early_stopping_rounds': 200,\n",
    "          'random_seed': 42\n",
    "         }\n",
    "cbc_1 = CatBoostRegressor(**params)\n",
    "cbc_1.fit(X_train, y_train,\n",
    "          eval_set=(X_test, y_test),\n",
    "          use_best_model=True,\n",
    "          plot=True\n",
    "         );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6edb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cbc1= cbc_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_cbc1 = r2_score(y_test, pred_cbc1)\n",
    "rmse_cbc1 = np.sqrt(mse(y_test, pred_cbc1))\n",
    "mse_cbc1 = mse(y_test, pred_cbc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f59f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing performance')\n",
    "print('RMSE: {:.2f}'.format(rmse_cbc1))\n",
    "print('MSE: {:.2f}'.format(mse_cbc1))\n",
    "print('R2: {:.2f}'.format(r2_cbc1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857da9dd",
   "metadata": {},
   "source": [
    "### WITH POOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cbc = Pool(X_train, y_train) \n",
    "test_dataset_cbc = Pool(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203eb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbc2 = CatBoostRegressor(loss_function='RMSE', random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1754d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'iterations': [100, 150, 200],\n",
    "        'learning_rate': [0.03, 0.1],\n",
    "        'depth': [2, 4, 6, 8],\n",
    "        'l2_leaf_reg': [0.2, 0.5, 1, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbc2.grid_search(grid, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cbc2 = model_cbc2.predict(X_test)\n",
    "rmse_cbc2 = (np.sqrt(mse(y_test, pred_cbc2)))\n",
    "r2_cbc2 = r2_score(y_test, pred_cbc2)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.2f}'.format(rmse_cbc2))\n",
    "print('R2: {:.2f}'.format(r2_cbc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbc2_params = {'depth': 8,\n",
    "  'iterations': 150,\n",
    "  'learning_rate': 0.1,\n",
    "  'l2_leaf_reg': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd416171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_cbc2_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ea341",
   "metadata": {},
   "source": [
    "### WITH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbc3 = CatBoostRegressor(random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d76dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'iterations': [100, 150, 200],\n",
    "        'learning_rate': [0.03, 0.1, 0.3],\n",
    "        'depth': [4, 6, 8, 10, 12],\n",
    "        'l2_leaf_reg': [0.2, 0.5, 1, 3],\n",
    "        'loss_function':'RMSE',\n",
    "        'eval_metric':'R2',\n",
    "        'cat_features': cat_features,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbc3.grid_search(grid, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccdd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Pool(X_train, y_train) \n",
    "test_dataset = Pool(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cv = {'loss_function':'RMSE',\n",
    "          'eval_metric':'R2',\n",
    "          'cat_features': cat_features, \n",
    "          'early_stopping_rounds': 200,\n",
    "          'verbose': 200,\n",
    "          'random_seed': 42\n",
    "         }\n",
    "model_cv = CatBoostRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'iterations': [100, 150, 200],\n",
    "        'learning_rate': [0.001, 0.03, 0.1],\n",
    "        'depth': [2, 4, 6, 8, 50, 100],\n",
    "        'l2_leaf_reg': [0.2, 0.5, 1, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_cv.grid_search(grid, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b112590",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_final = {'loss_function':'RMSE',\n",
    "          'eval_metric':'R2',\n",
    "          'cat_features': cat_features, \n",
    "          'early_stopping_rounds': 200,\n",
    "          'verbose': 200,\n",
    "          'random_seed': 42,\n",
    "          'max_depth' : 8,\n",
    "          'iterations' : 150,\n",
    "          'learning_rate' : 0.1,\n",
    "          'l2_leaf_reg': 0.5\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_tuned = CatBoostRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_tuned.fit(X_train, y_train,\n",
    "                   eval_set=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cafe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_z = cb_model_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_z = (np.sqrt(mse(y_test, pred_z)))\n",
    "r2_z = r2_score(y_test, pred_z)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.2f}'.format(rmse_z))\n",
    "print('R2: {:.2f}'.format(r2_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "rmse = (np.sqrt(mse(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.2f}'.format(rmse))\n",
    "print('R2: {:.2f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acdbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ec94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58019dc4",
   "metadata": {},
   "source": [
    "### SOMETHING ELSE WITH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb71ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Pool(data=X_train,\n",
    "                  label=y_train,\n",
    "                  cat_features=cat_features\n",
    "                 )\n",
    "\n",
    "test_data = Pool(data=X_test,\n",
    "                  label=y_test,\n",
    "                  cat_features=cat_features\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss_function':'RMSE',\n",
    "          'eval_metric':'R2',\n",
    "#           'cat_features': cat_features, # we don't need to specify this parameter as \n",
    "#                                           pool object contains info about categorical features\n",
    "          'early_stopping_rounds': 200,\n",
    "          'verbose': 200,\n",
    "          'random_seed': 42\n",
    "         }\n",
    "\n",
    "cbc_7 = CatBoostClassifier(**params)\n",
    "cbc_7.fit(train_data, # instead of X_train, y_train\n",
    "          eval_set=_data, # instead of (X_valid, y_valid)\n",
    "          use_best_model=True, \n",
    "          plot=True\n",
    "         );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cbc_7.get_all_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "params = {'loss_function':'RMSE',\n",
    "          'eval_metric':'R2',\n",
    "          'verbose': 200,\n",
    "          'random_seed': 42\n",
    "         }\n",
    "\n",
    "all_train_data = Pool(data=X_train,\n",
    "                      label=y_train,\n",
    "                      cat_features=cat_features\n",
    "                     )\n",
    "\n",
    "scores = cv(\n",
    "   params=params,\n",
    "   dtrain=train_data,\n",
    "   iterations=None,\n",
    "   num_boost_round=None,\n",
    "   fold_count=5,\n",
    "   nfold=None,\n",
    "   inverted=False,\n",
    "   partition_random_seed=0,\n",
    "   seed=42,\n",
    "   shuffle=True,\n",
    "   stratified=None,\n",
    "   as_pandas=True,\n",
    "   metric_period=None,\n",
    "   verbose=None,\n",
    "   verbose_eval=None,\n",
    "   plot=True,\n",
    "   early_stopping_rounds=200,\n",
    "   folds=None,\n",
    "   type='Classical',\n",
    "   return_models=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b741e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_7.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb5cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d63202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf957483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe_features = df_ohe.drop(columns=['Conf_Cases', 'new_case_percent_pop*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4822485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_feature_importance = model.feature_importances_.argsort()\n",
    "plt.barh(df_ohe_features.columns[sorted_feature_importance], \n",
    "        model.feature_importances_[sorted_feature_importance], \n",
    "        color='turquoise')\n",
    "plt.xlabel('CatBoost Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180a281",
   "metadata": {},
   "source": [
    "## Shap value plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d64c0",
   "metadata": {},
   "source": [
    "Optimized RG model SHAP value plots:\n",
    "    * Dot represents feature importance for one sample\n",
    "    * Right $\\Rightarrow$ feature increased probability of positive label\n",
    "    * Left $\\Rightarrow$ feature decreased probability of positivity label\n",
    "    * Red $\\Rightarrow$ high feature value\n",
    "    * Blue $\\Leftarrow$ low feature value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ceb21",
   "metadata": {},
   "source": [
    "for more info on shap plots and how to interpret: [this article](https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8569f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, feature_names = df_ohe_features.columns[sorted_feature_importance])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52526a1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a74d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe OHE\n",
    "#parse datetime column\n",
    "df_cb = pd.read_csv('ohe_data2.csv', parse_dates=['date'])\n",
    "df_cb.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_cb.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb.drop(columns=['Conf_Cases'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "X2, y2 = df_ohe.drop(columns=['new_case_percent_pop*']), df_ohe['new_case_percent_pop*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2513ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort y\n",
    "y_sorted2 = sorted(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your y values in a new ndarray, broken down by the bins created above.\n",
    "y_binned2 = np.digitize(y2, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, stratify=y_binned2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset2 = Pool(X_train2, y_train2) \n",
    "test_dataset2 = Pool(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76888f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_all_model = CatBoostRegressor(loss_function='RMSE', random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148780d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_all_model.grid_search(grid, train_dataset2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cff993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = ohe_all_model.predict(X_test2)\n",
    "rmse = (np.sqrt(mse(y_test2, pred2)))\n",
    "r2_2 = r2_score(y_test2, pred2)\n",
    "print('Testing performance')\n",
    "print('RMSE: {:.2f}'.format(rmse))\n",
    "print('R2: {:.2f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdceacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance = ohe_all_model.feature_importances_.argsort()\n",
    "plt.barh(df_cb.columns[sorted_feature_importance], \n",
    "        ohe_all_model.feature_importances_[sorted_feature_importance], \n",
    "        color='turquoise')\n",
    "plt.xlabel('CatBoost Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer2 = shap.TreeExplainer(model)\n",
    "shap_values2 = explainer2.shap_values(X_test2)\n",
    "shap.summary_plot(shap_values2, X_test2, feature_names = df_cb.columns[sorted_feature_importance])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfd508",
   "metadata": {},
   "source": [
    "## For catboost use: 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6440f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a68440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e00480e3",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879dfe1",
   "metadata": {},
   "source": [
    "#### Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(bootstrap = True,\n",
    "                             max_depth = 70,\n",
    "                             max_features = 'auto',\n",
    "                             min_samples_leaf = 2,\n",
    "                             min_samples_split = 2,\n",
    "                             n_estimators = 600\n",
    ")\n",
    "\n",
    "# ExtraTreesRegressor\n",
    "et_reg = ExtraTreesRegressor(n_estimators = 1700,\n",
    "                             min_samples_split = 3,\n",
    "                             min_samples_leaf = 1,\n",
    "                             max_features = 'auto',\n",
    "                             max_depth = 70,\n",
    "                             bootstrap = True)\n",
    "\n",
    "# CatBoostRegressor\n",
    "cb_reg = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74328cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Voting Classifier with soft voting because all models performed similarly\n",
    "\n",
    "clf_voting = VotingRegressor(estimators = [('rf_est', rf_reg), ('et_est', et_reg),\n",
    "                                           ('cb_est', cb_reg)])\n",
    "#Fit and predict\n",
    "\n",
    "clf_voting.fit(X_train, y_train)\n",
    "pred_voting = clf_voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a307c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unweighted VotingReg R2: ', r2_score(y_test, pred_voting))\n",
    "print('Unweighted VotingReg MSE: ', mse(y_test, pred_voting))\n",
    "print('Unweighted VotingReg RMSE: ', np.sqrt(mse(y_test, pred_voting)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52762b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists that will storage the different weights\n",
    "\n",
    "weights1 = []\n",
    "weights2 = []\n",
    "weights3 = []\n",
    "scores = []\n",
    "\n",
    "# Create a for loop to evaluate different combinations of weights\n",
    "\n",
    "for i in np.arange(0.1,1, 0.1):\n",
    "    for j in np.arange(0.1,1, 0.1):\n",
    "        for k in np.arange(0.1,1, 0.1):\n",
    "            reg_voting = VotingRegressor(estimators = [('rf_est', rf_reg), ('et_est', et_reg),\n",
    "                                           ('cb_est', cb_reg)], weights = [i, j, k])\n",
    "            reg_voting.fit(X_train, y_train)\n",
    "            pred = reg_voting.predict(X_test)\n",
    "            score = r2_score(y_test, pred)\n",
    "            scores.append(score)\n",
    "            weights1.append(i)\n",
    "            weights2.append(j)\n",
    "            weights3.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results in a data frame\n",
    "\n",
    "test_scores = pd.DataFrame()\n",
    "test_scores['Weight1'] = weights1\n",
    "test_scores['Weight2'] = weights2\n",
    "test_scores['Weight3'] = weights3\n",
    "test_scores['Test Score'] = scores\n",
    "\n",
    "# Create an additional column to save the sum of all the weights\n",
    "\n",
    "test_scores['sum_weights'] = test_scores['Weight1'].add(test_scores['Weight2']).add(test_scores['Weight3'])\n",
    "\n",
    "#We are only getting the rows that the sum of all weights were equal to one\n",
    "\n",
    "condition = test_scores['sum_weights'] == 1\n",
    "\n",
    "test_scores = test_scores.loc[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ea5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the values to see the different test scores depending on the weights\n",
    "test_scores.sort_values(by = 'Test Score', ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Voting Classifier with the most equally weighted because all models performed similarly\n",
    "\n",
    "reg_voting = VotingRegressor(estimators = [('rf_est', rf_reg), ('et_est', et_reg),\n",
    "                                           ('cb_est', cb_reg)], weights = [0.2, 0.4, 0.4])\n",
    "\n",
    "#Fit and predict\n",
    "\n",
    "reg_voting.fit(X_train, y_train)\n",
    "pred_voting = reg_voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3790d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_final = r2_score(y_test, pred_voting)\n",
    "MSE_final = mse(y_test, pred_voting)\n",
    "RMSE_final = np.sqrt(mse(y_test, pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final VotingRegressor R2: ', R2_final)\n",
    "print('Final VotingRegressor MSE: ', MSE_final)\n",
    "print('Final VotingRegressor RMSE: ', RMSE_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8291d3b",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad06df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(reg_voting.feature_importances_):\n",
    "    print(\"{0:s}: {1:.2f}\".format(X.columns[i], item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d2d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
