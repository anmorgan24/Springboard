{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0beff39",
   "metadata": {},
   "source": [
    "# Statistical Thinking in Python Functions for Reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4135f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa530cba",
   "metadata": {},
   "source": [
    "## Statistical inference packages:\n",
    "scipy.stats \\\n",
    "statsmodel \\\n",
    "scikit.learn \\\n",
    "numpy (for hacker statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b4a4e",
   "metadata": {},
   "source": [
    "## PMF vs PDF vs CDF vs ECDF:\n",
    "__PMF__: *Distcrete* outcomes (/discrete random variables); normal/Gaussian distribution (bell-curve) \\\n",
    "__PDF__: *Continuous* outcomes (/continuous random variables); normal/Gaussian distribution (bell-curve); for hist: normed=True\\\n",
    "__CDF__: *Hypothetical* probability distribution; exponential or normal/Sigmoid \\\n",
    "__ECDF__: *Observed* probability distribution; exponential or normal/Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea427d67",
   "metadata": {},
   "source": [
    "## ECDF\n",
    "__E__ mpirical __C__ umulative __D__ istribution __F__ unction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f597b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    \n",
    "    #Number of data points: n\n",
    "    n = len(data)\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n+1) / n\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735666c",
   "metadata": {},
   "source": [
    "`#Compute ECDF for versicolor data: x_vers, y_vers'\n",
    "x_vers, y_vers = ecdf(versicolor_petal_length)\n",
    "#Generate plot \n",
    "_ = plt.plot(x_vers, y_vers, marker= '.', linestyle = 'none') \n",
    "#Label the axes \n",
    "_ = plt.xlabel('versicolor_petal_length') \n",
    "_ = plt.ylabel('ECDF') \n",
    "#Display the plot \n",
    "plt.show()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfe286",
   "metadata": {},
   "source": [
    "### Binomial Distribution:\n",
    "The number *r* of successes in *n* Bernoulli (success/fail) trials, with probability *p* of success, is Binomially distributed. \\\n",
    "__`np.random.binomial()`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192c1d2",
   "metadata": {},
   "source": [
    "### Bernoulli Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c80f84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_bernoulli_trials(n, p):\n",
    "    \"\"\"Perform n Bernoulli trials with success probability p\n",
    "    and return number of successes.\"\"\"\n",
    "    # Initialize number of successes: n_success\n",
    "    n_success = 0\n",
    "\n",
    "    # Perform trials\n",
    "    for i in range(n):\n",
    "        # Choose random number between zero and one: random_number\n",
    "        random_number = np.random.random()\n",
    "\n",
    "        # If less than p, it's a success so add one to n_success\n",
    "        if random_number < p:\n",
    "            n_success += 1\n",
    "\n",
    "    return n_success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb30389",
   "metadata": {},
   "source": [
    "## Poisson: \n",
    "__Poisson process:__ The timing of the next event is completely independent of when the previous event happened (ie bus arrivals in Poissonville) \\\n",
    "__Poisson distribution:__ A limit of the Binomial distribution for low probabilty of success and large number of trials (ie, for rare events):\n",
    "1) The number *r* of arrivals of a Poisson process in a given time interval with average rate of ? arrivals per interval is Poisson distributed. \\\n",
    "2) The number *r* of hits on a website in one hour with an average hit rate of 6 hits per hour is Poisson distributed.\\\n",
    "__`np.random.poisson()`__\n",
    "\n",
    "The waiting time between arrivals of a Poisson process is Exponentially distributed. \\\n",
    "\n",
    "__`successive_poisson()` function:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b19cafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successive_poisson(tau1, tau2, size=1):\n",
    "    \"\"\"Compute time for arrival of 2 successive Poisson processes.\"\"\"\n",
    "    # Draw samples out of first exponential distribution: t1\n",
    "    t1 = np.random.exponential(tau1, size=1)\n",
    "\n",
    "    # Draw samples out of second exponential distribution: t2\n",
    "    t2 = np.random.exponential(tau2, size=1)\n",
    "\n",
    "    return t1 + t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3f798",
   "metadata": {},
   "source": [
    "## Exponential: \n",
    "The waiting time between arrivals of a Poisson process is Exponentially distributed. \\\n",
    "Parameters: mean (waiting time), size \\\n",
    "__`np.random.exponential(scale=1.0, size=None)`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa5874",
   "metadata": {},
   "source": [
    "`inter_nohitter_time = np.random.exponential(tau, 100000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291673f",
   "metadata": {},
   "source": [
    "## Checking normality of distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c39d0",
   "metadata": {},
   "source": [
    "`import numpy as np` \\\n",
    "`mean = np.mean(michelson_speed_of_light)` \\\n",
    "`std = np.std(michelson_speed_of_light)` \\\n",
    "`samples = np.random.normal(mean, std, size = 10000)` \\\n",
    "`x, y = ecdf(michelson_speed_of_light)` \\\n",
    "`x_theor, y_theor = ecdf(samples)` \\\n",
    "\n",
    "Then, plot empirical and theoretical CDF's on the same plot to check for normal distribution. \\\n",
    "__This is preferrable to histogram check for normal distribution because there is no binning bias.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a0b10",
   "metadata": {},
   "source": [
    "## Computing Percentiles:\n",
    "__`np.percentile(df['column'], [list of percentiles])`__ \n",
    "\n",
    "#### 25th, 50th, 75th percentiles:\n",
    "__`np.percentile(df['column'], [25, 50, 75])`__ \n",
    "#### 95% Confidence interval: \n",
    "__`np.percentile(df['column'], [2.5, 97.5])`__ \n",
    "#### 99% Confidence interval:\n",
    "__`np.percentile(df['column'], [0.5, 99.5])`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe8d4d",
   "metadata": {},
   "source": [
    "## Pearson Correlation Coefficient:\n",
    "Pearson correlation coefficient, $\\rho$, ranges from -1 (for complete anti-correlation) to 1 (for complete positive correlation). $\\rho$ = 0 indicates no correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2282b1a2",
   "metadata": {},
   "source": [
    "__Covariance:__ a measure of how two quantities vary *together.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8b875",
   "metadata": {},
   "source": [
    "$\\rho$ = covariance / [(std of x)(std of y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d82607",
   "metadata": {},
   "source": [
    "$\\rho$ = variablity due to codependence/ independent variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "030fb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_r(x, y):\n",
    "    \"\"\"Compute Pearson correlation coefficient between two arrays.\"\"\"\n",
    "    # Compute correlation matrix: corr_mat\n",
    "    corr_mat = np.corrcoef(x,y)\n",
    "\n",
    "    # Return entry [0,1]\n",
    "    return corr_mat[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee5d22",
   "metadata": {},
   "source": [
    "__Standard error of the mean (sem):__ \n",
    "\n",
    "```\n",
    "# Take 10,000 bootstrap replicates of the mean: bs_replicates\n",
    "bs_replicates = draw_bs_reps(rainfall, np.mean, size=10000)\n",
    "\n",
    "# Compute and print SEM\n",
    "sem = np.std(rainfall) / np.sqrt(len(rainfall))\n",
    "print(sem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a6ba64",
   "metadata": {},
   "source": [
    "## The np.random module:\n",
    "A suite of functions based on pseudo-random number generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a19d1",
   "metadata": {},
   "source": [
    "__`np.random.seed()`__ \\\n",
    "set the seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d99adc",
   "metadata": {},
   "source": [
    "__`np.random.random(size= )`__ \\\n",
    "draw a number between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69989ec2",
   "metadata": {},
   "source": [
    "__`np.random.choice()`__ \\\n",
    "`np.random.choice([1,2,3,4,5], size = 10)`\\\n",
    "first argument: array of values to \"choose\" from\\\n",
    "size: how many samples we want to take out of that array\\\n",
    "default: `np.random.choice(a, size=None, replace=True, p=None)`\\\n",
    "__`bs_sample`__ `= np.random.choice(michelson_speed_of_light, size=100)`\\\n",
    " --this is a bootstrap sample since there were 100 data points in the original data set, and we ar choosing 100 of them with replacement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67526ecc",
   "metadata": {},
   "source": [
    "__`np.random.binomial(4, 0.5)`__ \\\n",
    "__`np.random.binomial(4, 0.5, 10)`__ \n",
    "\n",
    "sampling from a Binomial distribution \\\n",
    "arguments: \\\n",
    "(4) = number of Bernoulli trials (coin flips) \\\n",
    "(0.5) = probability of success (50:50) \\\n",
    "(10) = how many times to repeat the (4 flip) experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfa4009",
   "metadata": {},
   "source": [
    "__`np.random.poisson(5, 10000)`__ \\\n",
    "`random.poisson(lam=1.0, size=None)`Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06fa6e",
   "metadata": {},
   "source": [
    "__`np.random.normal(mean, std, size)`__ \\\n",
    "`np.random.normal(np.mean(height), np.std(height), size = 10000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356bd5b0",
   "metadata": {},
   "source": [
    "__`random.exponential(scale=1.0, size=None)`__  \\\n",
    "`np.random.exponential(mean, 10000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdcc451",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a9022",
   "metadata": {},
   "source": [
    "__Residual:__ Distance between singular data point and the line of best fit; \"residual error\" \\\n",
    "__Least Squares:__ The process of finding the parameters for which the sum of the squares of the residual of the residuals is minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2689c4b",
   "metadata": {},
   "source": [
    "__`np.polyfit()`__ performs least squares analysis with polynomial functions (a linear function is a first degree polynomial). \\\n",
    "__`slope, intercept = np.polyfit(x, y, degree)`__ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bcddb",
   "metadata": {},
   "source": [
    "__Zip lists together for x, y coords and compute parameters of resulting linear regression:__ \n",
    "\n",
    "```#Iterate through x,y pairs\n",
    "for x, y in zip(anscombe_x, anscombe_y):\n",
    "    # Compute the slope and intercept: a, b\n",
    "    a, b = np.polyfit(x,y,1)\n",
    "    # Print the result\n",
    "    print('slope:', a, 'intercept:', b)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec9326",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "__Bootstrapping:__ The use of resampled data to perform statistical inference. \\\n",
    "__Bootstrap Sample:__ A resampled array of data. \\\n",
    "__Bootstrap replicate:__ A statistic computed from resampled array (for example; mean of a bootstrap sample/ resampled array). \"A simulated replica of the original data acquired by bootstrapping.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e68ea",
   "metadata": {},
   "source": [
    "__default:__ `np.random.choice(a, size=None, replace=True, p=None)`\\\n",
    "__`bs_sample = np.random.choice(michelson_speed_of_light, size=100)`__\\\n",
    " --this is a bootstrap sample since there were 100 data points in the original data set, and we ar choosing 100 of them with replacement.\n",
    "\n",
    "Since we will compute the bootstrap replicates over and over again, we can write a function to generate a bootstrap replicate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d16fad",
   "metadata": {},
   "source": [
    "__Single bootstrap replicate of 1D data:__\n",
    "```def bootstrap_replicate_1d(data, func):\n",
    "        '''Generate bootstrap replicate of 1-D data array'''\n",
    "        bs_sample = np.random.choice(data, len(data)) #bootstrap sample needs same number of entries as original data\n",
    "        return func(bs_sample)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5882520",
   "metadata": {},
   "source": [
    "__Many bootstrap replicates:__\n",
    "```bs_replicates = np.empty(10000)\n",
    "for i in range(10000):\n",
    "    bs_replicates[i] = bootstrap_replicate_1d(michelson_speed_of_light, np.mean)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de7bcbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bs_reps(data, func, size=1):\n",
    "    \"\"\"Draw bootstrap replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
    "\n",
    "    return bs_replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ec8bd",
   "metadata": {},
   "source": [
    "### Bootstrap confidence intervals\n",
    "__p% confidence interval of a statistic:__\n",
    "If we repeated measurements over and over again, p% of the observed values would lie within the p% confidence interval.\n",
    "\n",
    "`95_conf_int = np.percentile(bs_replicates, [2.5, 97.5])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2e97a",
   "metadata": {},
   "source": [
    "### Pairs bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e81ab",
   "metadata": {},
   "source": [
    "__Pairs bootstrap for linear regression:__ \\\n",
    "We can perform bootstrap estimates to get the confidence intervals of the slope and intercept of a linear regression model as well.\\\n",
    "In instances where we cannot resample individual data because each observation has two variables associated with it, we resample pairs. \n",
    "\n",
    "For example: voting counties in PA have total number of votes and democratic share of votes attributed to them, so we resample pairs of data (total votes per county with their respective democratic share of votes) together.\n",
    "\n",
    "1) Resample data in pairs.\\\n",
    "2) Compute slope and intercept from resampled data.\\\n",
    "3) Each slope and intercept is a bootstrap replicate.\\\n",
    "4) Compute confidence intervals from percentiles of bootstrap replicates. \n",
    "\n",
    "Because __`np.random.choice()`__ must sample a 1-D array, sample the indices of the data points. \\\n",
    "Generate the indices of a numpy array using __`np.arange(n)`__, which gives us a range of sequential integers, beginning with 0, and ending with n-1.\\\n",
    "The bootstrap sample is generated by slicing out the respective values from the original data arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792b264",
   "metadata": {},
   "source": [
    "__Generating a pairs bootstrap sample:__\n",
    "```inds = np.arange(len(total_votes))\n",
    "bs_inds = np.random.choice(inds, len(inds))\n",
    "bs_total_votes = total_votes[bs_inds]\n",
    "bs_dem_share = dem_share[bs_inds]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbab095",
   "metadata": {},
   "source": [
    "__Computing a pairs bootstrap replicate:__\\\n",
    "```bs_slope, bs_intercept = np.polyfit(bs_total_votes, bs_dem_share, 1)``` \\\n",
    "1 refers to degree of polynomial (1st), ie  we're using a linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bb5b9",
   "metadata": {},
   "source": [
    "__Function for pairs bootstrap:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f15ca9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bs_pairs_linreg(x, y, size=1):\n",
    "    \"\"\"Perform pairs bootstrap for linear regression.\"\"\"\n",
    "\n",
    "    # Set up array of indices to sample from: inds\n",
    "    inds = np.arange(0, len(x))\n",
    "\n",
    "    # Initialize replicates: bs_slope_reps, bs_intercept_reps\n",
    "    bs_slope_reps = np.empty(size)\n",
    "    bs_intercept_reps = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_inds = np.random.choice(inds, size=len(inds))\n",
    "        bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
    "        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x, bs_y, 1)\n",
    "\n",
    "    return bs_slope_reps, bs_intercept_reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add198a9",
   "metadata": {},
   "source": [
    "__Plotting bootstrap regressions:__\n",
    "__```#Generate array of x-values for bootstrap lines: x\n",
    "x = np.array([0,100])```__ #Creates array __x= ([0  100])__\n",
    "\n",
    "__```#Plot the bootstrap lines\n",
    "for i in range(100):\n",
    "    _ = plt.plot(x, \n",
    "                 bs_slope_reps[i]*x + bs_intercept_reps[i],\n",
    "                 linewidth=0.5, alpha=0.2, color='red')```__\n",
    "\n",
    "__```#Plot the data\n",
    "_ = plt.plot(illiteracy, fertility, marker='.', linestyle='none')```__\n",
    "\n",
    "__```#Label axes, set the margins, and show the plot\n",
    "_ = plt.xlabel('illiteracy')\n",
    "_ = plt.ylabel('fertility')\n",
    "plt.margins(0.02)\n",
    "plt.show()```__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1550af",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "How do we assess how reasonable it is that our observed data are actually described by a chosen model? \n",
    "\n",
    "__Hypothesis testing:__ Assessment of how reasonable the observed data are assuming a hypothesis is true.\\\n",
    "__Null hypothesis:__ $H_{0}$; The hypothesis that there is no significant statistical difference between specified popuations, any observed difference being due to sampling or experimental error (\"chance\"). Typically, you will always be testing the $H^{0}$.\n",
    "\n",
    "__Simulating the $H^{0}$__: Simulate what the data would look like if the county level voting trends in the two states were identically distibuted. We do this by:\n",
    "\n",
    "### Permuation\n",
    "1) Putting the democratic share of the vote for all of PA's 67 counties and Ohio's 88 counties together.\\\n",
    "2) Ignore what state each data point belongs to. \\\n",
    "3) Randomly scramble the order.\n",
    "4) Relabel first 67 as \"PA\" and the last 88 as \"Ohio\"\\\n",
    "__*So, essentially, we just redid the election as if there were no difference between PA county votes and OH county votes.*__\n",
    "\n",
    "__Permutation:__ \\\n",
    "Random reordering of array.\n",
    "\n",
    "__Permutation sample:__ \\\n",
    "The permutation, or newly shuffled arrangement assigned to values (`perm_sample_PA`, `perm_sample_OH`, for example).\n",
    "\n",
    "__Permutation replicate:__ \\\n",
    "A single value of a statistic computed from a permutation sample. (Test statistic of permutation sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143c426",
   "metadata": {},
   "source": [
    "### Generating a permutation sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd464416",
   "metadata": {},
   "source": [
    "```#Make a single array with all of the data in it (all counties from both states)\n",
    "#Note that concatenate only accepts a tuple of arrays to concatenate.\n",
    "dem_share_both = np.concatenate((dem_share_PA, dem_share_OH))\n",
    "#Shuffle concatenated array\n",
    "dem_share_perm = np.random.permutation(dem_share_both)\n",
    "#Slice first 67 counties as PA's permuted sample\n",
    "perm_sample_PA = dem_share_perm[:len(dem_share_PA)]\n",
    "#Slice last 88 counties as PA's permuted sample\n",
    "perm_sample_OH = dem_share_perm[len(dem_share_PA):]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3617785",
   "metadata": {},
   "source": [
    "`perm_sample_PA` and `perm_sample_OH` are called __permutation samples.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595caa5",
   "metadata": {},
   "source": [
    "__Generate single permutation sample:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b00467ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "\n",
    "    # Concatenate the data sets: data\n",
    "    data = np.concatenate((data1, data2))\n",
    "\n",
    "    # Permute the concatenated array: permuted_data\n",
    "    permuted_data = np.random.permutation(data)\n",
    "\n",
    "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
    "    perm_sample_1 = permuted_data[:(len(data1))]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "\n",
    "    return perm_sample_1, perm_sample_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12366739",
   "metadata": {},
   "source": [
    "### Generating permutation replicates\n",
    "Below: func *must* be a function that accpts two arrays as arguments. \\\n",
    "In most circumstances, func will be a function you write yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de16598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: perm_replicates\n",
    "    perm_replicates = np.empty(size)\n",
    "\n",
    "    for i in range(size):\n",
    "        # Generate permutation sample\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
    "\n",
    "        # Compute the test statistic\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "\n",
    "    return perm_replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2179f05",
   "metadata": {},
   "source": [
    "__diff_of_means()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99197d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_of_means(data_1, data_2):\n",
    "    \"\"\"Difference in means of two arrays.\"\"\"\n",
    "\n",
    "    # The difference of means of data_1, data_2: diff\n",
    "    diff = np.mean(data_1)- np.mean(data_2)\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de3928d",
   "metadata": {},
   "source": [
    "__p-value__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37978c38",
   "metadata": {},
   "source": [
    "```#Compute difference of mean impact force from experiment: empirical_diff_means\n",
    "empirical_diff_means = diff_of_means(force_a, force_b)\n",
    "#Draw 10,000 permutation replicates: perm_replicates\n",
    "perm_replicates = draw_perm_reps(force_a, force_b,\n",
    "                                 diff_of_means, size=10000)\n",
    "#Compute p-value: p\n",
    "p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc172dd0",
   "metadata": {},
   "source": [
    "## Test statistics and p-values\n",
    "Hypothesis testing: What about the data do we assess and how do we quantify the assessment? Test statistics and p-values (respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156aa2c7",
   "metadata": {},
   "source": [
    "__Test statistic:__ A single number that can be computed from observed data and from data you simulate under the null hypothesis, that serves as a basis of comparison between what the hypothesis predicts and what we actually observe.\n",
    "Example test statistic: difference in means (if hypothesis is correct, difference of difference in means should be 0).\n",
    "\n",
    "__Permutation replicate:__ The value of a test statistic computed from a permutation sample is called a permutation replicate. \\\n",
    "`(np.mean(dem_share_PA) - np.mean(dem_share_OH)) - (np.mean(perm_sample_PA) - np.mean(perm_sample_OH))` \\\n",
    "= difference in votes by state of observed data - difference in votes by state of permuted data\n",
    "\n",
    "__p-value:__ the probability of obtaining a value of your test statistic that is at least as extreme as what was observed, under the assumption the null hypothesis is true. \\\n",
    "When the p-value is small, it is often said that the data are statistically significantly different.\n",
    "\n",
    "__Statistical significance:__ determined by smallness of p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552b968",
   "metadata": {},
   "source": [
    "Pipeline for hypothesis testing: \n",
    "1) Clearly state the null hypothesis \\\n",
    "2) Define test statistic \\\n",
    "3) Generate many sets of simulated data assuming the null hypothesis is true \\\n",
    "4) Compute the test statistic for each simulated data set \\\n",
    "5) The p-value is the fraction of your simulated data sets for which the test statistic is at least as extreme as for the real data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef05e84",
   "metadata": {},
   "source": [
    "__One sample test:__ Compare one set of data to a single number\\\n",
    "__Two sample test:__ Compare two sets of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb78bf",
   "metadata": {},
   "source": [
    "__A/B Testing, diff_frac() function:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4e4082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_frac(data_A, data_B):\n",
    "    frac_A = np.sum(data_A)/ len(data_A)\n",
    "    frac_B = np.sum(data_B)/ len(data_B)\n",
    "    return frac_B - frac_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897cf88",
   "metadata": {},
   "source": [
    "for A/B testing: \\\n",
    "`diff_frac_obs = diff_frac(clickthrough_A, clickthrough_B)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20723312",
   "metadata": {},
   "source": [
    "__Hypothesis test of correlation:__ \\\n",
    "1) Posit null hypothesis: the two variables are completely uncorrelated.\\\n",
    "2) Simulate data assuming null hypothesis is true.\\\n",
    "3) Use Pearson correlation coefficient, $\\rho$, as test statistic.\\\n",
    "4) Compute p-value as fraction of replicates that have $\\rho$ at least as large as observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee8da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1796f5c1",
   "metadata": {},
   "source": [
    "## Plots:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e90c6",
   "metadata": {},
   "source": [
    "### Bee swarm plot:\n",
    "`sns.swarmplot()` \\\n",
    "`sns.swarmplot(x)` \\\n",
    "`sns.swarmplot(x, y, data)` \n",
    "\n",
    "`sns.swarmplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, dodge=False, orient=None, color=None, palette=None, size=5, edgecolor='gray', linewidth=0, ax=None, **kwargs)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99264ac8",
   "metadata": {},
   "source": [
    "## Other:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53380a0a",
   "metadata": {},
   "source": [
    "__`np.arange()`__ \\\n",
    "`([start, ]stop, [step, ]dtype=None, *, like=None)` \\\n",
    "Create an np array of range (n) \\\n",
    "`np.arange(7)` \\\n",
    "creates: `array([ 0 1 2 3 4 5 6 ])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3872c2",
   "metadata": {},
   "source": [
    "__`np.empty()`__ \\\n",
    "`(shape, dtype=float, order='C', *, like=None)` \\\n",
    "Create an empty np array of shape ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597392df",
   "metadata": {},
   "source": [
    "__`np.empty_like()`__ returns a new array with the same shape and type as a given array (which you provide as an argument). \\\n",
    "`rss = np.empty_like(a_vals)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c37d1",
   "metadata": {},
   "source": [
    "__`np.concatenate()`__ \\\n",
    "`((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")` \\\n",
    "Concatenate arrays to perform permutation when testing null hypothesis. \\\n",
    "__Note:__ Only accepts a *tuple* of values to concatenate (note extra parentheses)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a72cc",
   "metadata": {},
   "source": [
    "__`np.random.permutation(x)`__ \\\n",
    "Randomly permute a sequence, or return a permuted range.\\\n",
    "If *x* is a multi-dimensional array, it is only shuffled along its first index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c4b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa7ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284985cb",
   "metadata": {},
   "source": [
    "__Nonparametric inference:__ \\\n",
    "Makes no assumptions about the model or probability distribution underlying the data. Estimates/summary statistics are computed using data alone (and no underlying/assumed models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828d7a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd550a87",
   "metadata": {},
   "source": [
    "## Exponential + half tau + 2x tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6d510",
   "metadata": {},
   "source": [
    "`#Create an ECDF from real data: x, y` \\\n",
    "`x, y = ecdf(nohitter_times)` \n",
    "\n",
    "`#Create a CDF from theoretical samples: x_theor, y_theor`\\\n",
    "`x_theor, y_theor = ecdf(inter_nohitter_time)`\n",
    "\n",
    "`#Take samples with half tau: samples_half`\\\n",
    "`samples_half = np.random.exponential(tau/2, 10000)`\n",
    "\n",
    "`#Take samples with double tau: samples_double`\\\n",
    "`samples_double = np.random.exponential(2*tau, 10000)`\n",
    "\n",
    "`#Generate CDFs from these samples`\\\n",
    "`x_half, y_half = ecdf(samples_half)`\\\n",
    "`x_double, y_double = ecdf(samples_double)`\n",
    "\n",
    "`#Plot these CDFs as lines`\\\n",
    "`_ = plt.plot(x_half, y_half)`\\\n",
    "`_ = plt.plot(x_double, y_double)`\n",
    "\n",
    "`#Overlay the plots`\\\n",
    "`plt.plot(x_theor, y_theor)`\\\n",
    "`plt.plot(x, y, marker='.', linestyle='none')`\n",
    "\n",
    "`#Margins and axis labels`\\\n",
    "`plt.margins(0.02)`\\\n",
    "`plt.xlabel('Games between no-hitters')`\\\n",
    "`plt.ylabel('CDF')`\n",
    "\n",
    "`plt.show()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d54bb",
   "metadata": {},
   "source": [
    "__Simulating coin flips__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_all_heads = 0 \n",
    "for i in range(10000): \n",
    "    heads = np.random.random(size=4) < 0.5\n",
    "    n_heads = np.sum(heads)\n",
    "    if n_heads == 4:\n",
    "        n_all_heads += 1\n",
    "n_all_heads/10000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
