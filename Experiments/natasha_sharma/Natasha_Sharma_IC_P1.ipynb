{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f4ee74",
   "metadata": {},
   "source": [
    "# Natasha Sharma: Image Classification Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebf682",
   "metadata": {},
   "outputs": [],
   "source": [
    "data ='data/flowers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b44f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train=[]\n",
    "image_labels=[]\n",
    "image_names=[]\n",
    "size=224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ba826",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    for each in os.listdir(os.path.join(data, folder)):\n",
    "        if each.endswith('jpg'):\n",
    "            image_names.append(os.path.join(data,folder,each))\n",
    "            image_labels.append(folder)\n",
    "            img=cv2.imread(os.path.join(data,folder,each))\n",
    "            img_in=cv2.resize(img,size)\n",
    "            image_train.append(img_in)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c548f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for folder in folders:\n",
    "    for each in os.listdir(os.path.join(data, folder)):\n",
    "        test.append('1')\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd626a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(folders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee828104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0167e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model=tf.keras.applications.vgg16.VGG16(include_top= False,\n",
    "                                          input_shape= (64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7613fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639df1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf803a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model=tf.keras.applications.vgg16.VGG16(include_top= False,\n",
    "                                             input_shape= (64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b08573",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "for layers in vgg16_model.layers:\n",
    "    model.add(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation='relu'))\n",
    "model.add(Dense(4096,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9856f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "   layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5,activation='softmax'))\n",
    "optimizer=RMSprop(learning_rate=0.001,rho=0.9,epsilon=1e-08,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,minlr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e707845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894dd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, \n",
    "                   decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0fb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer, \n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a7e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965aa754",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            minlr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7971479",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit((X_train,Y_train,batch_size=10),epochs=5,validation_data=(X_val,Y_val),verbose=1,steps_per_epoch=X_train.shape[0]/10,callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7939bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4848ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense,Flatten, \n",
    "                                            GlobalAveragePooling2D)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd99217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ResNet50(include_top=False, pooling='avg', input_shape=(224,224,3),weights='imagenet'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc6f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    for each in os.listdir(os.path.join(data, folder)):\n",
    "        if each.endswith('jpg'):\n",
    "            image_names.append(os.path.join(data,folder,each))\n",
    "            image_labels.append(folder)\n",
    "            img=cv2.imread(os.path.join(data,folder,each))\n",
    "            img_in=cv2.resize(img,size)\n",
    "            image_train.append(img_in)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff36e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10, \n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035cdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c9f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f8eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce41dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model=tf.keras.applications.InceptionV3(include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd721fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in inception_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inception_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dense(5, activation='softmax')(x)\n",
    "model = tf.keras.models.Model(inception_model.input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=RMSprop(learning_rate=0.001,rho=0.9,epsilon=1e-08,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd75d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7566ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in inception_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2cff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a5fd6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'efficientnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mefn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'efficientnet'"
     ]
    }
   ],
   "source": [
    "import efficientnet.keras as efn\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9debc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = efn.EfficientNetB6(input_shape = (224, 224, 3), include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e14de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(datagen.flow(X_train, Y_train,batch_size= 24),\n",
    "                  epochs= 5,\n",
    "                  validation_data= (X_val, Y_val),\n",
    "                  verbose= 1,\n",
    "                  steps_per_epoch= 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
