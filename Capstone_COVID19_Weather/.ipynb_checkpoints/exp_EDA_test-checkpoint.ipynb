{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bdb2b8d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5683f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ppscore\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab50b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe created in data wrangling phase\n",
    "# Parse datetime column and make index\n",
    "df= pd.read_csv('cleaned_cov_weather4.csv', parse_dates=['date'], index_col ='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd53ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated DateTimeIndices\n",
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated DateTimeIndices (but keep first instances of indices)\n",
    "# Check to confirm duplicated indices have been removed \n",
    "df = df[~df.index.duplicated(keep='first')]\n",
    "df[df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437397b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# double check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int columns to float in preparation for calculations:\n",
    "int_columns= {\"CT_conf_cases\": 'float', \"ME_conf_cases\": 'float', \"MA_conf_cases\":\"float\", \"VT_conf_cases\":'float', \"vt_avg_temp\":'float', \"vt_prcp\":'float'}\n",
    "df = df.astype(int_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb017ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669aa3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Any missing values?\n",
    "df[pd.isnull(df).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062e9bc",
   "metadata": {},
   "source": [
    "No missing values.\n",
    "\n",
    "However, the units of TAVG and PRCP are clearly off. \n",
    "\n",
    "According to [NOAA documentation](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt), temperatures are reported in __*tenths*__ of a degree Celsius. I'll convert to degrees Fahrenheit instead (since this is US data here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (C*9/50)+32=F (since C is reported here as tenths of degrees)\n",
    "df2=df\n",
    "df2['vt_avg_temp'] = ((df['vt_avg_temp']*9)/50) + 32\n",
    "df2['me_avg_temp'] = ((df['me_avg_temp']*9)/50) + 32\n",
    "df2['ct_avg_temp'] = ((df['ct_avg_temp']*9)/50) + 32\n",
    "df2['ma_avg_temp'] = ((df['ma_avg_temp']*9)/50) + 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0afea",
   "metadata": {},
   "source": [
    "The [same documention](https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt) cited above also explains that PRCP data is reported in __*tenths*__ of a mm. [Wikipedia](https://en.wikipedia.org/wiki/Precipitation) reports that generally PRCP data is reported in millimeters, so I'll convert to millimeters instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2\n",
    "df3['vt_prcp'] = df2['vt_prcp']/10\n",
    "df3['me_prcp'] = df2['me_prcp']/10\n",
    "df3['ct_prcp'] = df2['ct_prcp']/10\n",
    "df3['ma_prcp'] = df2['ma_prcp']/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72516f9f",
   "metadata": {},
   "source": [
    "For the sake of clarity, I'll update column names to reflect this unit change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update column names to reflect new units:\n",
    "units_dict= {'vt_avg_temp': 'VT_Avg_Temp(F)', 'vt_prcp': 'VT_PRCP(mm)', 'me_avg_temp':'ME_Avg_Temp(F)', 'me_prcp': 'ME_PRCP(mm)', 'ct_avg_temp': 'CT_Avg_Temp(F)', 'ct_prcp':'CT_PRCP(mm)', 'ma_avg_temp': 'MA_Avg_Temp(F)', 'ma_prcp':'MA_PRCP(mm)'}\n",
    "df3.rename(columns=units_dict, inplace=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f385308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine timespan of data:\n",
    "print('Beginning date: ',min(df3.index))\n",
    "print('End date: ', max(df3.index))\n",
    "print('Total timespan: ', max(df3.index-min(df3.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22587bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of df \n",
    "df4=df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16199494",
   "metadata": {},
   "source": [
    "The confirmed cases column represented total number of cumulative new COVID cases per date. To explore new infection *rates* over time, rather than cumulative COVID cases, we'll have to take the first differences of the cumulative counts. There shouldn't be any `NaN`s left, but just in case, we'll chain the `.fillna()` method to the end of our first differences calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column of non-cumulative counts of confirmed cases for each state:\n",
    "df4[\"CT_Conf_Cases\"] = df4['CT_conf_cases'].diff().fillna(0)\n",
    "df4[\"VT_Conf_Cases\"] = df4['VT_conf_cases'].diff().fillna(0)\n",
    "df4[\"ME_Conf_Cases\"] = df4['ME_conf_cases'].diff().fillna(0)\n",
    "df4[\"MA_Conf_Cases\"] = df4['MA_conf_cases'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop cumulative confirmed case columns:\n",
    "df5 = df4.drop(columns=['CT_conf_cases', 'VT_conf_cases', 'ME_conf_cases', 'MA_conf_cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c28d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take a look at some summary statistics of the data:\n",
    "# First, we'll define a function to highlight any negative values (as we can't have negative new COVID case values)\n",
    "def highlight_neg(cell):\n",
    "    if cell < 0 :\n",
    "        return 'background: yellow'  \n",
    "df5.describe().style.applymap(highlight_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440322fb",
   "metadata": {},
   "source": [
    "The negative value in `ME_Avg_Temp(F)` column is fine, however it looks like some of the states have `Conf_Cases` values that are less than zero. That can't be right; this needs to be looked into. Let's first see how many negative values are in each state's confirmed case counts and how large or small the values are. These will be considerations when we decide how to best address them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_neg = df5[df5['CT_Conf_Cases']<0]\n",
    "print(\"CT has\", len(CT_neg), \"negative case value(s):\")\n",
    "print(CT_neg.CT_Conf_Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_neg = df5[df5['VT_Conf_Cases']<0]\n",
    "print(\"VT has\", len(VT_neg), \"negative case value(s):\")\n",
    "print(VT_neg.VT_Conf_Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_neg = df5[df5['ME_Conf_Cases']<0]\n",
    "print(\"ME has\", len(ME_neg), \"negative case value(s):\")\n",
    "print(ME_neg.ME_Conf_Cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d46fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_neg = df5[df5['MA_Conf_Cases']<0]\n",
    "print(\"MA has\", len(MA_neg), \"negative case value(s):\")\n",
    "print(MA_neg.MA_Conf_Cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33ea9b",
   "metadata": {},
   "source": [
    "Connecticut has two negative case counts, Vermont also has two negative case counts, Maine has four negative case counts, and Massachusetts has one negative case count (for a total of 9 negative case counts). Thankfully we don't have *a lot* of these erroneous counts, but before blindly filling them all with zeroes, let's check to see what the case counts around these dates look like. If they're very low, we may be able to fill the negative values with zeroes without much impact. If these values occur during a surge, however, we may need to look a little deeper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd64488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print day before and after each negative case value in CT:\n",
    "ct_neg_df = pd.DataFrame(pd.concat([df5['2020-05-26':'2020-05-28'].CT_Conf_Cases, \n",
    "                                    df5['2020-08-17':'2020-08-19'].CT_Conf_Cases]))\n",
    "ct_neg_df.style.applymap(highlight_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print day before and after each negative case value in VT:\n",
    "vt_neg_df = pd.DataFrame(pd.concat([df5['2020-05-10':'2020-05-12'].VT_Conf_Cases, \n",
    "                                    df5['2020-06-16':'2020-06-18'].VT_Conf_Cases]))\n",
    "vt_neg_df.style.applymap(highlight_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a022dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print day before and after each negative case value in ME:\n",
    "me_neg_df = pd.DataFrame(pd.concat([df5['2020-03-14':'2020-03-16'].ME_Conf_Cases, \n",
    "                                    df5['2020-07-21':'2020-07-23'].ME_Conf_Cases, \n",
    "                                    df5['2020-09-08':'2020-09-10'].ME_Conf_Cases, \n",
    "                                    df5['2021-08-08':'2021-08-10'].ME_Conf_Cases]))\n",
    "me_neg_df.style.applymap(highlight_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8957f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print day before and after each negative case value in MA:\n",
    "ma_neg_df = pd.DataFrame(pd.concat([df5['2020-09-02':'2020-09-04'].MA_Conf_Cases]))\n",
    "ma_neg_df.style.applymap(highlight_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ba470e",
   "metadata": {},
   "source": [
    "If Vermont was the only state with negative case counts, it may be alright to fill negative case counts with zeroes, but all other states would likely be adversely affected by this. For example, Massachusetts has a case count value of -280, between dates with case counts of positive 404 and 212. Maine, too, has a value of -1 right before a value of 361 cases (which is a large case count for this less-populous state). Therefore, let's replace these negative case count values with the average of the case counts of the date before and after them. To do this, we'll first convert the negative values to `NaN`s, and then we'll use the `.fillna()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdff397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace cases negative values with np.nan\n",
    "df5.MA_Conf_Cases['2020-09-03'] = np.nan\n",
    "df5.CT_Conf_Cases[['2020-05-27', '2020-08-18']] = np.nan\n",
    "df5.VT_Conf_Cases[['2020-05-11', '2020-06-17']] = np.nan\n",
    "df5.ME_Conf_Cases[['2020-03-15','2020-07-22', '2020-09-09', '2021-08-09']]= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through NaNs and fill with average of previous and following cell values \n",
    "state_col_list=['CT_Conf_Cases', 'VT_Conf_Cases', 'ME_Conf_Cases', 'MA_Conf_Cases']\n",
    "for col in state_col_list:\n",
    "    df5[col] = df5[col].fillna((df5[col].shift() + df5[col].shift(-1))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819240bd",
   "metadata": {},
   "source": [
    "Now all of the negative case values should have been replaced with the average of the value preceding and following it. Let's double check the summary statistics of the full DataFrame just to make sure everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a80497",
   "metadata": {},
   "outputs": [],
   "source": [
    " df5.describe().style.applymap(highlight_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8730f",
   "metadata": {},
   "source": [
    "Now there are no more negative COVID case counts in the DataFrame; the only negative values belong to an average temperature column (which makes sense- Maine gets pretty cold in the winter!).\n",
    "\n",
    "A quick look at the tail of the DataFrame reveals another interesting detail, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to highlight zero values (which may be indicative of missing values)\n",
    "def highlight_zero(cell):\n",
    "    if cell == 0:\n",
    "        return 'background: yellow'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(df5['CT_Conf_Cases'].tail(25))).style.applymap(highlight_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf289010",
   "metadata": {},
   "source": [
    "Zeroes are sometimes, but not always, indicative of missing values. We would probably expect a certain proportion of zero values for confirmed cases in a dataset like ours, but the above highlighted values follow a pretty clear pattern (which is suspicious). For every five days of values for `Conf_Cases`, there are two days of zero values. It seems that values have not been recorded for weekends dates in Connecticut, and a quick calendar check confirms the above highlighted zero values all correspond to weekend dates. But what about Monday 2021-09-06? The calendar shows that this was [Labor Day](https://www.officeholidays.com/countries/usa/2021), a bank holiday in the US.\n",
    "\n",
    "\n",
    "Let's check if the other states follow Connecticut's case reporting schedule, or some other schedule entirely. Before we do that, though, let's add a column, `weekday`, indicating the day of the week for each row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ab3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6= df5\n",
    "# Add a weekday column\n",
    "df6[\"weekday\"] = df5.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1420ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare all states' missing value patterns\n",
    "(pd.DataFrame(df5[['CT_Conf_Cases', 'MA_Conf_Cases', 'ME_Conf_Cases', \n",
    "                            'VT_Conf_Cases', 'weekday']].tail(25)).style.applymap(highlight_zero))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e42f4",
   "metadata": {},
   "source": [
    "From the above data, it looks like Massachusetts and Connecticut may have similar Monday-Friday reporting schedules. It also seems that Maine may report cases Tuesday-Saturday and Vermont may report cases seven days a week (at least for these last 25 rows). Three out of four of the states also reported zero values for 2021-09-06 (a Monday) which we've already determined was a US bank holiday. Notably, Vermont did report cases on this date however.\n",
    "\n",
    "It's clear that each state's reporting schedule varies, and also that there may be some unsual exceptions to these schedules (like bank holidays) for some states. Clearly we'll need to investigate each state's individual reporting schedule more closely. We may get a better idea of the overall distribution and pattern of these zero values by representing them visually. \n",
    "\n",
    "Below I plot each state's daily new confirmed case counts. In the plots for Massachusetts, Connecticut, and Vermont, there is an orange vertical line for every zero value that falls on a Saturday, a red vertical line for every zero value that falls on a Sunday, and a green vertical line for every zero value that falls on any day of the week other than Saturday or Sunday.\n",
    "\n",
    "Because Maine seems to follow a different schedule, I've placed a red vertical line for every zero count that falls on *Sunday*, an orange vertical line for every zero value that falls on a *Monday*, and a green vertical line for every zero value that falls on any day of the week other than Sunday or Monday.\n",
    "\n",
    "By plotting the orange and red lines, we'll be able to check our hypothesis regarding each state's reporting schedule. By plotting the green lines, we'll be able to double check for any unusual cases of zero values that do not fit within our hypothesized reporting schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7528147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6\n",
    "sunday_ind_me=(df7[(df7.weekday == 6)&(df7.ME_Conf_Cases==0)& (df7.index >'2020-01-29')]).index # Sunday zero values\n",
    "monday_ind_me=(df7[(df7.weekday == 0)&(df7.ME_Conf_Cases==0)&(df7.index>'2020-01-29')]).index # Monday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_me=(df7[(df7.weekday != 0)& (df7.weekday != 6)&(df7.ME_Conf_Cases==0)& (df7.index >'2020-01-29')]).index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254af99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(18,8)})\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df7.index, df7['ME_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Maine COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_me:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in monday_ind_me:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_me:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Maine COV cases', fontsize=20)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4832b",
   "metadata": {},
   "source": [
    "It seems that (with a few individual exceptions), Maine actually reported new case counts every day of the week until around July of 2021. This means that **we'll only need to address Sunday-Monday zero case counts for Maine from July of 2021 onwards.** We can also look into the few exceptions (green lines) that occur prior to July, 2021, and check for bank holidays. We can also see that Maine did not report its first COVID case until March of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_ma=(df7[(df7.weekday == 6)&(df7.MA_Conf_Cases==0)& (df7.index >'2020-01-29')]).index # Sunday zero values\n",
    "saturday_ind_ma=(df7[(df7.weekday == 5)&(df7.MA_Conf_Cases==0)&(df7.index>'2020-01-29')]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_ma=(df7[(df7.weekday != 5)& (df7.weekday != 6)&(df7.MA_Conf_Cases==0)& (df7.index >'2020-01-29')]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e23e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df7.index, df7['MA_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Massachusetts COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_ma:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_ma:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_ma:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Massachusetts COV cases', fontsize=20)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78676145",
   "metadata": {},
   "source": [
    "It looks like Massachusetts was also reporting case counts daily (seven days a week) until around July of 2021 (when it switched to a Monday-Friday reporting schedule). We can also examine the few exceptions (green lines) for Massachusetts, but it looks like **we'll only need to examine Saturday-Sunday zero case values for Massachusetts from July, 2021 onwards** also. We can see that Massachusetts hasn't reported any significant case values until around March of 2020 either. We may want to further slice our data to begin in March, 2020 to avoid skewing our data with these zero values, but let's first check the Connecticut and Vermont case counts to make sure we aren't dropping any useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d115360",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_ct=(df7[(df7.weekday == 6)&(df7.CT_Conf_Cases==0)& (df7.index >'2020-01-29')]).index # Sunday zero values\n",
    "saturday_ind_ct=(df7[(df7.weekday == 5)&(df7.CT_Conf_Cases==0)&(df7.index>'2020-01-29')]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_ct=(df7[(df7.weekday != 5)& (df7.weekday != 6)&(df7.CT_Conf_Cases==0)& (df7.index >'2020-01-29')]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee6c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df7.index, df7['CT_Conf_Cases'],  color = 'blue')\n",
    "    ax.set_ylabel('Connecticut COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_ct:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_ct:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_ct:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Connecticut COV cases', fontsize=20)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8fba7",
   "metadata": {},
   "source": [
    "Connecticut clearly has a very different reporting schedule than Massachusetts and Maine. It looks like Connecticut only reported case counts seven days a week until around July of *2020*. **We'll need to address Saturday-Sunday zero value counts for Connecticut from July, *2020* onwards.** Connecticut also seems to have reported its first COVID case sometime in March of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b09cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_vt=(df7[(df7.weekday == 6)&(df7.VT_Conf_Cases==0)& (df7.index >'2020-01-29')]).index # Sunday zero values\n",
    "saturday_ind_vt=(df7[(df7.weekday == 5)&(df7.VT_Conf_Cases==0)&(df7.index>'2020-01-29')]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_vt=(df7[(df7.weekday != 5)& (df7.weekday != 6)&(df7.VT_Conf_Cases==0)& (df7.index >'2020-01-29')]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615783c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df7.index, df7['VT_Conf_Cases'],  color = 'blue')\n",
    "    ax.set_ylabel('Vermont COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_vt:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_vt:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_vt:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Vermont COV cases', fontsize=16)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795906be",
   "metadata": {},
   "source": [
    "Vermont seems only to have followed a Monday-Friday reporting schedule for about 2-3 months, from around June of 2021 until August 2021, before reverting back to daily reporting. **We'll need to address Saturday-Sunday zero case values for Vermont from June 2021- August 2021.** Vermont also didn't report its first COVID case until sometime in March of 2020.\n",
    "\n",
    "It seems pretty clear that we can cut all data prior to March 2020 as we only have 1 non-zero value count (from Massachusetts) prior to March, and so the repetetive zero values from this period can only serve to skew our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3af23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut data from before March of 2020\n",
    "df8=df7.loc['2020-03-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d4752",
   "metadata": {},
   "source": [
    "Let's check out how one of the plots looks after the slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ccc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_vt=(df8[(df8.weekday == 6)&(df8.VT_Conf_Cases==0)& (df8.index >'2020-01-29')]).index # Sunday zero values\n",
    "saturday_ind_vt=(df8[(df8.weekday == 5)&(df8.VT_Conf_Cases==0)&(df8.index>'2020-01-29')]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_vt=(df8[(df8.weekday != 5)& (df8.weekday != 6)&(df8.VT_Conf_Cases==0)& (df8.index >'2020-01-29')]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0687e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df8.index, df8['VT_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Vermont COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_vt:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_vt:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_vt:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Vermont COV cases', fontsize=16)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0063b93",
   "metadata": {},
   "source": [
    "This looks a lot better! \n",
    "\n",
    "Now we'll need to address each state's unique reporting schedule. \n",
    "By examining each state governments' webpages (see here: [Maine](https://www.maine.gov/dhhs/mecdc/infectious-disease/epi/airborne/coronavirus/data.shtml), [Massachusetts](https://www.mass.gov/info-details/covid-19-response-reporting), [Vermont](https://www.healthvermont.gov/covid-19), [Connecticut](https://portal.ct.gov/coronavirus/covid-19-data-tracker)), we can confirm the apparent trends in the plots above. From [this Associated Press article](https://apnews.com/article/health-coronavirus-pandemic-vermont-c781aa063d30e8f665500deaf8902ab9) we can also confirm that Vermont resumed daily case reporting on 2021-08-23 (due to a surge in cases).\n",
    "\n",
    "More simply, each state reported cases daily, besides the following periods (and a few select bank holidays):\n",
    "\n",
    "* **Maine** reported cases **Tuesday-Saturday** from **2021-07-01 onwards**.\n",
    "* **Massachusetts** reported cases **Monday-Friday** from **2021-07-01 onwards**.\n",
    "* **Connecticut** reported cases **Monday-Friday** from **2020-07-01 onwards**.\n",
    "* **Vermont** reported cases **Monday-Friday** from **2021-06-01 to 2021-08-23**.\n",
    "\n",
    "The above hyperlinked resources also describe that each state reports a cumulative total of new cases on the day following a two-day break in reporting. For Massachusetts, Connecticut, and Vermont, this would be Monday. For Maine this would be Tuesday. The resources also indicate that if the day following a two-day break in reporting (either Monday or Tuesday) is a bank holiday, then a cumulative case count for the *three* prior days will be reported on the day following the bank holiday (for Massachusetts, Connecticut, and Vermont, this would be Tuesday, and for Maine, this would be Wednesday).\n",
    "\n",
    "Now that we've more clearly defined each state's reporting schedules, let's address the zero values. Because we know that each state reports a *cumulative total* the day following a break in reporting, we can divide this cumulative count by three and replace each of the three days' values with a third of the cumulative value for those days. Before doing so, we'll have to check to make sure none of these days fall on a bank holiday, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e8068",
   "metadata": {},
   "source": [
    "Let's quickly plot the distribution of cases per weekday before we make any changes, so we can compare with the distributions after we've updated the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplot of distribution of cases per weekday\n",
    "#plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "weekdays =['Mon', 'Tue', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\n",
    "weekday_nums = [0, 1, 2, 3, 4, 5, 6]\n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, axes = plt.subplots(2,2, sharex=True, figsize=(16,12))\n",
    "    fig.suptitle('Distribution of case counts per weekday', fontsize=20)\n",
    "    # Set suptitle and subtitles\n",
    "    axes[0,0].set_title('Massachusetts', fontsize=16)\n",
    "    axes[0,1].set_title('Connecticut', fontsize =16)\n",
    "    axes[1,0].set_title('Vermont', fontsize= 16)\n",
    "    axes[1,1].set_title('Maine', fontsize= 16)\n",
    "    #Maine\n",
    "    sns.boxplot(ax=axes[0, 0], data=df8, x='weekday', y='MA_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    #Connecticut\n",
    "    sns.boxplot(ax=axes[0, 1], data=df8, x='weekday', y='CT_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    # Vermont\n",
    "    sns.boxplot(ax=axes[1, 0], data=df8, x='weekday', y='VT_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    #Massachusetts\n",
    "    sns.boxplot(ax=axes[1, 1], data=df8, x='weekday', y='ME_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19464d",
   "metadata": {},
   "source": [
    "## Maine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b9840",
   "metadata": {},
   "source": [
    "For Maine, we'll first check each confirmed case count occurring on or after 2021-07-01, on a Tuesday, that does not have a zero case count (so must not be a bank holiday on which cases were not reported), and create a column `ME_third` with a third of that value. We'll replace the original cumulative Tuesday value with one third of itself. Then we'll add 3 more columns representing lag-1, lag-2, and lag-3 of `ME_third`. We'll replace Monday zero values with lag-1 of `ME_third`, Sunday zero values with lag-2 of `ME_third`, and so on. Once this is complete we *should* only be left with missing values for non-reporting days that were part of a long weekend (bank holiday Tuesday, in the case of Maine). We'll then need to calculate using the returning Wednesday's value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d14cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9.at['2021-09-12','ME_Conf_Cases'] = x\n",
    "#df9.loc[:, 'ME_Conf_Cases'][index] = df9.loc[:, 'ME_third'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beced38e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df9['ME_third'] = round(df9['ME_Conf_Cases']/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "me_lags = {'me_lag_1': -1, 'me_lag_2': -2, 'me_lag_3': -3}\n",
    "for key, value in me_lags.items():\n",
    "    df9[key] = df9['ME_third'].shift(value, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccdcba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==1) & (row['ME_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'ME_Conf_Cases'] = df9.at[index, 'ME_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d16b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==0) & (row['ME_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'ME_Conf_Cases'] = df9.at[index, 'me_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2537090",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==6) & (row['ME_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'ME_Conf_Cases'] = df9.at[index, 'me_lag_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0068b",
   "metadata": {},
   "source": [
    "Now let's address any long weekends where Tuesday was a bank holiday by taking a third of that week's Wednesday case count and replacing Monday, Tuesday, and Wednesday's count with that value instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb12133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df9.drop(['ME_third', 'me_lag_1', 'me_lag_2', 'me_lag_3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e09fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==2) & (row['ME_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'ME_Conf_Cases'] = df9.at[index, 'ME_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53134a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==1) & (row['ME_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'ME_Conf_Cases'] = df9.at[index, 'me_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a720a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==0) & (row['ME_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'ME_Conf_Cases'] = df9.at[index, 'me_lag_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf7765",
   "metadata": {},
   "source": [
    "Now let's check out a plot of Maine's updated case counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acdd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_me=(df9[(df9.weekday == 6)&(df9.ME_Conf_Cases==0)]).index # Sunday zero values\n",
    "monday_ind_me=(df9[(df9.weekday == 0)&(df9.ME_Conf_Cases==0)]).index # Monday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_me=(df9[(df9.weekday != 0)& (df9.weekday != 6)&(df9.ME_Conf_Cases==0)]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(18,8)})\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df9.index, df9['ME_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Maine COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_me:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in monday_ind_me:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_me:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Maine COV cases', fontsize=20)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9febf68",
   "metadata": {},
   "source": [
    "## Connecticut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b595d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of Maine-specific columns\n",
    "df9 = df9.drop(['ME_third', 'me_lag_1', 'me_lag_2', 'me_lag_3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Connecticut-specific columns\n",
    "# CT_third\n",
    "df9['CT_third'] = round(df9['CT_Conf_Cases']/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374567d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_lags\n",
    "ct_lags = {'ct_lag_1': -1, 'ct_lag_2': -2, 'ct_lag_3': -3}\n",
    "for key, value in ct_lags.items():\n",
    "    df9[key] = df9['CT_third'].shift(value, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2020-07-01')) & (row['weekday']==0) & (row['CT_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'CT_Conf_Cases'] = df9.at[index, 'CT_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d62c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2020-07-01')) & (row['weekday']==6) & (row['CT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'CT_Conf_Cases'] = df9.at[index, 'ct_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e152b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2020-07-01')) & (row['weekday']==5) & (row['CT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'CT_Conf_Cases'] = df9.at[index, 'ct_lag_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e095ba4c",
   "metadata": {},
   "source": [
    "Now let's address any long weekends where Monday was a bank holiday by taking a third of that week's Tuesday case count and replacing Saturday, Sunday, and Monday count with that value instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2020-07-01')) & (row['weekday']==1) & (row['CT_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'CT_Conf_Cases'] = df9.at[index, 'CT_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2020-07-01')) & (row['weekday']==0) & (row['CT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'CT_Conf_Cases'] = df9.at[index, 'ct_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2020-07-01')) & (row['weekday']==6) & (row['CT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'CT_Conf_Cases'] = df9.at[index, 'ct_lag_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be244208",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2020-07-01')) & (row['weekday']==5) & (row['CT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'CT_Conf_Cases'] = df9.at[index, 'ct_lag_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_ct=(df9[(df9.weekday == 6)&(df9.CT_Conf_Cases==0)]).index # Sunday zero values\n",
    "saturday_ind_ct=(df9[(df9.weekday == 5)&(df9.CT_Conf_Cases==0)]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_ct=(df9[(df9.weekday != 5)& (df9.weekday != 6)&(df9.CT_Conf_Cases==0)]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ed5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df9.index, df9['CT_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Connecticut COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_ct:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_ct:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_ct:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Connecticut COV cases', fontsize=20)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9850388",
   "metadata": {},
   "source": [
    "## Vermont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of Connecticut-specific columns\n",
    "df9 = df9.drop(['CT_third', 'ct_lag_1', 'ct_lag_2', 'ct_lag_3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vermont-specific columns\n",
    "# VT_third\n",
    "df9['VT_third'] = round(df9['VT_Conf_Cases']/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vt_lags\n",
    "vt_lags = {'vt_lag_1': -1, 'vt_lag_2': -2, 'vt_lag_3': -3}\n",
    "for key, value in vt_lags.items():\n",
    "    df9[key] = df9['VT_third'].shift(value, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index >=pd.Timestamp('2021-06-01')) & (index <=pd.Timestamp('2021-08-24')) & (row['weekday']==0) & (row['VT_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'VT_Conf_Cases'] = df9.at[index, 'VT_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffde03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index >=pd.Timestamp('2021-06-01')) & (index <=pd.Timestamp('2021-08-24'))& (row['weekday']==6) & (row['VT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'VT_Conf_Cases'] = df9.at[index, 'vt_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941af35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index >=pd.Timestamp('2021-06-01')) & (index <=pd.Timestamp('2021-08-24')) & (row['weekday']==5) & (row['VT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'VT_Conf_Cases'] = df9.at[index, 'vt_lag_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c6e40",
   "metadata": {},
   "source": [
    "Now let's address any long weekends where Monday was a bank holiday by taking a third of that week's Tuesday case count and replacing Saturday, Sunday, and Monday count with that value instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e898c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index >=pd.Timestamp('2021-06-01')) & (index <=pd.Timestamp('2021-08-24')) & (row['weekday']==1) & (row['VT_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'VT_Conf_Cases'] = df9.at[index, 'VT_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index >=pd.Timestamp('2021-06-01')) & (index <=pd.Timestamp('2021-08-24')) & (row['weekday']==0) & (row['VT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'VT_Conf_Cases'] = df9.at[index, 'vt_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index >=pd.Timestamp('2021-06-01')) & (index <=pd.Timestamp('2021-08-24')) & (row['weekday']==6) & (row['VT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'VT_Conf_Cases'] = df9.at[index, 'vt_lag_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7938ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index >=pd.Timestamp('2021-06-01')) & (index <=pd.Timestamp('2021-08-24')) & (row['weekday']==5) & (row['VT_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'VT_Conf_Cases'] = df9.at[index, 'vt_lag_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_vt=(df9[(df9.weekday == 6)&(df9.VT_Conf_Cases==0)]).index # Sunday zero values\n",
    "saturday_ind_vt=(df9[(df9.weekday == 5)&(df9.VT_Conf_Cases==0)]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_vt=(df9[(df9.weekday != 5)& (df9.weekday != 6)&(df9.VT_Conf_Cases==0)]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df9.index, df9['VT_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Vermont COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_vt:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_vt:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_vt:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Vermont COV cases', fontsize=16)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c414354",
   "metadata": {},
   "source": [
    "## Massachusetts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of Vermont-specific columns\n",
    "df9 = df9.drop(['VT_third', 'vt_lag_1', 'vt_lag_2', 'vt_lag_3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a99c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Massachusetts-specific columns\n",
    "# MA_third\n",
    "df9['MA_third'] = round(df9['MA_Conf_Cases']/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab170557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_lags\n",
    "ma_lags = {'ma_lag_1': -1, 'ma_lag_2': -2, 'ma_lag_3': -3}\n",
    "for key, value in ma_lags.items():\n",
    "    df9[key] = df9['MA_third'].shift(value, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21063964",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==0) & (row['MA_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'MA_Conf_Cases'] = df9.at[index, 'MA_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==6) & (row['MA_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'MA_Conf_Cases'] = df9.at[index, 'ma_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==5) & (row['MA_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'MA_Conf_Cases'] = df9.at[index, 'ma_lag_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89dc320",
   "metadata": {},
   "source": [
    "Now let's address any long weekends where Monday was a bank holiday by taking a third of that week's Tuesday case count and replacing Saturday, Sunday, and Monday count with that value instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==1) & (row['MA_Conf_Cases'] != 0):\n",
    "        df9.at[index, 'MA_Conf_Cases'] = df9.at[index, 'MA_third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==0) & (row['MA_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'MA_Conf_Cases'] = df9.at[index, 'ma_lag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64edcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==6) & (row['MA_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'MA_Conf_Cases'] = df9.at[index, 'ma_lag_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df9.iterrows():\n",
    "    if (index>= pd.Timestamp('2021-07-01')) & (row['weekday']==5) & (row['MA_Conf_Cases'] == 0):\n",
    "        df9.at[index, 'MA_Conf_Cases'] = df9.at[index, 'ma_lag_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_ind_ma=(df9[(df9.weekday == 6)&(df9.MA_Conf_Cases==0)]).index # Sunday zero values\n",
    "saturday_ind_ma=(df9[(df9.weekday == 5)&(df9.MA_Conf_Cases==0)]).index # Saturday zero values\n",
    "# Zero values that are neither Sunday nor Monday\n",
    "other_ind_ma=(df9[(df9.weekday != 5)& (df9.weekday != 6)&(df9.MA_Conf_Cases==0)]).index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25baf26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(df9.index, df9['MA_Conf_Cases'], color = 'blue')\n",
    "    ax.set_ylabel('Massachusetts COVID cases')\n",
    "    plt.xticks(rotation=45)\n",
    "    for i in sunday_ind_ma:    \n",
    "        ax.axvline(x=i, color='red', alpha=0.7)\n",
    "    for i in saturday_ind_ma:    \n",
    "        ax.axvline(x=i, color='orange', alpha=0.7)\n",
    "    for i in other_ind_ma:    \n",
    "        ax.axvline(x=i, color='green', alpha=0.7)\n",
    "    plt.title('Zero values by weekday of Massachusetts COV cases', fontsize=20)\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of Vermont-specific columns\n",
    "df9 = df9.drop(['MA_third', 'ma_lag_1', 'ma_lag_2', 'ma_lag_3'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b229efa9",
   "metadata": {},
   "source": [
    "## Bank Holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e382d",
   "metadata": {},
   "source": [
    "Now the missing weekend values have been addressed, I'll identify US bank holidays that correspond to missing case counts across most or all of the states. After cross-checking with the US bank holidays listed in the below hyperlinks, I discovered 5 bank holidays where at least 50% of the states did not report any case values. \n",
    "\n",
    "Full list of 2020 US Holidays [here](https://www.officeholidays.com/countries/usa/2020).\n",
    "\n",
    "Full list of 2021 US Holidays [here](https://www.officeholidays.com/countries/usa/2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98081ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of US bank holidays in 2020-2021:\n",
    "US_bank_holidays = ['2020-12-25', '2020-11-26', '2021-01-01', '2021-05-31', '2021-09-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ed4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with indices in US_bank_holidays list:\n",
    "df9= df9.drop(df9[(df9.index.isin(US_bank_holidays))].index)\n",
    "#df7=df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d551918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9.loc['2021-09-06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083819fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_missing_MA = []\n",
    "remaining_missing_ME = []\n",
    "remaining_missing_CT = []\n",
    "remaining_missing_VT = []\n",
    "\n",
    "for index, row in df9.iterrows():\n",
    "    if row['MA_Conf_Cases'] == 0:\n",
    "        remaining_missing_MA.append(index)\n",
    "    elif row['CT_Conf_Cases'] == 0:\n",
    "        remaining_missing_CT.append(index)\n",
    "    elif row['ME_Conf_Cases'] == 0:\n",
    "        remaining_missing_ME.append(index)\n",
    "    elif row['VT_Conf_Cases'] == 0:\n",
    "        remaining_missing_VT.append(index)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5252c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remaining_missing_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c227ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remaining_missing_ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ddce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remaining_missing_VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remaining_missing_CT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d669a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace cases negative values with np.nan\n",
    "df9.MA_Conf_Cases[remaining_missing_MA] = np.nan\n",
    "df9.CT_Conf_Cases[remaining_missing_CT] = np.nan\n",
    "df9.VT_Conf_Cases[remaining_missing_VT] = np.nan\n",
    "df9.ME_Conf_Cases[remaining_missing_ME] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed2410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through NaNs and fill with average of previous and following cell values \n",
    "state_col_list=['CT_Conf_Cases', 'VT_Conf_Cases', 'ME_Conf_Cases', 'MA_Conf_Cases']\n",
    "for col in state_col_list:\n",
    "    df9[col] = df9[col].fillna((df9[col].shift() + df9[col].shift(-1))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cb4cc",
   "metadata": {},
   "source": [
    "Let's double check for any remaining `NaN`s, as many machine learning models cannot work with them. It would be expected that we may still have some `NaN`s if we consider that towards the start of the pandemic, there may have been multiple days in a row with zero cases. Because we filled `NaN`s with the average of the value before and after the `NaN` value, we may have inadvertantly tried to divide by zero. Any number divided by zero is undefined, and would have left the `NaN` value in place. Let's see how many `NaN`s remaining, and as long as there aren't too many, let's convert them back to zeroes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59caa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many remaining NaN values?\n",
    "df9.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c26d3",
   "metadata": {},
   "source": [
    "Great! We only have 14 `NaN`s left. Let's fill these with zeroes before saving the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3195d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill remaining NaNs\n",
    "df9.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check all NaNs are gone:\n",
    "df9.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df9.loc['ME_Conf_Cases','2021-07-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recheck summary statistics with dropped US_bank_holidays:\n",
    "df9.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518d794",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot boxplot of distribution of cases per weekday\n",
    "#plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, axes = plt.subplots(2,2, sharex=True, figsize=(16,12))\n",
    "    fig.suptitle('Distribution of case counts per weekday', fontsize=20)\n",
    "    # Set suptitle and subtitles\n",
    "    axes[0,0].set_title('Massachusetts', fontsize=16)\n",
    "    axes[0,1].set_title('Connecticut', fontsize =16)\n",
    "    axes[1,0].set_title('Vermont', fontsize= 16)\n",
    "    axes[1,1].set_title('Maine', fontsize= 16)\n",
    "    #Maine\n",
    "    sns.boxplot(ax=axes[0, 0], data=df10, x='weekday', y='MA_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    #Connecticut\n",
    "    sns.boxplot(ax=axes[0, 1], data=df10, x='weekday', y='CT_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    # Vermont\n",
    "    sns.boxplot(ax=axes[1, 0], data=df10, x='weekday', y='VT_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    #Massachusetts\n",
    "    sns.boxplot(ax=axes[1, 1], data=df10, x='weekday', y='ME_Conf_Cases', palette = 'Blues')\n",
    "    plt.xticks(weekday_nums, weekdays)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "#month_nums = np.arange(1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd71ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot boxplot of distribution of cases per month\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, axes = plt.subplots(2,2, sharex=False, figsize=(16,12))\n",
    "    fig.suptitle('Distribution of case counts per month', fontsize=20)\n",
    "    # Set suptitle and subtitles\n",
    "    axes[0,0].set_title('Massachusetts', fontsize=16)\n",
    "    axes[0,0].set_xlabel('Month')\n",
    "    axes[0,1].set_title('Connecticut', fontsize =16)\n",
    "    axes[0,1].set_xlabel('Month')\n",
    "    axes[1,0].set_title('Vermont', fontsize=16)\n",
    "    axes[1,0].set_xlabel('Month')\n",
    "    axes[1,1].set_title('Maine', fontsize=16)\n",
    "    axes[1,1].set_xlabel('Month')\n",
    "    #Maine\n",
    "    sns.boxplot(ax=axes[0, 0], data=df10, x=[i.month for i in df10['date']], y='MA_Conf_Cases', palette = 'flare')\n",
    "    #plt.xticks(month_nums, months)\n",
    "    #Connecticut\n",
    "    sns.boxplot(ax=axes[0, 1], data=df10, x=[i.month for i in df10['date']], y='CT_Conf_Cases', palette = 'flare')\n",
    "    #plt.xticks(month_nums, months)\n",
    "    # Vermont\n",
    "    sns.boxplot(ax=axes[1, 0], data=df10, x=[i.month for i in df10['date']], y='VT_Conf_Cases', palette = 'flare')\n",
    "    #plt.xticks(month_nums, months)\n",
    "    #Massachusetts\n",
    "    sns.boxplot(ax=axes[1, 1], data=df10, x=[i.month for i in df10['date']], y='ME_Conf_Cases', palette = 'flare')\n",
    "    #plt.xticks(month_nums, months)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out how each state compares with each other: \n",
    "#with sns.axes_style(\"white\"):\n",
    "    #fig, ax = plt.subplots(figsize=(12,8))\n",
    "    #ax = sns.boxplot(data=df10[['MA_Conf_Cases', 'CT_Conf_Cases','ME_Conf_Cases', 'VT_Conf_Cases']], palette=\"flare\")\n",
    "    #plt.title('Distribution of daily COV counts by state', fontsize=16)\n",
    "    #ax.set_ylabel('Daily COVID counts', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9071ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DateTimeIndex\n",
    "df9.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f02cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a new csv file\n",
    "df9.to_csv('state_cov_weather2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5564f2d",
   "metadata": {},
   "source": [
    "## Plots:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc0bb2",
   "metadata": {},
   "source": [
    "With so many twin axes to plot, I'll define a function to help plot all of twin axes time series data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ff751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(axes, x, y, color, xlabel, ylabel):\n",
    "    axes.plot(x,y,color=color)\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.tick_params('y', colors = color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387eb7d",
   "metadata": {},
   "source": [
    "## Connecticut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86decaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set(rc={'figure.figsize':(18,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffb602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot CT time vs confirmed cases\n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['CT_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "#Plot CT temp vs time\n",
    "plot_timeseries(ax2, df9.index, df9['CT_Avg_Temp(F)'], 'red', 'Time', 'Average Temperature (F)')\n",
    "plt.title('Connecticut temp vs conf cases over time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937519de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot CT time vs confirmed cases\n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['CT_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "#Plot CT prcp vs time\n",
    "plot_timeseries(ax2, df9.index, df9['CT_PRCP(mm)'], 'red', 'Time', 'CT_PRCP(mm)')\n",
    "plt.title('Connecticut prcp vs confirmed cases over time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b1ffe",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf44e7",
   "metadata": {},
   "source": [
    "## Maine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6de82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot ME time vs Avg. Temp \n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['ME_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "plot_timeseries(ax2, df9.index, df9['ME_Avg_Temp(F)'], 'red', 'Time', 'Average Temperature (F)')\n",
    "plt.title('Maine Temp vs Conf Cases')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed4124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot ME time vs confirmed cases\n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['ME_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "#Plot ME prcp vs time\n",
    "plot_timeseries(ax2, df9.index, df9['ME_PRCP(mm)'], 'red', 'Time', 'ME_PRCP(mm)')\n",
    "plt.title('Maine prcp vs confirmed cases over time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f47afa",
   "metadata": {},
   "source": [
    "## Massachusetts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot MA time vs confirmed cases\n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['MA_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "#Plot MA temp vs time\n",
    "plot_timeseries(ax2, df9.index, df9['MA_Avg_Temp(F)'], 'red', 'Time', 'MA_Avg_Temp(F)')\n",
    "plt.title('Massachusetts TAVG vs confirmed cases over time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bfa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot MA time vs confirmed cases\n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['MA_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "#Plot MA prcp vs time\n",
    "plot_timeseries(ax2, df9.index, df9['MA_PRCP(mm)'], 'red', 'Time', 'MA_PRCP(mm)')\n",
    "plt.title('Massachusetts prcp vs confirmed cases over time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb5d83",
   "metadata": {},
   "source": [
    "## Vermont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5696de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot VT time vs confirmed cases\n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['VT_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "#Plot VT temp vs time\n",
    "plot_timeseries(ax2, df9.index, df9['VT_Avg_Temp(F)'], 'red', 'Time', 'VT_Avg_Temp(F)')\n",
    "plt.title('Vermont TAVG vs confirmed cases over time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot VT time vs confirmed cases\n",
    "fig, ax = plt.subplots()\n",
    "plot_timeseries(ax, df9.index, df9['VT_Conf_Cases'], 'blue', 'Time', 'Confirmed Cases')\n",
    "plt.xticks(rotation=90)\n",
    "ax2 = ax.twinx()\n",
    "#Plot MA prcp vs time\n",
    "plot_timeseries(ax2, df9.index, df9['VT_PRCP(mm)'], 'red', 'Time', 'VT_PRCP(mm)')\n",
    "plt.title('Vermont prcp vs confirmed cases over time')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b89640",
   "metadata": {},
   "source": [
    "## Perform Shapiro-Wilk test for normality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataframe to array to perform Shapiro-Wilcox test:\n",
    "np_cov_weather9 = df9.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Shapiro test:\n",
    "shapiro_test = stats.shapiro(np_cov_weather9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d7bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print values:\n",
    "print(\"Shapiro test statistic is: \", shapiro_test.statistic)\n",
    "print(\"Shapiro p-value is: \", shapiro_test.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ca05c",
   "metadata": {},
   "source": [
    "## Predictive Power Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate ppscore \n",
    "pps = ppscore.matrix(df9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd2572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df9.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d65a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = ppscore.matrix(df9).pivot(columns='x', index='y',  values='ppscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38e003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(14.5,11.5)})\n",
    "sns.heatmap(matrix_df, annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ba73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,12)})\n",
    "sns.heatmap(df9.corr(), square=True, annot=True)\n",
    "#cmap='rocket'\n",
    "#(11.7,8.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d44fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hierarchical clustering with heatmap: clustermap\n",
    "sns.set(rc={'figure.figsize':(15,12)})\n",
    "sns.clustermap(df9.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5b7d8",
   "metadata": {},
   "source": [
    "The clustermap is much easier to interpret than the unclustered heatmap, and visually points us immediately the correlation between average temperatures and confirmed case counts. The clustermap has also grouped Massachusetts values most closely with Connecticut values for each observation, as well as Vermont values most closely with Maine values. This is not surprising, as this is also the geographical grouping of the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT = df9[['CT_Avg_Temp(F)', 'CT_PRCP(mm)', 'CT_Conf_Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bef2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(9,7)})\n",
    "sns.heatmap(CT.corr(), square=True, cmap='rocket', annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855de591",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA = df9[['MA_Avg_Temp(F)', 'MA_PRCP(mm)', 'MA_Conf_Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(MA.corr(), square=True, cmap='rocket', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "VT= df9[['VT_Avg_Temp(F)', 'VT_PRCP(mm)', 'VT_Conf_Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(VT.corr(), square=True, cmap='rocket', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME = df9[['ME_Avg_Temp(F)', 'ME_PRCP(mm)', 'ME_Conf_Cases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27cc034",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ME.corr(), square=True, cmap='rocket', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ddfe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
