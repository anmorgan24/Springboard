{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e485446",
   "metadata": {},
   "source": [
    "Note: This notebook was completed alongside the DataCamp course by the same name\n",
    "# Reshaping Data with pandas\n",
    "Often data is in a human-readable format, but it’s not suitable for data analysis. This is where pandas can help—it’s a powerful tool for reshaping DataFrames into different formats. In this course, you’ll grow your data scientist and analyst skills as you learn how to wrangle string columns and nested data contained in a DataFrame. You’ll work with real-world data, including FIFA player ratings, book reviews, and churn analysis data, as you learn how to reshape a DataFrame from wide to long format, stack and unstack rows and columns, and get descriptive statistics of a multi-index DataFrame.\n",
    "\n",
    "**Instructor:** Maria Eugenia Inzaugarat, PhD Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf8b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc334459",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 1: Introduction to Data Reshaping\n",
    "Let's start by understanding the concept of wide and long formats and the advantages of using each of them. You’ll then learn how to pivot data from long to a wide format, and get summary statistics from a large DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13444818",
   "metadata": {},
   "source": [
    "* Wide and long formats\n",
    "* Long to wide transformation\n",
    "* Wide to long transformation\n",
    "* Stacking and unstacking columns\n",
    "* Reshaping and handling complex data, such as string columns or JSON data\n",
    "* Nested data\n",
    "* Statistical data formats\n",
    "* Multi-level index DataFrames\n",
    "\n",
    "### Shape of data\n",
    "* The way in which a dataset is organized into rows and columns\n",
    "\n",
    "#### Wide format\n",
    "* Each feature is in a separate column\n",
    "* Each row contains many features of the same player\n",
    "* Wide format has **no repeated records**, but this **could lead to missing values.**\n",
    "* This format is preferred to do **simple statistics and imputation**, such as calculating the mean or imputing missing values.\n",
    "\n",
    "<img src='data/wide_format.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Long format\n",
    "* Each row represents one feature\n",
    "* Multiple rows for each player\n",
    "* Notice that there is no row for the feature `age` for the first player\n",
    "* This happens because we had a missing value there\n",
    "* A column (`name`) that identifies the same player through the records\n",
    "* These are typical characteristics of the long format that is usually seen as the standard for a tidy dataset\n",
    "* Tidy data:\n",
    "    * Better to summarize data\n",
    "    * Key-value pairs\n",
    "    * Preferred or required for many advanced graphing and analysis techniques\n",
    "\n",
    "<img src='data/long_format.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "#### Reshaping data\n",
    "* In a broad sense, reshaping data is transforming a data structure to adjust it for analysis\n",
    "* Transpose:\n",
    "    * `fifa_players.set_index('club')[['name', 'nationality']].transpose()`\n",
    "    * Alternately, `.T`\n",
    "* **In this course, we will define reshaping data as converting data from wide to long format and vice versa.**\n",
    "* To decide between using long or wide format, think about the unit of analysis:\n",
    "    * Long format $\\Rightarrow$ characteristic of a player\n",
    "    * Wide format $\\Rightarrow$ each player\n",
    "    \n",
    "#### Wide to long transformation\n",
    "* Performed using `pandas` functions, such as:\n",
    "     * `.melt()`\n",
    "     * `.wide_to_long()`\n",
    "   \n",
    "#### Long to wide format\n",
    "* Transform data using `pandas` methods, for example:\n",
    "    * `.pivot()`\n",
    "    * `.pivot_table()`\n",
    "    \n",
    "#### Exercises: Flipping players\n",
    "\n",
    "```\n",
    "# Set name as index\n",
    "fifa_transpose = fifa_players.set_index('name')\n",
    "\n",
    "# Print fifa_transpose\n",
    "print(fifa_transpose)\n",
    "\n",
    "# Modify the DataFrame to keep only height and weight columns\n",
    "fifa_transpose = fifa_players.set_index('name')[['height', 'weight']]\n",
    "# Print fifa_transpose\n",
    "print(fifa_transpose)\n",
    "\n",
    "# Change the DataFrame so rows become columns and vice versa\n",
    "fifa_transpose = fifa_players.set_index('name')[['height', 'weight']].transpose()\n",
    "\n",
    "# Print fifa_transpose\n",
    "print(fifa_transpose)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa6c222",
   "metadata": {},
   "source": [
    "### Reshaping using pivot method\n",
    "* The long format is usually the most suitble to store a clean dataset\n",
    "\n",
    "#### Why go from long to WIDE format?\n",
    "* Demonstrate relationship between two (or more) columns\n",
    "* Time series operations with the variables\n",
    "* Operation that requires columns to be the unique variable\n",
    "* Wide format allows us to **discover patterns**\n",
    "* The `pivot()` method allows us to reshape the data from a long to a wide format\n",
    "\n",
    "<img src='data/pivot_method2.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* The `pivot()` method takes three arguments:\n",
    "    * **`index`:** takes the name of the column we want to have as an index in the new, pivoted DF.\n",
    "    * **`columns`:** takes the name of the column we want to have as each column in the new, pivoted DF.\n",
    "    * **`values`:** takes the name of the column of values with which we want to populate the new, pivoted DF.\n",
    "* **If the method cannot find a row and column matching the original dataframe, it will set that cell value as a missing value (see the `NaN` above).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff69ce71",
   "metadata": {},
   "source": [
    "<img src='data/pivot1.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "```\n",
    "fifa.pivot(index = 'name', columns = 'variable', values='metric_system')\n",
    "```\n",
    "\n",
    "<img src='data/pivot2.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725ee23",
   "metadata": {},
   "source": [
    "* **Note** that we can also pass a list of two values to the pivot method:\n",
    "* `fifa.pivot(index='name', columns='variable', values=['metric_system', 'imperical_system'])`\n",
    "* In this case, the resulting DataFrame has a hierarchical column index with both column names as demonstrated below:\n",
    "\n",
    "<img src='data/pivot3.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3066ad",
   "metadata": {},
   "source": [
    "***\n",
    "#### Pivoting multiple columns\n",
    "\n",
    "<img src='data/pivot4.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* What if we want to extend the pivot method to all the column values in the DataFrame instead of just one or two?\n",
    "* We can do this easily by omitting the values argument:\n",
    "* `df.pivot(index='name', columns='variable')\n",
    "* We see that we get the same result as above when we identified multiple columns as `value` columns:\n",
    "\n",
    "<img src='data/pivot5.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9a35c",
   "metadata": {},
   "source": [
    "#### Duplicate entries error\n",
    "* Passing only index and column arguments to the pivot method will work in most cases\n",
    "* However, pay attention to the 3rd and 5th rows below:\n",
    "\n",
    "<img src='data/pivot6.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ad4038",
   "metadata": {},
   "source": [
    "* If we try to perform the same operation: `another_fifa.pivot(index='name', columns='variable')`, we get:\n",
    "\n",
    "<img src='data/pivot7.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* It doesn't know which of the two values should be the corresponding value, pandas will raise an error. \n",
    "* We could choose to delete one of the rows (for example the fifth row) and then rerun the command without raising an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65640b2",
   "metadata": {},
   "source": [
    "#### Exercises: Dribbling the pivot method \n",
    "\n",
    "```\n",
    "# Pivot fifa_players to get overall scores indexed by name and identified by movement\n",
    "fifa_overall = fifa_players.pivot(index='name', columns='movement', values='overall')\n",
    "\n",
    "# Print fifa_overall\n",
    "print(fifa_overall)\n",
    "\n",
    "# Pivot fifa_players to get attacking scores indexed by name and identified by movement\n",
    "fifa_attacking = fifa_players.pivot(index='name', columns='movement', values='attacking')\n",
    "\n",
    "# Print fifa_attacking\n",
    "print(fifa_attacking)\n",
    "\n",
    "# Use the pivot method to get overall scores indexed by movement and identified by name\n",
    "fifa_names = fifa_players.pivot(index='movement', columns='name', values='overall')\n",
    "\n",
    "# Print fifa_names\n",
    "print(fifa_names)\n",
    "```\n",
    "\n",
    "#### Exercises: Offensive or defensive player?\n",
    "\n",
    "```\n",
    "# Pivot fifa_players to get overall and attacking scores indexed by name and identified by movement\n",
    "fifa_over_attack = fifa_players.pivot(index='name', \n",
    "                                     columns='movement', \n",
    "                                     values=['overall', 'attacking'])\n",
    "\n",
    "# Print fifa_over_attack\n",
    "print(fifa_over_attack)\n",
    "\n",
    "# Use pivot method to get all the scores index by name and identified by movement\n",
    "fifa_all = fifa_players.pivot(index='name',\n",
    "                              columns='movement',\n",
    "                              values=['overall', 'attacking'])\n",
    "\n",
    "# Print fifa_over_attack\n",
    "print(fifa_all)\n",
    "```\n",
    "\n",
    "#### Exercises: Replay that last move!\n",
    "\n",
    "```\n",
    "# Drop the fifth row to delete all repeated rows\n",
    "fifa_no_rep = fifa_players.drop(4, axis=0)\n",
    "\n",
    "# Print fifa_pivot\n",
    "print(fifa_no_rep)\n",
    "\n",
    "# Drop the fifth row to delete all repeated rows\n",
    "fifa_no_rep = fifa_players.drop(4, axis=0)\n",
    "\n",
    "# Pivot fifa players to get all scores by name and movement\n",
    "fifa_pivot = fifa_no_rep.pivot(index='name', columns='movement', values=['overall', 'attacking']) \n",
    "\n",
    "# Print fifa_pivot\n",
    "print(fifa_pivot)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ee319",
   "metadata": {},
   "source": [
    "## Pivot tables\n",
    "\n",
    "#### Pivot method limitations\n",
    "* The `.pivot()` method has some limitations\n",
    "* Great general purpose pivoting technique\n",
    "* However, **it requires the index column pair to be unique**\n",
    "    * This is mainly due to the fact that the pivot method cannot aggregate values\n",
    "    \n",
    "### Pivot table\n",
    "* A DataFrame containing statistics that summarize the data of a larger DataFrame\n",
    "* To convert from the DataFrame in long format on the left to the DataFrame on the right with aggregated values, we can use the **`.pivot_table()`** method\n",
    "* It is important to note that with this method we can also summarize DataFrames that are not in long format\n",
    "\n",
    "<img src='data/pivot8.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* `df.pivot_table(index='Year', columns='Name', values='Weight', aggfunc='mean')`\n",
    "* **Note** the new, additional parameter: **`aggfunc`**\n",
    "    * **Default `aggfunc` is `mean`.**\n",
    "    \n",
    "### Hierarchical indexes\n",
    "* Another advantage of pivot tables is that we can have multi-level indexes, not only in the columns, but also in the tows: the indexes first and last "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae6ea9",
   "metadata": {},
   "source": [
    "<img src='data/pivot9.png' width=\"700\" height=\"350\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607165d6",
   "metadata": {},
   "source": [
    "### Margins\n",
    "* Finally, we would like to get the number of attacking and overall scores each player has\n",
    "* In the `pivot_table` method, by omitting a `values` argument, pandas will pivot **all values.**\n",
    "* But, we will pass the **`margins`** argument\n",
    "* `fifa_players.pivot_table(index['first', 'last'], columns='movement', aggfunc='count', margins=True)`\n",
    "* When the `margins` parameter is set to `True`, all the columns and rows will be added.\n",
    "* In this case (with `aggfunc='count'`) we'll get the total counts for each row and column\n",
    "\n",
    "<img src='data/pivot10.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c70601",
   "metadata": {},
   "source": [
    "#### Pivot or pivot table?\n",
    "* *Does the DataFrame have more than one value for each index/column pair?*\n",
    "* *Do you need to have a multi-index in your resulting pivoted DataFrame?*\n",
    "* *Do you need summary statistics of your large DataFrame?*\n",
    "* **If YES** Use `.pivot_table()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72edc76",
   "metadata": {},
   "source": [
    "#### Exercises: Reviewing the moves\n",
    "\n",
    "```\n",
    "# Discard the fifth row to delete all repeated rows\n",
    "fifa_drop = fifa_players.drop(4, axis=0)\n",
    "\n",
    "# Use pivot method to get all scores by name and movement\n",
    "fifa_pivot = fifa_drop.pivot(index='name', columns='movement') \n",
    "\n",
    "# Print fifa_pivot\n",
    "print(fifa_pivot)  \n",
    "\n",
    "# Use pivot table to get all scores by name and movement\n",
    "fifa_pivot_table = fifa_players.pivot_table(index='name', \n",
    "                                     columns='movement', \n",
    "                                     aggfunc='mean')\n",
    "# Print fifa_pivot_table\n",
    "print(fifa_pivot_table)\n",
    "```\n",
    "\n",
    "#### Exercises: Exploring the big match\n",
    "\n",
    "```\n",
    "# Use pivot table to display mean age of players by club and nationality \n",
    "mean_age_fifa = fifa_players.pivot_table(index='nationality', \n",
    "                                  columns=['club', 'nationality'], \n",
    "                                  values='age', \n",
    "                                  aggfunc='mean')\n",
    "\n",
    "# Print mean_age_fifa\n",
    "print(mean_age_fifa)\n",
    "\n",
    "# Use pivot table to display max height of any player by club and nationality\n",
    "tall_players_fifa = fifa_players.pivot_table(index='nationality', \n",
    "                                     columns='club', \n",
    "                                      values='height', \n",
    "                                      aggfunc='max')\n",
    "\n",
    "# Print tall_players_fifa\n",
    "print(tall_players_fifa)\n",
    "\n",
    "# Use pivot table to show the count of players by club and nationality and the total count\n",
    "players_country = fifa_players.pivot_table(index='nationality', \n",
    "                                    columns='club', \n",
    "                                    values='name', \n",
    "                                    aggfunc='count', \n",
    "                                    margins=True)\n",
    "\n",
    "# Print players_country\n",
    "print(players_country)\n",
    "```\n",
    "\n",
    "#### Exercises: The tallest and the heaviest\n",
    "\n",
    "```\n",
    "# Define a pivot table to get the characteristic by nationality and club\n",
    "fifa_mean = fifa_players.pivot_table(index=['nationality', 'club'], \n",
    "                                     columns='year')\n",
    "\n",
    "# Print fifa_mean\n",
    "print(fifa_mean)\n",
    "\n",
    "# Set the appropriate argument to show the maximum values\n",
    "fifa_mean = fifa_players.pivot_table(index=['nationality', 'club'], \n",
    "                                     columns='year', \n",
    "                                     aggfunc='max')\n",
    "\n",
    "# Print fifa_mean\n",
    "print(fifa_mean)\n",
    "\n",
    "# Set the argument to get the maximum for each row and column\n",
    "fifa_mean = fifa_players.pivot_table(index=['nationality', 'club'], \n",
    "                                     columns='year', \n",
    "                                     aggfunc='max', \n",
    "                                     margins=True)\n",
    "\n",
    "# Print fifa_mean\n",
    "print(fifa_mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b88d1d",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 2: Converting Between Wide and Long Format\n",
    "Master the technique of reshaping DataFrames from wide to long format. In this chapter, you'll learn how to use the melting method and wide to long function before discovering how to handle string columns by concatenating or splitting them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d4bef",
   "metadata": {},
   "source": [
    "### Reshaping with melt\n",
    "* In this lesson, we will learn how to reshape a DataFrame from wide to long format using the `melt` function.\n",
    "\n",
    "#### Wide to long transformation\n",
    "* Perform analytics\n",
    "* Plot different variables in the same graph\n",
    "\n",
    "<img src='data/wide_to_long.png' width=\"700\" height=\"350\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849c0dc",
   "metadata": {},
   "source": [
    "* Most data is stored in a wide format\n",
    "* The first argument to set is **`id_vars`**\n",
    "* This argument takes the names of the column(s) to use as identifier variables\n",
    "* **`df.melt(id_vars=[\"first\",\"last\"])`**\n",
    "* The columns identified in `id_vars` will also appear in the long format table and will help us match all the records for the same observation\n",
    "    * The rest of the columns are melted\n",
    "    \n",
    "<img src='data/pivot11.png' width=\"700\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "### Values and variables\n",
    "* What can we do if we do not want to melt all the columns?\n",
    "* We have other arguments for that purpose: \n",
    "    * **`value_vars`:** \n",
    "        * Takes the names of the columns we want to melt\n",
    "        * This can be only one column or a list of many columns\n",
    "    * **`var_name`:** \n",
    "        * Takes the name to use for the column \"variable\"\n",
    "        * Default value is `variable`\n",
    "    * **`value_name`:**\n",
    "        * Takes the name to use for the column \"value\"\n",
    "        * Default value is `value`\n",
    "\n",
    "<img src='data/pivot12.png' width=\"700\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "#### Specifying values to melt\n",
    "* `books.melt(id_vars='title', value_vars=['language_code', 'num_pages'])`\n",
    "\n",
    "#### Exercises: Gothic times\n",
    "\n",
    "```\n",
    "# Melt books_gothic using the title column as identifier \n",
    "gothic_melted = books_gothic.melt(id_vars='title')\n",
    "\n",
    "# Print gothic_melted\n",
    "print(gothic_melted)\n",
    "\n",
    "# Melt books_gothic using the title, authors, and publisher columns as identifier\n",
    "gothic_melted_new = books_gothic.melt(id_vars=['title', 'authors', 'publisher'])\n",
    "\n",
    "# Print gothic_melted_new\n",
    "print(gothic_melted_new)\n",
    "\n",
    "# Melt publisher column using title and authors as identifiers\n",
    "publisher_melted = books_gothic.melt(id_vars=['title', 'authors'], \n",
    "                                     value_vars='publisher')\n",
    "\n",
    "# Print publisher_melted\n",
    "print(publisher_melted)\n",
    "\n",
    "# Melt rating and rating_count columns using the title as identifier\n",
    "rating_melted = books_gothic.melt(id_vars='title', \n",
    "                                  value_vars=['rating', 'rating_count'])\n",
    "\n",
    "# Print rating_melted\n",
    "print(rating_melted)\n",
    "\n",
    "# Melt rating and rating_count columns using title and authors as identifier\n",
    "books_melted = books_gothic.melt(id_vars=['title', 'authors'], \n",
    "                                 value_vars=['rating', 'rating_count'])\n",
    "\n",
    "# Print books_melted\n",
    "print(books_melted)\n",
    "\n",
    "# Melt the rating and rating_count using title, authors and publisher as identifiers\n",
    "books_ratings = books_gothic.melt(id_vars=['title', 'authors', 'publisher'], \n",
    "                                  value_vars=['rating', 'rating_count'])\n",
    "\n",
    "# Print books_ratings\n",
    "print(books_ratings)\n",
    "\n",
    "# Assign the name feature to the new variable column\n",
    "books_ratings = books_gothic.melt(id_vars=['title', 'authors', 'publisher'], \n",
    "                                  value_vars=['rating', 'rating_count'], \n",
    "                                  var_name='feature')\n",
    "\n",
    "# Print books_ratings\n",
    "print(books_ratings)\n",
    "\n",
    "# Assign the name number to the new column containing the values\n",
    "books_ratings = books_gothic.melt(id_vars=['title', 'authors', 'publisher'], \n",
    "                                  value_vars=['rating', 'rating_count'], \n",
    "                                  var_name='feature', \n",
    "                                  value_name='number')\n",
    "\n",
    "# Print books_ratings\n",
    "print(books_ratings)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29ef77",
   "metadata": {},
   "source": [
    "### Wide to long function\n",
    "* In addition to `melt`, another function that can help us transform the data from wide to long is the **`pd.wide_to_long()`** function\n",
    "    * **Notice** that this is a pandas function, and not a dataframe method\n",
    "    \n",
    "<img src='data/pivot13.png' width=\"800\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a032f5",
   "metadata": {},
   "source": [
    "* `pd.wide_to_long(books, stubnames=['ratings', 'sold'], i='title', j='year')`\n",
    "\n",
    "<img src='data/pivot14.png' width=\"700\" height=\"350\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb0b26",
   "metadata": {},
   "source": [
    "* **It is important to mention that if we have a DataFrame with a named index and we apply the `wide_to_long` function, the resulting DataFrame will not keep the original index.**\n",
    "\n",
    "<img src='data/pivot15.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04aa2a6",
   "metadata": {},
   "source": [
    "* If we want to keep a named index, we must modify the original dataframe by resetting the index without dropping it\n",
    "* Then, apply the transformation including the new column\n",
    "\n",
    "```\n",
    "books_with_index.reset_index(drop=False, inplace=True)\n",
    "pd.wide_to_long(books_with_index, stubnames=['ratings', 'sold'], i=['author', 'title'], j='year')\n",
    "```\n",
    "\n",
    "<img src='data/pivot16.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c31b9",
   "metadata": {},
   "source": [
    "#### sep argument\n",
    "* This new dataframe (below) is very similar to the previous one, but the name of the columns contains an underscore between the prefix (`ratings` or `sold`) and the suffix (the year, `2019` or `2020`).\n",
    "\n",
    "<img src='data/pivot17.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* If we apply the transformation as before, we'll get an empty DataFrame:\n",
    "\n",
    "<img src='data/pivot18.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* This happens because pandas doesn't recognize the name of the columns\n",
    "* **It is always assumed that the prefix is *immediately* followed by a numeric suffix.**\n",
    "* To overcome this, we can use the `sep` argument\n",
    "\n",
    "<img src='data/pivot19.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### suffix argument\n",
    "* Finally, if the names of the wide columns do not end in a numeric number, (and instead, for example, end in alphabetic `one` or `two`)... if we apply the same transformation as before, we'll get an empty DataFrame since pandas assumes the suffixes are numeric\n",
    "* To solve this, we use the `suffix` argument with a regex expression\n",
    "\n",
    "<img src='data/pivot20.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd87d0",
   "metadata": {},
   "source": [
    "#### Exercises: The golden age\n",
    "\n",
    "```\n",
    "# Reshape wide to long using title as index and version as new name, and extracting isbn prefix \n",
    "isbn_long = pd.wide_to_long(golden_age, \n",
    "                            stubnames='isbn', \n",
    "                            i='title', \n",
    "                            j='version')\n",
    "\n",
    "# Print isbn_long\n",
    "print(isbn_long)\n",
    "```\n",
    "\n",
    "```\n",
    "# Reshape wide to long using title and authors as index and version as new name, and prefix as wide column prefix\n",
    "prefix_long = pd.wide_to_long(golden_age, \n",
    "                      stubnames='prefix', \n",
    "                      i=['title', 'authors'], \n",
    "                      j='version')\n",
    "\n",
    "# Print prefix_long\n",
    "print(prefix_long)\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "# Reshape wide to long using title and authors as index and version as new name, and prefix and isbn as wide column prefixes\n",
    "all_long = pd.wide_to_long(golden_age, \n",
    "                   stubnames=['isbn', 'prefix'], \n",
    "                   i=['title', 'authors'], \n",
    "                   j='version')\n",
    "\n",
    "# Print all_long\n",
    "print(all_long)\n",
    "```\n",
    "\n",
    "#### Exercises: Decrypting the code\n",
    "\n",
    "```\n",
    "# Reshape using author and title as index, code as new name and getting the prefix language and publisher\n",
    "the_code_long = pd.wide_to_long(books_brown, \n",
    "                                stubnames=['language', 'publisher'], \n",
    "                                i=['author', 'title'], \n",
    "                                j='code',\n",
    "                                sep='_')\n",
    "\n",
    "# Print the_code_long\n",
    "print(the_code_long)\n",
    "```\n",
    "\n",
    "```\n",
    "# Specify underscore as the character that separates the variable names\n",
    "the_code_long = pd.wide_to_long(books_brown, \n",
    "                                stubnames=['language', 'publisher'], \n",
    "                                i=['author', 'title'], \n",
    "                                j='code', sep='_')\n",
    "\n",
    "# Print the_code_long\n",
    "print(the_code_long)\n",
    "```\n",
    "\n",
    "```\n",
    "# Specify that wide columns have a suffix containing words\n",
    "the_code_long = pd.wide_to_long(books_brown, \n",
    "                                stubnames=['language', 'publisher'], \n",
    "                                i=['author', 'title'], \n",
    "                                j='code', \n",
    "                                sep='_', \n",
    "                                suffix='\\w+')\n",
    "\n",
    "# Print the_code_long\n",
    "print(the_code_long)\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "# Modify books_hunger by resetting the index without dropping it\n",
    "books_hunger.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Reshape using title and language as index, feature as new name, publication and page as prefix separated by space and ending in a word\n",
    "publication_features = pd.wide_to_long(books_hunger, \n",
    "                                       stubnames=['publication', 'page'], \n",
    "                                       i=['title', 'language'], \n",
    "                                       j='feature', \n",
    "                                       sep=' ', \n",
    "                                       suffix='\\w+')\n",
    "\n",
    "# Print publication_features\n",
    "print(publication_features)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc98e8d",
   "metadata": {},
   "source": [
    "### Working with string columns\n",
    "* pandas Series and Indexes have a set of string processing methods\n",
    "* Easily accessible with `str` attribute\n",
    "    * `books['title'].str.split(':')`\n",
    "    * The method returns a list for each row \n",
    "    * Each list contains the two sub-strings obtained from splitting the title by the colon.\n",
    "    \n",
    "<img src='data/pivot21.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We could also access only one of the resulting elements\n",
    "* In that case, we would use the `.get()` method from the `str` attribute, passing in the index of the element we want.\n",
    "    * `books['title'].str.split(\":\").str.get(0)\n",
    "    * In this example we get the element of index zero\n",
    "    \n",
    "<img src='data/pivot22.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e663cb1",
   "metadata": {},
   "source": [
    "* We can also set the `expand` argument of `split` to `True`\n",
    "* This will return a new DataFrame with two columns, one for each split element\n",
    "\n",
    "<img src='data/pivot23.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf11de",
   "metadata": {},
   "source": [
    "* This allows us to assign the split elements to columns in the original DataFrame:\n",
    "* `books[['main_title', 'subtitle']] = books['title'].str.split(\":\", expand=True)`\n",
    "* In our example, we first split the column title by the colon, indicating we wanted to expand it to two columns, and assign it to two new columns \n",
    "* This is useful because now we can drop the original column title\n",
    "* And after that, transform the DataFrame by using the new columns as indices, getting a clean, long DataFrame with a multi-level index. \n",
    "\n",
    "```\n",
    "books[['main_title', 'subtitle']] = books['title'].str.split(\":\", expand=True)\n",
    "books.drop('title', axis =1, inplace=True)\n",
    "pd.wide_to_long(books, stubnames=['ratings', 'sold'], i=['main_title', 'subtitle'], j='year')\n",
    "```\n",
    "\n",
    "<img src='data/pivot24.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc921e",
   "metadata": {},
   "source": [
    "#### Concatenating two columns\n",
    "* `books_new['name_author'].str.cat(books_new['lastname_author'], sep=' ')`\n",
    "\n",
    "<img src='data/pivot25.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09831c8e",
   "metadata": {},
   "source": [
    "* This is helpful because then we can melt our DataFrame using this new (concatenated) column as an index, instead of using the two original columns\n",
    "\n",
    "\n",
    "### Concatente index\n",
    "* The `cat` and `split` methods can also be used for indexes\n",
    "* To concatenate the index with a column in the DataFrame:\n",
    "* `comics_marvel.index = comics_marvel.index.str.cat(comics_marvel['subtitle'], sep='-')`\n",
    "\n",
    "<img src='data/pivot26.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a35a9",
   "metadata": {},
   "source": [
    "### Split index\n",
    "* We can do the same to split the string contained in the index\n",
    "* `comics_marvel.index = comics_marvel.index.str.split('-', expand=True)`\n",
    "* We now get a dataframe with a multilevel index\n",
    "\n",
    "<img src='data/pivot27.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc98fb",
   "metadata": {},
   "source": [
    "### Concatenate Series\n",
    "* So far we have only worked with concatenating columns, but we can apply the `cat` method to concatenate a **column** with a **pre-defined list**\n",
    "* `books_new['name_author'].str.cat(new_list, sep=' ')`\n",
    "\n",
    "<img src='data/pivot28.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c023e39",
   "metadata": {},
   "source": [
    "* As we can see in the output, we obtain a Series where each string in the main title has been concatenated with the corresponding element in the list\n",
    "\n",
    "#### Exercises: Did you say dystopia\n",
    "\n",
    "```\n",
    "# Split the index of books_dys by the hyphen \n",
    "books_dys.index = books_dys.index.str.split('-')\n",
    "\n",
    "# Print books_dys\n",
    "print(books_dys)\n",
    "```\n",
    "\n",
    "```\n",
    "# Get the first element after splitting the index of books_dys\n",
    "books_dys.index = books_dys.index.str.split('-').str.get(0)\n",
    "\n",
    "# Print books_dys\n",
    "print(books_dys)\n",
    "```\n",
    "\n",
    "```\n",
    "# Split by the hyphen the index of books_dys\n",
    "books_dys.index = books_dys.index.str.split('-').str.get(0)\n",
    "\n",
    "# Concatenate the index with the list author_list separated by a hyphen\n",
    "books_dys.index = books_dys.index.str.cat(author_list, sep='-')\n",
    "\n",
    "# Print books_dys\n",
    "print(books_dys)\n",
    "```\n",
    "\n",
    "```\n",
    "# Concatenate the title and subtitle separated by \"and\" surrounded by spaces\n",
    "hp_books['full_title'] = hp_books['title'].str.cat(hp_books['subtitle'], sep =' and ') \n",
    "\n",
    "# Print hp_books\n",
    "print(hp_books)\n",
    "```\n",
    "\n",
    "```\n",
    "# Concatenate the title and subtitle separated by \"and\" surrounded by spaces\n",
    "hp_books['full_title'] = hp_books['title'].str.cat(hp_books['subtitle'], sep =\" and \") \n",
    "\n",
    "# Split the authors into writer and illustrator columns\n",
    "hp_books[['writer', 'illustrator']] = hp_books['authors'].str.split(\"/\", expand=True) \n",
    "\n",
    "# Print hp_books\n",
    "print(hp_books)\n",
    "```\n",
    "\n",
    "```\n",
    "# Concatenate the title and subtitle separated by \"and\" surrounded by spaces\n",
    "hp_books['full_title'] = hp_books['title'].str.cat(hp_books['subtitle'], sep =\" and \") \n",
    "\n",
    "# Split the authors into writer and illustrator columns\n",
    "hp_books[['writer', 'illustrator']] = hp_books['authors'].str.split('/', expand=True)\n",
    "\n",
    "# Melt goodreads and amazon columns into a single column\n",
    "hp_melt = hp_books.melt(id_vars=['full_title', 'writer'], \n",
    "                        var_name='source', \n",
    "                        value_vars=['goodreads', 'amazon'], \n",
    "                        value_name='rating')\n",
    "\n",
    "# Print hp_melt\n",
    "print(hp_melt)\n",
    "```\n",
    "\n",
    "#### Exercises: Elementary, dear Watson\n",
    "\n",
    "```\n",
    "# Split main_title by a colon and assign it to two columns named title and subtitle \n",
    "books_sh[['title', 'subtitle']] = books_sh['main_title'].str.split(':', expand=True)\n",
    "\n",
    "# Print books_sh\n",
    "print(books_sh)\n",
    "```\n",
    "\n",
    "```\n",
    "# Split main_title by a colon and assign it to two columns named title and subtitle \n",
    "books_sh[['title', 'subtitle']] = books_sh['main_title'].str.split(':', expand=True)\n",
    "\n",
    "# Split version by a space and assign the second element to the column named volume \n",
    "books_sh['volume'] = books_sh['version'].str.split(' ').str.get(1)\n",
    "\n",
    "# Print books_sh\n",
    "print(books_sh)\n",
    "```\n",
    "\n",
    "```\n",
    "# Split main_title by a colon and assign it to two columns named title and subtitle \n",
    "books_sh[['title', 'subtitle']] = books_sh['main_title'].str.split(':', expand=True)\n",
    "\n",
    "# Split version by a space and assign the second element to the column named volume\n",
    "books_sh['volume'] = books_sh['version'].str.split(' ').str.get(1)\n",
    "\n",
    "# Drop the main_title and version columns modifying books_sh\n",
    "books_sh.drop(['main_title', 'version'], axis=1, inplace=True)\n",
    "\n",
    "# Print books_sh\n",
    "print(books_sh)\n",
    "```\n",
    "\n",
    "```\n",
    "# Split main_title by a colon and assign it to two columns named title and subtitle \n",
    "books_sh[['title', 'subtitle']] = books_sh['main_title'].str.split(':', expand=True)\n",
    "\n",
    "# Split version by a space and assign the second element to the column named volume \n",
    "books_sh['volume'] = books_sh['version'].str.split(' ').str.get(1)\n",
    "\n",
    "# Drop the main_title and version columns modifying books_sh\n",
    "books_sh.drop(['main_title', 'version'], axis=1, inplace=True)\n",
    "\n",
    "# Reshape using title, subtitle and volume as index, name feature the new variable from columns starting with number, separated by undescore and ending in words \n",
    "sh_long = pd.wide_to_long(books_sh, \n",
    "                          stubnames='number', \n",
    "                          i=['title', 'subtitle', 'volume'], \n",
    "                          j='feature', \n",
    "                          sep='_', \n",
    "                          suffix='\\w+')\n",
    "\n",
    "# Print sh_long \n",
    "print(sh_long)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94594d",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 3: Stacking and Unstacking DataFrames\n",
    "In this chapter, you’ll level-up your data manipulation skills using multi-level indexing. You'll learn how to reshape DataFrames by rearranging levels of the row indexes to the column axis, or vice versa. You'll also gain the skills you need to handle missing data generated in the stacking and unstacking processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7930e",
   "metadata": {},
   "source": [
    "### Stacking DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3106c543",
   "metadata": {},
   "source": [
    "* Pandas also has some reshaping methods that are designed to work on DataFrames with multi-level indexes\n",
    "* A **MultiIndex**, also known as a **multi-level index** allows us to **store and manipulate multidimensional data in simple DataFrames.**\n",
    "\n",
    "### Creating a MultiIndex\n",
    "* There are several ways to create a multilevel index.\n",
    "\n",
    "#### Setting the index\n",
    "* The simplest way to create a multilevel index is to use the **`set_index()`** method:\n",
    "* In the below code, we specify that we want the columns `country` and `age` to be set as row indices\n",
    "* `churn.set_index(['country', 'age'], inplace=True)`\n",
    "\n",
    "<img src='data/pivot29.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab26dd8",
   "metadata": {},
   "source": [
    "### MultiIndex from array\n",
    "* Another option is to use the method `from_arrays()` from MultiIndex\n",
    "* In this case, we define a list of lists named `new_array` (below)\n",
    "* Each element represents one index\n",
    "* We call the `from_arrays()` medthod, passing our array and a list of names we want for the indexes\n",
    "* **We assign it to the original DataFrame *index* by calling the *index attribute.***\n",
    "\n",
    "```\n",
    "new_array = [['yes', 'no', 'yes'], ['no', 'yes', 'yes']]\n",
    "churn.index = pd.MultiIndex.from_arrays(new_array, names=['member', 'credit_card'])\n",
    "```\n",
    "\n",
    "<img src='data/pivot30.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b24894",
   "metadata": {},
   "source": [
    "* We can also define a DataFrame with multi-level indexes on the rows **and** the columns \n",
    "\n",
    "<img src='data/pivot31.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5129cf",
   "metadata": {},
   "source": [
    "* The process is very similar:\n",
    "    * We create two MultiIndexes using the method `from_arrays()`: one for the index and one for the columns\n",
    "    \n",
    "```\n",
    "index = pd.MultiIndex.from_arrays([['Wick', 'Wick', 'Shelley', 'Shelley'],\n",
    "                                  ['John', 'Julien', 'Mary', 'Frank']],\n",
    "                                 names = ['last', 'first'])\n",
    "columns = pd.MultiIndex.from_arrays([['2019', '2019', '2020', '2020'],\n",
    "                                     ['age', 'weight', 'age', 'weight']],\n",
    "                      names=['year', 'feature'])\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea17fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_arrays([['Wick', 'Wick', 'Shelley', 'Shelley'],\n",
    "                                  ['John', 'Julien', 'Mary', 'Frank']],\n",
    "                                 names = ['last', 'first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630e4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.MultiIndex.from_arrays([['2019', '2019', '2020', '2020'],\n",
    "                                     ['age', 'weight', 'age', 'weight']],\n",
    "                      names=['year', 'feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee1930",
   "metadata": {},
   "source": [
    "* When we create the DataFrame, we set the index and the columns to be the recently created multi-level indexes\n",
    "\n",
    "```\n",
    "patients = pd.DataFrame(data, index=index, columns=columns)\n",
    "patients\n",
    "```\n",
    "* As a result, we get a DataFrame with multi-level indexes on the rows and on the columns\n",
    "\n",
    "<img src='data/pivot32.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8fb6c",
   "metadata": {},
   "source": [
    "### The .stack() method\n",
    "* The `stack()` method with reshape the DataFrame with a multi-level index by converting it into a **stacked form**\n",
    "* `df.stack()`\n",
    "* In other words, stacking means: **Rearranging the innermost column index to become the innermost row index.**\n",
    "\n",
    "<img src='data/pivot33.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "\n",
    "### Stack into a series\n",
    "* If we take a DataFrame with a multi-level index on the rows and a simple column index, `stack()` will compress the last (/first?) level in the DataFrame columns to produce a Series, as we can see in the output\n",
    "\n",
    "<img src='data/pivot34.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/pivot35.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495545e",
   "metadata": {},
   "source": [
    "### Stack into a DataFrame\n",
    "* We have a DataFrame with a multi-level index in the columns; we apply the `stack()` method\n",
    "* As a consequence, `stack()` will compress the last level in the columns to produce a DataFrame, as seen in the output\n",
    "\n",
    "<img src='data/pivot36.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553ad53",
   "metadata": {},
   "source": [
    "### Stack a Level by Number\n",
    "* It is also possible to choose which level to stack\n",
    "* In the example below, we want to stack the first column level, so we set the `level` argument to zero\n",
    "* Now **the stacked level becomes the new lowest level in the row multi-level index**\n",
    "\n",
    "<img src='data/pivot37.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* **It is important to remember that if we don't set the level argument, `stack()` will move the last level by default.**\n",
    "\n",
    "### Stack a level by name\n",
    "* If our DataFrame has named column levels, we can also specify the level to stack by passing in the column name\n",
    "* In the code below, we set `level='year'`\n",
    "* In the resulting DataFrame, we see that the year level has now become the innermost row level\n",
    "\n",
    "<img src='data/pivot38.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a9e8ac",
   "metadata": {},
   "source": [
    "#### Exercises: Stack the calls!\n",
    "\n",
    "```\n",
    "# Predefined list to use as index\n",
    "new_index = [['California', 'California', 'New York', 'Ohio'], \n",
    "             ['Los Angeles', 'San Francisco', 'New York', 'Cleveland']]\n",
    "\n",
    "# Create a multi-level index using predefined new_index\n",
    "churn_new = pd.MultiIndex.from_arrays(new_index, names=['state', 'city'])\n",
    "\n",
    "# Print churn_new\n",
    "print(churn_new)\n",
    "```\n",
    "\n",
    "```\n",
    "# Predefined list to use as index\n",
    "new_index = [['California', 'California', 'New York', 'Ohio'], \n",
    "             ['Los Angeles', 'San Francisco', 'New York', 'Cleveland']]\n",
    "\n",
    "# Create a multi-level index using predefined new_index\n",
    "churn_new = pd.MultiIndex.from_arrays(new_index, names=['state', 'city'])\n",
    "\n",
    "# Assign the new index to the churn index\n",
    "churn.index = churn_new\n",
    "\n",
    "# Print churn\n",
    "print(churn)\n",
    "```\n",
    "\n",
    "```\n",
    "# Predefined list to use as index\n",
    "new_index = [['California', 'California', 'New York', 'Ohio'], \n",
    "             ['Los Angeles', 'San Francisco', 'New York', 'Cleveland']]\n",
    "\n",
    "# Create a multi-level index using predefined new_index\n",
    "churn_new = pd.MultiIndex.from_arrays(new_index, names=['state', 'city'])\n",
    "\n",
    "# Assign the new index to the churn index\n",
    "churn.index = churn_new\n",
    "\n",
    "# Reshape by stacking churn DataFrame\n",
    "churn_stack = churn.stack()\n",
    "\n",
    "# Print churn_stack\n",
    "print(churn_stack)\n",
    "```\n",
    "\n",
    "#### Exercises: Phone Directory Index\n",
    "\n",
    "```\n",
    "# Set state and city as index modifying the DataFrame\n",
    "churn.set_index(['state', 'city'], inplace=True)\n",
    "\n",
    "# Print churn\n",
    "print(churn)\n",
    "```\n",
    "\n",
    "```\n",
    "# Set state and city as index modifying the DataFrame\n",
    "churn.set_index(['state', 'city'], inplace=True)\n",
    "\n",
    "# Reshape by stacking the second level\n",
    "churn_stack = churn.stack(level=1)\n",
    "\n",
    "# Print churn_stack\n",
    "print(churn_stack)\n",
    "```\n",
    "\n",
    "#### Exercises: Text me!\n",
    "\n",
    "```\n",
    "# Stack churn by the time column level\n",
    "churn_time = churn.stack(level='time')\n",
    "\n",
    "# Print churn_time\n",
    "print(churn_time)\n",
    "```\n",
    "\n",
    "```\n",
    "# Stack churn by the feature column level\n",
    "churn_feature = churn.stack(level='feature')\n",
    "\n",
    "# Print churn_feature\n",
    "print(churn_feature)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d263ded",
   "metadata": {},
   "source": [
    "## Unstacking DataFrames\n",
    "\n",
    "### Undoing stacking process\n",
    "* pandas provides us with the `unstack()` method\n",
    "* **The unstacking process performs exactly the inverse operation of stacking**\n",
    "* **Unstacking** means rearranging the innermost row index to become the innermost column index.\n",
    "\n",
    "<img src='data/pivot39.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327ef46",
   "metadata": {},
   "source": [
    "* If we take another look at this $\\Downarrow$ stacked series, we can see that it has three row index levels:\n",
    "\n",
    "<img src='data/pivot40.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* If we apply the `unstack()` method, we can see that the innermost row level has now moved to the innermost column level; this is the same as the original DataFrame we had before the stacking operation, effectively \"undoing\" the stacking:\n",
    "\n",
    "<img src='data/pivot41.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9858944",
   "metadata": {},
   "source": [
    "### Unstacking a DataFrame\n",
    "* `unstack()` can also be applied to DataFrames\n",
    "\n",
    "<img src='data/pivot42.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/pivot43.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd249a18",
   "metadata": {},
   "source": [
    "* As a result $\\Uparrow$, we can see that the last row level, the `feature` level, has moved to the column level.\n",
    "* Again, we got the original DataFrame we had before the stacking operation\n",
    "\n",
    "### Unstack a level\n",
    "* We can also choose *which* level to unstack by setting the `level` argument to either the **index name** or **index number**, just as we did with the `stack()` method:\n",
    "\n",
    "<img src='data/pivot44.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77712017",
   "metadata": {},
   "source": [
    "### Unstack level by number\n",
    "* Remember that if we don't set the `level` argument, `unstack()` moves the last column level by default.\n",
    "\n",
    "<img src='data/pivot45.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Unstack level by name\n",
    "\n",
    "<img src='data/pivot46.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57935846",
   "metadata": {},
   "source": [
    "### Sort index\n",
    "* Note that the `stack()` and `unstack()` methods implicitly sort the index levels\n",
    "* To change that, we can use the **`sort_index()`** method\n",
    "* In the example below, we set the `ascending` argument to `False`\n",
    "* The resulting DataFrame contains the row indices sorted by descending order\n",
    "\n",
    "<img src='data/pivot47.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41768957",
   "metadata": {},
   "source": [
    "### Rearranging levels\n",
    "* **One useful way to rearrange levels is to chain the stacking and unstacking processes**\n",
    "* Below we unstack the second row level and then stack the first column level\n",
    "* In the output, we see that the row level named `first` appears now in the column index\n",
    "* Also, the column level named `year` has moved to the row index\n",
    "\n",
    "<img src='data/pivot48.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245488d4",
   "metadata": {},
   "source": [
    "#### Exercises: International caller\n",
    "\n",
    "```\n",
    "# Reshape the churn DataFrame by unstacking\n",
    "churn_unstack = churn.unstack()\n",
    "\n",
    "# Print churn_unstack\n",
    "print(churn_unstack)\n",
    "```\n",
    "\n",
    "```\n",
    "# Reshape churn by unstacking the first row level\n",
    "churn_first = churn.unstack(level=0)\n",
    "\n",
    "# Print churn_zero\n",
    "print(churn_first)\n",
    "```\n",
    "\n",
    "```\n",
    "# Reshape churn by unstacking the second row level\n",
    "churn_second = churn.unstack(level=1)\n",
    "\n",
    "# Print churn_second\n",
    "print(churn_second)\n",
    "```\n",
    "\n",
    "#### Exercises: Call another time\n",
    "\n",
    "```\n",
    "# Unstack the time level from churn\n",
    "churn_time = churn.unstack(level='time')\n",
    "\n",
    "# Print churn_time\n",
    "print(churn_time)\n",
    "```\n",
    "\n",
    "```\n",
    "# Sort the index in descending order\n",
    "churn_time = churn.unstack(level='time').sort_index(ascending=False)\n",
    "\n",
    "# Print churn_time\n",
    "print(churn_time)\n",
    "```\n",
    "\n",
    "#### Exercises: Organizing your voicemail\n",
    "\n",
    "```\n",
    "# Unstack churn by type level\n",
    "churn_type = churn.unstack(level='type')\n",
    "\n",
    "# Stack the resulting DataFrame using the first column level\n",
    "churn_final = churn_type.stack(level=0)\n",
    "\n",
    "# Print churn_type\n",
    "print(churn_final)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec031f94",
   "metadata": {},
   "source": [
    "## Working with multiple levels\n",
    "* Rearranging one level at a time has its limitations\n",
    "\n",
    "### Rearranging multiple levels\n",
    "* Swap levels\n",
    "* Stack and unstack multiple levels at the same time\n",
    "\n",
    "### Swap levels\n",
    "* The **`swaplevel()`** method can switch the order of two levels *within the same axis*\n",
    "* This means that we can swap the order of two row levels or two column levels\n",
    "\n",
    "<img src='data/pivot49.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* See the following example with the `cars` dataset:\n",
    "* We apply the `swaplevel()` method, passing the index zero and two\n",
    "* In the output, we can see how the first and tird row levels are now interchanged\n",
    "\n",
    "<img src='data/pivot50.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e9a1e",
   "metadata": {},
   "source": [
    "### Swap levels and unstack\n",
    "* We can now chain it with the unstacking process\n",
    "* We can see that the row level containing the `price` and `sold` features was moved to the column index\n",
    "* If we hadn't changed the order of the levels, the unstacked level would have been the brand level.\n",
    "\n",
    "<img src='data/pivot51.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530ce76",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Swap levels and unstack\n",
    "* In the following example, we first unstack the last row index level, then swap the first and second column levels \n",
    "* We do this by setting the `axis` parameters to `1`\n",
    "* We can see how the year appears on top of the brand level\n",
    "\n",
    "<img src='data/pivot52.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f406e",
   "metadata": {},
   "source": [
    "### Swap levels and stack\n",
    "* Finally, we can also stack the column index of cars\n",
    "* Then, call the `swaplevel()` method, passing zero and two as arguments\n",
    "* In the output, we can see how the recently stacked level and the output first level are switched\n",
    "\n",
    "<img src='data/pivot53.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928e42d",
   "metadata": {},
   "source": [
    "### Multiple levels\n",
    "* The DataFrame here has multi-level indexes on the rows and on the columns \n",
    "* So, how do we reshape any of these multiple levels *at the same time*\n",
    "\n",
    "<img src='data/pivot54.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Unstacking multiple levels\n",
    "* The `cars` DataFrame; it has a **multi-index on the rows**. In particular, it has **three levels.**\n",
    "\n",
    "<img src='data/pivot55.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Unstacking levels by number\n",
    "* Unstacking several levels at the same time is easy\n",
    "* We just have to pass a list of the index numbers to the level parameter\n",
    "* `cars.unstack(level=[0,1])`\n",
    "* In the output, we see that the first and second row levels are now on the column index.\n",
    "* The resulting DataFrame has three levels on the row indices\n",
    "\n",
    "<img src='data/pivot56.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Unstacking levels by name\n",
    "* We could also use the level names by passing a list of brand and model levels to `unstack()`\n",
    "* `cars.unstack(level=['brand', 'model'])`\n",
    "* As a result, we get the same DataFrame as before\n",
    "\n",
    "<img src='data/pivot57.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Stacking multiple levels\n",
    "* For the following examples, we'll use this $\\Downarrow$ DataFrame:\n",
    "\n",
    "<img src='data/pivot58.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Stacking by name or number\n",
    "* We could pass a list of index numbers or the respective names \n",
    "* In both cases, we get a resulting DataFrame where the year and brand levels are now in the row indices\n",
    "* It is important to notice that the order in which you pass the names matters\n",
    "\n",
    "<img src='data/pivot59.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8d38b",
   "metadata": {},
   "source": [
    "#### Exercises: Swap your SIM card\n",
    "\n",
    "```\n",
    "# Switch the first and third row index levels in churn\n",
    "churn_swap = churn.swaplevel(0, 2)\n",
    "\n",
    "# Print churn_swap\n",
    "print(churn_swap)\n",
    "```\n",
    "\n",
    "```\n",
    "# Switch the first and third row index levels in churn\n",
    "churn_swap = churn.swaplevel(0, 2)\n",
    "\n",
    "# Reshape by unstacking the last row level \n",
    "churn_unstack = churn_swap.unstack()\n",
    "\n",
    "# Print churn_unstack\n",
    "print(churn_unstack)\n",
    "```\n",
    "\n",
    "#### Exercises: Two many calls\n",
    "\n",
    "```\n",
    "# Unstack the first and second row level of churn\n",
    "churn_unstack = churn.unstack(level=[0, 1])\n",
    "\n",
    "# Print churn_unstack\n",
    "print(churn_unstack)\n",
    "```\n",
    "\n",
    "```\n",
    "# Unstack the first and second row level of churn\n",
    "churn_unstack = churn.unstack(level=[0, 1])\n",
    "\n",
    "# Stack the resulting DataFrame using plan and year\n",
    "churn_py = churn_unstack.stack(level=['plan', 'year'])\n",
    "\n",
    "# Print churn_py\n",
    "print(churn_py)\n",
    "```\n",
    "\n",
    "```\n",
    "# Unstack the first and second row level of churn\n",
    "churn_unstack = churn.unstack(level=[0, 1])\n",
    "\n",
    "# Stack the resulting DataFrame using plan and year\n",
    "churn_py = churn_unstack.stack(['plan', 'year'])\n",
    "\n",
    "# Switch the first and second column levels\n",
    "churn_switch = churn_py.swaplevel(0, 1, axis=1)\n",
    "\n",
    "# Print churn_switch\n",
    "print(churn_switch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1d47a",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "* In this lesson, we'll learn how to handle missing data when we stack or unstack DataFrames\n",
    "\n",
    "### Unstacking leads to missing values\n",
    "* This happens when: **Subgroups do not have the same set of labels**\n",
    "\n",
    "<img src='data/pivot60.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/pivot61.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* In the reshaped data above $\\Uparrow$ we can see that the subgroup *Aves Carnivora* shows a missing value `NaN`\n",
    "* This happens because it was not present in the original DataFrame\n",
    "\n",
    "### Handling NaN with unstack\n",
    "* Luckily, the parameter `fill_value` of the `unstack()` method allows us to fill those values with any value\n",
    "\n",
    "<img src='data/pivot62.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "## Stack and missing values\n",
    "* However, the case of `stack()` is different;\n",
    "* Missing values appear when: **Combinations of index and column values missing from the original DataFrame**\n",
    "* We'll work with the following DataFrame $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot63.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* After applying the stack method, we can see that the combination of rose and size is completely missing $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot64.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* **This happens because `stack()` has the argument `dropna` set to `True` by *default***\n",
    "* If we would prefer to keep that information, we need to set the `dropna` argument to `False` $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot65.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We can see in the resulting DataFrame that the row with indices rose size is now present (all it's values are now missing values. \n",
    "* We *could* then fill the missing values using the `fillna()` method $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot66.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We pass the value with which we want to replace the missing values (in this case `0`).\n",
    "* The resulting DataFrame $\\Uparrow$ will have zeros instead of `NaN`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eee7c8",
   "metadata": {},
   "source": [
    "#### Exercises: A missed phone call\n",
    "\n",
    "```\n",
    "# Unstack churn level and fill missing values with zero\n",
    "churn = churn.unstack(level='churn', fill_value=0)\n",
    "\n",
    "# Sort by descending voice mail plan and ascending international plan\n",
    "churn_sorted = churn.sort_index(level=['voice_mail_plan', 'international_plan'], \n",
    "                          ascending=[False, True])\n",
    "\n",
    "# Print final DataFrame and observe pattern\n",
    "print(churn_sorted)\n",
    "```\n",
    "\n",
    "#### Exercises: Don't drop the stack\n",
    "\n",
    "```\n",
    "# Stack the level type from churn\n",
    "churn_stack = churn.stack(level='type')\n",
    "\n",
    "# Fill the resulting missing values with zero \n",
    "churn_fill = churn_stack.fillna(0)\n",
    "\n",
    "# Print churn_fill\n",
    "print(churn_fill)\n",
    "```\n",
    "\n",
    "```\n",
    "# Stack the level scope without dropping rows with missing values\n",
    "churn_stack = churn.stack(level='scope', dropna=False)\n",
    "\n",
    "# Fill the resulting missing values with zero\n",
    "churn_fill = churn_stack.fillna(0)\n",
    "\n",
    "# Print churn_fill\n",
    "print(churn_fill)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace0382",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 4: Advanced Reshaping\n",
    "You'll finish by learning how to combine the reshaping process with grouping to produce quick data manipulations. Lastly, you'll discover how to transform list-like columns and handle complex nested data, such as nested JSON files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb4c13",
   "metadata": {},
   "source": [
    "## Reshaping and combining data\n",
    "* We have been reshaping DataFrames using methods such as `stack` and `unstack`\n",
    "* Now, we'll learn how to combine DataFrames with **grouping** and **statistical functions**\n",
    "* Let's use the following DataFrame with multi-level indices\n",
    "\n",
    "<img src='data/pivot67.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We could perform some statistical operations between the columns of this DataFrame, such as:\n",
    "\n",
    "#### Statistcal functions\n",
    "* Sum: `.sum()`\n",
    "* Mean: `.mean()`\n",
    "* Median: `.median()`\n",
    "\n",
    "### Stacking and stats\n",
    "* Here, we chain the `stack` and `sum` functions and apply them to the `sales` DataFrame, as seen below $\\Downarrow$\n",
    "* We set `axis` to `1` to apply the functions over the column axis\n",
    "\n",
    "<img src='data/pivot68.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* To turn the shop level of row index into a column index, we could chain the previous sequence to the unstack method, as shown below $\\Downarrow$\n",
    "* This will yield the same result, but in a different, wider format: now `online` and `onsite` are column labels \n",
    "\n",
    "<img src='data/pivot69.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba42d9c",
   "metadata": {},
   "source": [
    "### Unstacking and stats\n",
    "* To obtain the mean amount of products sold for each year in both countries, we can unstack the first level of sales and then apply the `mean` function\n",
    "* Again, we set `axis` to `1` to specify the column axis\n",
    "\n",
    "<img src='data/pivot70.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "***\n",
    "* Now, we'll get the difference in the amount of office supplies sold in 2018 compared to 2017\n",
    "* First, we select the `office supply` column of sales and unstack the `country` level:\n",
    "    * `sales['office supply'].unstack(level='country')`\n",
    "* After that, we apply the function `diff()`\n",
    "* **`diff()`** finds the difference between columns or rows\n",
    "    * By setting the `axis` parameter to `1`, we apply it over the columns\n",
    "    * By setting `periods` to `2`, we calculate between a column and every other column\n",
    "* The output is a DataFrame with values representing the difference between the first and third column, and the second and fourth column, as seen below \n",
    "\n",
    "<img src='data/pivot71.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Reshaping and grouping\n",
    "* The `stack` and `unstack` functions can also be used with grouping functions such as `groupby`\n",
    "* Say we want the total amount of different products by online or onsite regardless of country\n",
    "* First, we will stack the DataFrame\n",
    "* THis will result in the `shop` column being the innermost level of the index\n",
    "\n",
    "<img src='data/pivot72.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* After that, we group the data by the type of shop\n",
    "* We set the `level` parameter to the desired column name, `shop`\n",
    "* Then, we chain it with the `sum()` function\n",
    "* As a result, we will get the total amount of office suppy or technology purchased online or onsite, as shown:\n",
    "\n",
    "<img src='data/pivot73.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* When grouping columns, the resulting DataFrame will have the grouping factor as the row index\n",
    "* In the code, we group the data by `year` and then calculate the `median()`\n",
    "* The output is a DataFrame where year is now the row index\n",
    "\n",
    "<img src='data/pivot74.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We can also chain these operations to the `stack` and `unstack` function to reshape the data\n",
    "* Below, we stack the first and second level, and then unstack the year level, and get a DataFrame containing the mean amount of products sold by year where shop and product are now the row indexes\n",
    "\n",
    "<img src='data/pivot75.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e195310",
   "metadata": {},
   "source": [
    "#### Exercises: Less fast food, please!\n",
    "\n",
    "```\n",
    "# Unstack the first level and calculate the mean of the columns\n",
    "obesity_general = obesity.unstack(level=0).mean(axis=1)\n",
    "\n",
    "# Print obesity_general\n",
    "print(obesity_general)\n",
    "```\n",
    "\n",
    "```\n",
    "# Unstack the second level and calculate the mean of the columns\n",
    "obesity_mean = obesity.unstack(level=1).mean(axis=1)\n",
    "\n",
    "# Print obesity_mean\n",
    "print(obesity_mean)\n",
    "```\n",
    "\n",
    "```\n",
    "# Unstack the third level and calculate the difference between columns\n",
    "obesity_variation = obesity.unstack(level=2).diff(axis=1)\n",
    "\n",
    "# Print obesity_variation\n",
    "print(obesity_variation)\n",
    "```\n",
    "\n",
    "#### Exercises: Only going up\n",
    "\n",
    "```\n",
    "# Stack obesity, get median of columns and unstack again\n",
    "median_obesity = obesity.stack().median(axis=1).unstack()\n",
    "\n",
    "# Print median_obesity\n",
    "print(median_obesity)\n",
    "```\n",
    "\n",
    "```\n",
    "# Stack the first level, get sum, and unstack the second level\n",
    "obesity_sum = obesity.stack(level=0).sum(axis=1).unstack(level=1)\n",
    "\n",
    "# Print obesity_max\n",
    "print(obesity_sum)\n",
    "```\n",
    "\n",
    "#### Exercises: a group analysis\n",
    "\n",
    "```\n",
    "# Stack country level, group by country and get the mean\n",
    "obesity_mean = obesity.stack(level='country').groupby('country').mean()\n",
    "\n",
    "# Print obesity_mean\n",
    "print(obesity_mean)\n",
    "```\n",
    "\n",
    "```\n",
    "# Stack country level, group by country and get the median \n",
    "obesity_median = obesity.stack('country').groupby('country').median()\n",
    "\n",
    "# Print obesity_median\n",
    "print(obesity_median)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df2d5a",
   "metadata": {},
   "source": [
    "### Transforming a list-like column\n",
    "* In most (if not all?) of the cases we've examined thus far, our columns have contained single values\n",
    "* But, **what if we have a column that contains values in a list**, such as the `zip code` column in the example below?\n",
    "\n",
    "<img src='data/pivot76.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* This type of column (`zip code`) is called a **list-like column** \n",
    "* It is often difficult to work with columns in this format\n",
    "* The best approach is to transform each list-like column into a separate row, as illustrated in the image above\n",
    "* pandas provides us with the **`.explode()`** method to help with this precise operation\n",
    "* Image we have the following DataFrame $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot77.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We can explode the values of zip code to a separate row\n",
    "* For that, we select the column `zip code` from the DataFrame and call the `explode()` method\n",
    "* As a result, we get a pandas Series with each value in a different row:\n",
    "\n",
    "<img src='data/pivot78.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* As you can see $\\Uparrow$ this replicated the index values from the original row\n",
    "* Now, let's get this information back in the original DataFrame\n",
    "* First, we select the rest of the columns: `city` and `country`\n",
    "* We then apply the `merge()` method and pass the exploded series `cities_explode`.\n",
    "* This method will join both data structures together\n",
    "* We need to specify how to join them\n",
    "* Because the index is replicted, we can use this to track the original row\n",
    "* We se the parameters `left_index` and `right_index` to `True`; this will tell pandas to join the rows with the same index\n",
    "* As a result, we get the original DataFrame but with each value of `zip_code` in a separate row $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot79.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Exploding a column in the Data Frame\n",
    "* We can explode the `zip code` column in the `cities` DataFrame\n",
    "* For that, we apply the `explode()` method on the whole DataFrame\n",
    "* Then, we pass the name of the column we want to explode\n",
    "* As a result, we get a DataFrame but with each value of `zip_code` in a separate row\n",
    "* Again, this operation replicated the index values \n",
    "\n",
    "<img src='data/pivot80.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We can use the `reset_index` method to modify the DataFrame without keeping the original index\n",
    "\n",
    "<img src='data/pivot81.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Empty lists\n",
    "* In the following DataFrame $\\Downarrow$, notice an **empty list** in the second row.\n",
    "* **The `explode` method will replace the empty list with a `NaN` value**\n",
    "* We have to be careful with newly generated missing values for this reason\n",
    "\n",
    "<img src='data/pivot82.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Chaining operation \n",
    "* Below is the `cities` DataFrame again, but this time, the `zip code` column does not contain lists, but rather comma-separated strings\n",
    "* How can we expand this column?\n",
    "\n",
    "<img src='data/pivot83.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We have seen how to split strings using the `split()` method of the `str` module\n",
    "* But this leads to separated columns, as shown below (when we want separated rows) $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot84.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* We will call the **`assign()`** method on the `cities` DataFrame\n",
    "* This method allows us to assign values to columns \n",
    "* We specify we want to set the `zip code` column to the values after splitting the `zip code` column\n",
    "* Then, we chain this operation to the `explode()` method\n",
    "* As a result, we get the `zip code` values in separated rows, as we wanted\n",
    "\n",
    "<img src='data/pivot85.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d552fb",
   "metadata": {},
   "source": [
    "#### Exercises: Merge it all!\n",
    "\n",
    "```\n",
    "# Explode the values of bounds to a separate row\n",
    "obesity_bounds = obesity['bounds'].explode()\n",
    "\n",
    "# Print obesity_bounds\n",
    "print(obesity_bounds)\n",
    "```\n",
    "\n",
    "```\n",
    "# Explode the values of bounds to a separate row\n",
    "obesity_bounds = obesity['bounds'].explode()\n",
    "\n",
    "# Merge obesity_bounds with country and perc_obesity columns of obesity using the indexes\n",
    "obesity_final = obesity[['country', 'perc_obesity']].merge(obesity_bounds, \n",
    "                                        right_index=True, \n",
    "                                        left_index=True)\n",
    "\n",
    "# Print obesity_final\n",
    "print(obesity_final)\n",
    "```\n",
    "\n",
    "#### Exercises: Explode the bounds\n",
    "\n",
    "```\n",
    "# Transform the list-like column named bounds  \n",
    "obesity_explode = obesity.explode('bounds')\n",
    "\n",
    "# Modify obesity_explode by resetting the index \n",
    "obesity_explode.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print obesity_explode\n",
    "print(obesity_explode)\n",
    "```\n",
    "\n",
    "#### Exercises: The good old split\n",
    "\n",
    "```\n",
    "# Split the columns bounds using a hyphen as delimiter\n",
    "obesity_split = obesity['bounds'].str.split('-')\n",
    "\n",
    "# Print obesity_split\n",
    "print(obesity_split)\n",
    "```\n",
    "\n",
    "```\n",
    "# Assign the result of the split to the bounds column\n",
    "obesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-'))\n",
    "\n",
    "# Print obesity\n",
    "print(obesity_split)\n",
    "```\n",
    "\n",
    "```\n",
    "# Transform the column bounds in the obesity DataFrame\n",
    "obesity_split = obesity.assign(bounds=obesity['bounds'].str.split('-')).explode('bounds')\n",
    "\n",
    "# Print obesity_split\n",
    "print(obesity_split)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf657e",
   "metadata": {},
   "source": [
    "# Reading nested data into a DataFrame\n",
    "\n",
    "## JSON format\n",
    "* JSON stands for **JavaScript Object Notation**\n",
    "* **Data-interchange format** that is **human-readable**\n",
    "* Easy for humans to read and write\n",
    "* Easy for machines to parse and generate\n",
    "* JSON files are commonly used when sharing data between applications and data scientists, saving information (or **metadata** about a dataset), or reading data from an API\n",
    "* JSON format is very similar to a dictionary\n",
    "\n",
    "#### Simple JSON format\n",
    "* Here is an example of a very simple JSON\n",
    "\n",
    "<img src='data/pivot86.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Nested JSON\n",
    "* Oftentimes we will be working with a nested JSON, like the one below\n",
    "* We can see that we have a **dictionary inside a list and a dictionary inside a dictionary**\n",
    "* These are more complex data to work with\n",
    "\n",
    "<img src='data/pivot87.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Data normalization\n",
    "* For those cases, we can use the `json_normalize` function from pandas\n",
    "* **`json_normalize()`** takes our nested JSON object, flattens it out, and reads it into a DataFrame\n",
    "\n",
    "<img src='data/pivot88.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* By default, `json_normalize` uses a period to indicate nested levels\n",
    "* To change that, we can use the `sep` parameter\n",
    "\n",
    "<img src='data/pivot89_b.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* Now, the last two column names are separated by an underscore\n",
    "\n",
    "#### Reshaping a normalized nested JSON\n",
    "* We can take advantage of the names \n",
    "* We can reshape the DataFrame using the `pd.wide_to_long` function, setting `'books'` as `stubnames`, an underscore as the separators, and the regex expression for word-endings `'\\w+'` to indicate the columns end in a word\n",
    "\n",
    "<img src='data/pivot90.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "## Complex JSON\n",
    "* Now, let's analyze the even-more-complex JSON pictured below $\\Downarrow$\n",
    "* We have not only nested dictionaries, but the books keys now have a list of dictionaries as values\n",
    "\n",
    "<img src='data/pivot91.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* If we apply `json_normalize()` as before, the books column is still not flattened out, as shown below $\\Downarrow$\n",
    "\n",
    "<img src='data/pivot92.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Record path\n",
    "* In this case, we can use the `record_path` parameter\n",
    "* **`record_path`** tells pandas what key path leads to each individual observation in the JSON\n",
    "\n",
    "<img src='data/pivot93.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* In the output, the `books` column has been converted into two columns, `title` and `year`\n",
    "\n",
    "### Metadata\n",
    "* We can add a third parameter, the `meta` parameter\n",
    "* The **`meta`** parameter tells pandas what data we want to include from the rest of the JSON\n",
    "\n",
    "<img src='data/pivot94.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* Now, we can see the rest of the data present in the resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a640863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254d188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2db628b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc35f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37bee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68541096",
   "metadata": {},
   "source": [
    "<img src='data/pivot.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
