{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd23576e",
   "metadata": {},
   "source": [
    "# Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e0f09",
   "metadata": {},
   "source": [
    "#### Unsupervised Learning Basics\n",
    "* **Unsupervised learning:** a group of machine learning algorithms that find patterns in unlabeled data.\n",
    "* Data used in these algorithms has not been labeled, classified, or characterized in any way.\n",
    "* The objective of the algorithm is to interpret any inherent structure(s) in the data.\n",
    "* Common unsupervised learning algorithms: clustering, neural networks, anomaly detection\n",
    "\n",
    "#### Clustering\n",
    "* The process of grouping items with similar characteristics\n",
    "* The groups are formed as such that items in a single group are closer to eachother in terms of some characteristics as compared to items in other clusters\n",
    "* A **cluster** is a group of items with similar characteristics\n",
    "    * For example, Google News articles where similar words and word associations appear together\n",
    "    * Customer Segmentation\n",
    "* Clustering algorithms:\n",
    "    * Hierarchical clustering $\\Rightarrow$ Most common\n",
    "    * K means clustering $\\Rightarrow$ Most common\n",
    "    * Other clustering algorithms: DBSCAN (Density based), Gaussian Methods\n",
    "    \n",
    "```\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns, pandas as pd\n",
    "\n",
    "x_coordinates = [80.1, 93.1, 86.6, 98.5, 86.4, 9.5, 15.2, 3.4, 10.4, 20.3, 44.2, 56.8, 49.2, 62.5, 44.0]\n",
    "y_coordinates = [87.2, 96.1, 95.6, 92.4, 92.4, 57.7, 49.4, 47.3, 59.1, 55.5, 25.6, 2.1, 10.9, 24.1, 10.3]\n",
    "\n",
    "df = pd.DataFrame({'x_coordinate': x_coordinates, 'y_coordinate' : y_coordinates})\n",
    "\n",
    "Z = linkage(df, 'ward')\n",
    "df['cluster_labels'] = fcluster(Z, 3, criterion = 'maxclust')\n",
    "sns.scatterplot(x='x_coordinate', y='y_coordinate', hue = 'cluster_labels', data=df)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381cc51",
   "metadata": {},
   "source": [
    "### K-means clustering in SciPy\n",
    "\n",
    "```\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns, pandas as pd\n",
    "\n",
    "import random\n",
    "random.seed((1000, 2000))\n",
    "\n",
    "x_coordinates = [80.1, 93.1, 86.6, 98.5, 86.4, 9.5, 15.2, 3.4, 10.4, 20.3, 44.2, 56.8, 49.2, 62.5, 44.0]\n",
    "y_coordinates = [87.2, 96.1, 95.6, 92.4, 92.4, 57.7, 49.4, 47.3, 59.1, 55.5, 25.6, 2.1, 10.9, 24.1, 10.3]\n",
    "\n",
    "df = pd.DataFrame({'x_coordinate': x_coordinates, 'y_coordinate' : y_coordinates})\n",
    "\n",
    "centroids,_ = kmeans(df, 3) # second argument is 'distortion' represented by dummy variable '_'\n",
    "df['cluster_labels'],_ = vq(df, centroids) # second argument is 'distortion' represented by dummy variable '_'\n",
    "\n",
    "sns.scatterplot(x='x_coordinate', y='y_coordinate', hue='cluster_labels', data=df)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e58cc",
   "metadata": {},
   "source": [
    "#### Data preparation for cluster analysis\n",
    "Why prepare data for clustering?\n",
    "* Variables may have incomparable units (product dimensions in cm, price in dollars)\n",
    "* Even if variables have the same unit, they may be significantly different in terms of their scales and variances\n",
    "* Data in raw form may lead to bias in clustering\n",
    "* Clusters may be heavily dependent on one variable\n",
    "* **Solution:** normalization of variables\n",
    "\n",
    "* **Normalization:** process of rescaling data to a standard deviation of 1: `x_new = x / std(x)`\n",
    "    * normalization library: `from scipy.cluster.vq import whiten`\n",
    "    * `scaled_data = whiten(data)`\n",
    "    * output is an array of the same dimensions as original `data`\n",
    "**Illustration of the normalization of data:**\n",
    "\n",
    "```\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(data, label = \"original\")\n",
    "plt.plot(scaled_data, label = \"scaled\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "* By default, pyplot plots line graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea656328",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2a294",
   "metadata": {},
   "source": [
    "#### Creating a distance matrix using linkage\n",
    "\n",
    "`scipy.cluster.hierarchy.linkage(observations, method='single', metric='euclidean', optimal_ordering=False)`\n",
    "* This process computes the distances between clusters as we go from n clusters to one cluster where n is the number of points\n",
    "* `method`: how to calculate the proximity of clusters\n",
    "* `metric`: distance metric (Euclidean, Manhattan...)\n",
    "* `optimal_ordering`: order data points (optional argument)\n",
    "\n",
    "* **`method`**:\n",
    "    * **single:** based on two closest objects (clusters tend to be more dispersed)\n",
    "    * **complete:** based on two farthest objects\n",
    "    * **average:** based on the arithmetic mean of all objects\n",
    "    * **centroid:** based on the geometric mean of all objects\n",
    "    * **median:** based on the median of all objects\n",
    "    * **ward:** based on the sum of squares (clusters tend to be dense towards the centers)\n",
    "    \n",
    "* **Create cluster labels with fcluster:**\n",
    "`scipy.cluster.hierarchy.fcluster(distance_matrix, num_clusters, criterion)`\n",
    "* `distance_matrix`: output of `linkage` method\n",
    "* `num_clusters`: number of clusters\n",
    "* `criterion`: how to decide thresholds to form clusters\n",
    "\n",
    "* **Note** that in all seaborn plots, an extra cluster with label 0 is shown even though no objects are present in it. This can be removed it you store the cluster labels as strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836dd2bd",
   "metadata": {},
   "source": [
    "#### Visualize Clusters\n",
    "* Visualizing clusters may help to make sense of clusters formed or identify number of clusters\n",
    "* Visualizing can serve as an additional step in the validation of clusters formed\n",
    "* May help you to spot trends in data\n",
    "* For clustering, we will often use pandas DataFrames to store our data, often adding a separate column for cluster centers\n",
    "\n",
    "```\n",
    "df = pd.DataFrame({'x':[2, 3, 5, 6, 2], 'y': [1, 1, 5, 5, 2], 'labels': ['A', 'A', 'B', 'B', 'A']})\n",
    "```\n",
    "#### Visualizing clusters with matplotlib\n",
    "\n",
    "```\n",
    "from matplotlib import pyplot as plt\n",
    "colors = {'A': 'red', 'B': 'blue'}\n",
    "df.plot.scatter(x='x', y='y', c = df['labels'].apply(lambda x: colors[x]))\n",
    "plt.show()\n",
    "```\n",
    "* We use the `c` argument of the scatter method to assign a color to each cluster\n",
    "* However, we first need to manually map each cluster to a color\n",
    "* Create dictionary `colors` with the cluster labels as keys and respectively associated colors as values\n",
    "\n",
    "#### Visualizing clusters with seaborn\n",
    "\n",
    "```\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x = 'x', y = 'y', hue = 'labels', data = df)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "* Two reasons to prefer seaborn:\n",
    "    * 1) For implementation, using seaborn is more convenient once you have stored cluster labels in your dataframe\n",
    "    * 2) You do not need to manually select colors (there is a default palette that you can manually change if you so choose, but is not necessary)\n",
    "    \n",
    "#### Determining how many clusters with dendrograms\n",
    "* ** Dendrograms:**\n",
    "    * dendrograms help show progressions as clusters are merged\n",
    "    * a dendrogram is a branching diagram that demonstrates how each cluster is composed by branching out into its child nodes\n",
    "    \n",
    "```\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "Z = linkage(df[['x_whiten', 'y_whiten']], method = 'ward', metric = 'euclidean')\n",
    "dn = dendrogram(Z)\n",
    "plt.show()\n",
    "```\n",
    "* Recall the hierarchical clustering algorithm, where each step was a result of merging the two closest clusters in the earlier step\n",
    "* The x-axis of a dendrogram represents individual points, whereas the y-axis represents the distance or dissimilarity between clusters\n",
    "* The inverted U at the top of a dendrogram represents a single cluster of all datapoints\n",
    "* The width of the inverted U-shape represents the distance between the two child clusters. Therefore, a wider inverted-U shape means that the two child clusters were further away from each other as compared to a narrower inverted-U in the diagram.\n",
    "* If you draw a horizontal line at any part of the figure, the number of vertical lines it intersects with tells you the number of clusters at that stage and the distance between those vertical lines indicates the **intercluster distance.**\n",
    "* **Note:** There is no \"right\" metric to determine \"how many\" clusters are ideal.\n",
    "* An additional step of visualizing the data in a scatter plot (after visualizing it in a dendrogram) may be helpful before deciding on the number of clusters.\n",
    "\n",
    "```\n",
    "# Import the dendrogram function\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# Create a dendrogram\n",
    "dn = dendrogram(distance_matrix)\n",
    "\n",
    "# Display the dendogram\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f5d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b85cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102aa6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f7fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e58617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
