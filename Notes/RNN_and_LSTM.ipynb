{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1943b416",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNN) and Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae77b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a59b1",
   "metadata": {},
   "source": [
    "* **Image recognition** $\\Rightarrow$ mostly **CNNs**\n",
    "* **Speech-to-text** $\\Rightarrow$ mostly **RNNs**, particularly **LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd16a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to display image using IPython's display() function (no alignment):\n",
    "#display(Image(filename='data/whats_for_dinner.png', width = 600, height = 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d663de",
   "metadata": {},
   "source": [
    "*Image display code in markdown cell*\n",
    "<img src='data/whats_for_dinner.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "<img src='data/how_nns_work.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b4eca",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks\n",
    "* On a very basic level, you can think of neural networks as a very complicated \"voting process\" (over-simplification)\n",
    "* Say we know that our roommate has a very consistent cycle of what they make for dinner: pizza then sushi then waffles then sushi. We can easily (and 100% accurately) predict what they will make for dinner tonight, knowing what they made last night. But say we weren't home last night (so don't know what he made last night for dinner). Well, we would just think back to the night before and calculate accordingly:\n",
    "<img src='data/yester_yesterday.png' width=\"500\" height=\"250\" align=\"center\"/>\n",
    "***\n",
    "#### A vector describing the weather:\n",
    "<img src='data/weather_vectors.png' width=\"500\" height=\"250\" align=\"center\"/>\n",
    "\n",
    "* Vectors are computer's native language; everything gets reduced to a list of numbers before it goes into an algorithm.\n",
    "\n",
    "#### A vector for \"It's Tuesday\":\n",
    "<img src='data/its_tuesday.png' width=\"500\" height=\"250\" align=\"center\"/>\n",
    "\n",
    "#### A vector for our prediction for dinner tonight:\n",
    "<img src='data/dinner_pred.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c4097",
   "metadata": {},
   "source": [
    "We can also group together our inputs and outputs as vectors, or separate lists of numbers\n",
    "<img src='data/din_vects.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27371bdc",
   "metadata": {},
   "source": [
    "Here we can see how our prediction for one day get's recycled for the next day's dinner prediction:\n",
    "<img src='data/rec_pred.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba91cb2",
   "metadata": {},
   "source": [
    "Above you can see how you can still make a prediction about what is for dinner tonight, even if, say, we've been out of town for two weeks. We just ignore the \"new information\" part and unwind this vector in time until we do have some information to base it on.\n",
    "\n",
    "When these vectors are unwrapped, they look like this:\n",
    "<img src='data/unrolled_vects.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718360de",
   "metadata": {},
   "source": [
    "The above charts are a very nice and tidy picture of **Recurrent Neural Networks**\n",
    "\n",
    "* The **hyperbolic tangent (tanh) squashing function** helps the model to \"behave\":\n",
    "    * Sigmoid shape ranging from -1 to 1\n",
    "    * tanh squashing function **symbol**:\n",
    "<img src='data/tanh_sym.png' align=\"center\"/>    \n",
    "    * For small numbers, your \"squashed version\" is very similar to your original number\n",
    "    * As your number gets larger, it gets more and more squashed\n",
    "<img src='data/tanh_squash.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab25b6f",
   "metadata": {},
   "source": [
    "* By ensuring that the output is always less than 1 and more than -1, you can process information through the model loops as many times as you want, without risking explosively large (nonsensical) or small (meaningless) outputs.\n",
    "    * In a feedback loop, this is an example of **negative feedback** or **atenuating feedback**\n",
    "    \n",
    "#### Mistakes an RNN can make\n",
    "* `Doug saw Doug.`\n",
    "* `Jane saw Spot saw Doug saw... `\n",
    "* `Spot. Doug. Jane.`\n",
    "* **Because each of our predictions only looks back one time step (it has very short-term memory), it doesn't use the information from further back and it's subject to these types of mistakes.**\n",
    "* In order to overcome this, we take our Recurrent Neural Network and we expand it and add some more pieces to it\n",
    "* The critical part that we add to the middle is **`memory`**; we want to be able to remember what happened many time steps ago.\n",
    "<img src='data/memory.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5eb8ca",
   "metadata": {},
   "source": [
    "* Above, you'll notice we've add a few more symbols.\n",
    "* First, the plus junction: \n",
    "\n",
    "### Plus Junction\n",
    "<img src='data/plus.png' align=\"center\"/>\n",
    "<img src='data/plus_junc.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234f8fb",
   "metadata": {},
   "source": [
    "* Input vectors of equal length\n",
    "* Output vector is of same size as each of your input vectors\n",
    "* Output vector is the sum, element by element, of the two input vectors\n",
    "\n",
    "### Times Junction\n",
    "<img src='data/times_sym.png' align=\"center\"/>\n",
    "<img src='data/times_junc.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356eaa8",
   "metadata": {},
   "source": [
    "* Times junction: element by element multiplication \n",
    "* Once again, input vectors are of same size as output vector\n",
    "* The times junction allows you to do something pretty cool called **Gating** (similar to weighting?)\n",
    "\n",
    "### Gating\n",
    "<img src='data/gating.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16339027",
   "metadata": {},
   "source": [
    "* Gating lets us control what passes through and what gets blocked\n",
    "* To do gating, it's nice to have a value that you know is always between 0 and 1 \n",
    "\n",
    "### Logistic (Sigmoid) Function\n",
    "<img src='data/sig_squash_sym.png' align=\"center\"/>\n",
    "<img src='data/sig_squash_junc.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5353a",
   "metadata": {},
   "source": [
    "* Minimum of 0, maximum 1\n",
    "\n",
    "\n",
    "When we put all of these things together, we get:\n",
    "<img src='data/memory.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715245f",
   "metadata": {},
   "source": [
    "* We still have the combination of our previous predictions and our new information.\n",
    "* Those vectors get passed below and we make predictions based upon them \n",
    "* Those predictions get passed through, but **a copy of those predictions is held onto for the nex time step, the next pass through the network**\n",
    "    * **Some of them are forgotten**\n",
    "    * **Some of them are remembered**\n",
    "        * **The ones that are remembered are added back into the prediction**\n",
    "<img src='data/remembered_pred.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c703812",
   "metadata": {},
   "source": [
    "* So now we have not just prediction, but predictions, but **predictions plus the memories that we've accumulated and that we haven't chosen to forget yet.**\n",
    "* **There is an entirely separate neural network here to decide when to forget what:**\n",
    "<img src='data/memory_nn.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5640ae7",
   "metadata": {},
   "source": [
    "* Basically: \"Based on what we're seeing right now, what do we want to remember? What do we want to forget?\"\n",
    "* This lets us hold to things for as long as we want\n",
    "* **When we are combining our predictions with our memories, we may not necessarily want to release all of those memories out as new predictions each time**\n",
    "<img src='data/mem_release.png' width=\"500\" height=\"250\" align=\"center\"/>\n",
    "<img src='data/selection.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f5f5d",
   "metadata": {},
   "source": [
    "* So, we want a filter to keep our memories inside and let our predictions out\n",
    "* We add another gate for that to do **selection** (see above)\n",
    "* **Selection** has it's own neural network, so it's own voting process, so that our new information and our previous predictions can be used to vote on what all the gates should be, what should be kept internal and what should be released as a prediction\n",
    "* We also introduce another squashing function after the plus junction to make sure that we keep our predictions within the realms of -1 to 1\n",
    "* Each of these things (when to forget and when to release things from memory) are learned by their own neural networks \n",
    "\n",
    "### Long short-term memory\n",
    "* The only other piece we need to add to complete our picture here is yet another set of gates which lets us ignore possible predictions\n",
    "* This is an **attention mechanism**\n",
    "* It lets things that aren't immediately relevant be set aside so they don't cloud the predictions in memory going forward\n",
    "* It has its own neural network and its own logistic squashing function and its own gating activity \n",
    "\n",
    "<img src='data/ignoring.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72101f5",
   "metadata": {},
   "source": [
    "* Clearly LSTM has a lot of pieces that work together\n",
    "\n",
    "#### Epoch 1:\n",
    "<img src='data/epoch1.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807c7ad",
   "metadata": {},
   "source": [
    "#### Epoch2: \n",
    "<img src='data/epoch2.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea114e4",
   "metadata": {},
   "source": [
    "* **What this shows is that LSTM can look back 2, 3, many time steps... and use that information to make good predictions about what's going to happen next.**\n",
    "    * As a note: regular, vanilla neural networks can look back a couple time steps as well, but not very many\n",
    "    * **LSTM can look back many time steps**\n",
    "    \n",
    "    \n",
    "## Sequential Patterns\n",
    "* LSTMs are really useful in some surprisingly practical applications:\n",
    "    * Text\n",
    "        * translation; LSTM is able to represent word-to-word, phrase-to-phrase, sentence-to-sentence grammar structures\n",
    "    * Speech\n",
    "    * Audio\n",
    "    * Video\n",
    "    * Physical Processes\n",
    "    * Robotics\n",
    "    * Anything embedded in time (almost everything)\n",
    "    \n",
    "#### Mathematical structure of LSTMs\n",
    "<img src='data/LSTM_math.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
