{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ab5767",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow in Python\n",
    "Not long ago, cutting-edge computer vision algorithms couldn’t differentiate between images of cats and dogs. Today, a skilled data scientist equipped with nothing more than a laptop can classify tens of thousands of objects with greater accuracy than the human eye. In this course, you will use TensorFlow 2.6 to develop, train, and make predictions with the models that have powered major advances in recommendation systems, image classification, and FinTech. You will learn both high-level APIs, which will enable you to design and train deep learning models in 15 lines of code, and low-level APIs, which will allow you to move beyond off-the-shelf routines. You will also learn to accurately predict housing prices, credit card borrower defaults, and images of sign language gestures.\n",
    "\n",
    "**Instructor:** Isaiah Hull, senior economist at Sweden's Central Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545a42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import constant, add, ones, matmul, multiply, reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39687257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a25aec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x0):\n",
    "  \t# Define x as a variable with an initial value of x0\n",
    "\tx = Variable(x0)\n",
    "\twith GradientTape() as tape:\n",
    "\t\ttape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "\t\ty = multiply(x,x)\n",
    "    # Return the gradient of y with respect to x\n",
    "\treturn tape.gradient(y, x).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aaa5f9",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 1: Introduction to TensorFlow\n",
    "Before you can build advanced models in TensorFlow 2, you will first need to understand the basics. In this chapter, you’ll learn how to define constants and variables, perform tensor addition and multiplication, and compute derivatives. Knowledge of linear algebra will be helpful, but not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7312447",
   "metadata": {},
   "source": [
    "### Constants and variables\n",
    "* TensorFlow's two basic objects of computation are: **constants** and **variables**\n",
    "\n",
    "#### What is TensorFlow?\n",
    "* An open-source library for graph-based numerical computation\n",
    "    * Developed by the Google Brain Team\n",
    "* Low- and high-level APIs\n",
    "    * Addition, multiplication, differentiation\n",
    "    * Design and train machine learning models\n",
    "* Important changes in TensorFlow 2.0\n",
    "    * Eager execution enabled by default\n",
    "        * Allows users to write simpler and more intuitive code\n",
    "        * Model building with Keras and Estimators (high-level APIs)\n",
    "        \n",
    "#### What is a tensor?\n",
    "* The TensorFlow documentation describes a **tensor** as \"generalization of vectors and matrices to potentially higher dimensions.\"\n",
    "* If you're not familiar with linear algebra, think of a tensor as **a collection of numbers, which is arranged into a particular shape**.\n",
    "    * 0-dimensional: point\n",
    "    * 1-dimensional: line\n",
    "    * etc\n",
    "    \n",
    "### Defining tensors in TensorFlow\n",
    "* Each object defined below will be a `tf.Tensor object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12963ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# 0D Tensor\n",
    "d0 = tf.ones((1,))\n",
    "\n",
    "# 1D Tensor\n",
    "d1 = tf.ones((2,))\n",
    "\n",
    "# 2D Tensor\n",
    "d2 = tf.ones((2, 2))\n",
    "\n",
    "# 3D Tensor\n",
    "d3 = tf.ones((2, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc08fda",
   "metadata": {},
   "source": [
    "If we want to print the array contained in that object, we can apply the `.numpy()` method and pass the resulting object to the print function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d62af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# Print the 3D tensor\n",
    "print(d3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899de03",
   "metadata": {},
   "source": [
    "### Defining constants in TensorFlow\n",
    "* A **constant** the simplest category of tensor\n",
    "* A constant does not change and cannot be trained\n",
    "    * Immutable\n",
    "    * Untrainable\n",
    "* A constant can have any dimension\n",
    "* In the code below, we've defined two constants:\n",
    "    * `a` is a 2x3 tensor of 3s\n",
    "    * `b` is a 2x2 tensor which is constructed from the 1-dimensional tensor: 1, 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab34e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import constant\n",
    "\n",
    "# Define a 2x3 constant\n",
    "a = constant(3, shape=[2, 3])\n",
    "\n",
    "# Define a 2x2 constant\n",
    "b = constant([1, 2, 3, 4], shape=[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a5240f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 3]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897ac6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9ec03",
   "metadata": {},
   "source": [
    "* Above we worked exclusively with the constant operation\n",
    "* However, in some cases, there are more convenient options for defining certain types of special tensors\n",
    "<img src='data/convenience_functions.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b92ea",
   "metadata": {},
   "source": [
    "* Use the `.zeros` or `.ones` operations to generate a tensor of arbitrary (but defined) dimension, that is populated entirely with zeros or ones\n",
    "* Use the `zeros_like` or `ones_like` operations to populate tensors with zeros and ones, copying the dimensions of some input tensor passed to it.\n",
    "* Use the `.fill` operation to populate a tensor of arbitrary dimension with the same scalar value in each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f414d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_ex = tf.fill([3, 3],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb7e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 7 7]\n",
      " [7 7 7]\n",
      " [7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "print(fill_ex.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933bdd7",
   "metadata": {},
   "source": [
    "### Defining and initializing variables\n",
    "* Unlike a constant, a variable's value can change during computation\n",
    "* The value of a variable is **shared**, **persistent**, and **modifiable**.\n",
    "* A variable's **data type and shape are fixed**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50a680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# Define a variable\n",
    "a0 = tf.Variable([1, 2, 3, 4, 5, 6], dtype=tf.float32)\n",
    "a1 = tf.Variable([1, 2, 3, 4, 5, 6], dtype=tf.int16)\n",
    "\n",
    "# Define a constant\n",
    "b = tf.constant(2, tf.float32)\n",
    "\n",
    "# Compute their product\n",
    "c0 = tf.multiply(a0, b)\n",
    "c1 = a0 * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "695dff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  4.  6.  8. 10. 12.]\n",
      "[ 2.  4.  6.  8. 10. 12.]\n"
     ]
    }
   ],
   "source": [
    "print(c0.numpy())\n",
    "print(c1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e924966",
   "metadata": {},
   "source": [
    "* Note that certain TensorFlow operations, such as `tf.multiply` are overloaded, which allows us to use the simpler `a0*b` expression instead.\n",
    "\n",
    "#### Exercises: Defining data as constants\n",
    "Throughout this course, we will use `tensorflow` version 2.6.0 and will exclusively import the submodules needed to complete each exercise. This will usually be done for you, but you will do it in this exercise by importing `constant` from `tensorflow`.\n",
    "\n",
    "After you have imported `constant`, you will use it to transform a `numpy` array, `credit_numpy`, into a `tensorflow` constant, `credit_constant`. This array contains feature columns from a dataset on credit card holders and is previewed in the image below. We will return to this dataset in later chapters.\n",
    "\n",
    "Note that `tensorflow` 2 allows you to use data as either a `numpy` array or a `tensorflow` `constant` object. Using a constant will ensure that any operations performed with that object are done in `tensorflow`.\n",
    "\n",
    "```\n",
    "# Import constant from TensorFlow\n",
    "from tensorflow import constant\n",
    "\n",
    "# Convert the credit_numpy array into a tensorflow constant\n",
    "credit_constant = constant(credit_numpy)\n",
    "\n",
    "# Print constant datatype\n",
    "print('\\n The datatype is:', credit_constant.dtype)\n",
    "\n",
    "# Print constant shape\n",
    "print('\\n The shape is:', credit_constant.shape)\n",
    "```\n",
    "\n",
    "#### Exercises: Defining variables\n",
    "Unlike a constant, a variable's value can be modified. This will be useful when we want to train a model by updating its parameters.\n",
    "\n",
    "Let's try defining and printing a variable. We'll then convert the variable to a `numpy` array, print again, and check for differences. Note that `Variable()`, which is used to create a variable tensor, has been imported from `tensorflow` and is available to use in the exercise.\n",
    "\n",
    "```\n",
    "# Define the 1-dimensional variable A1\n",
    "A1 = Variable([1, 2, 3, 4])\n",
    "\n",
    "# Print the variable A1\n",
    "print('\\n A1: ', A1)\n",
    "\n",
    "# Convert A1 to a numpy array and assign it to B1\n",
    "B1 = A1.numpy()\n",
    "\n",
    "# Print B1\n",
    "print('\\n B1: ', B1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e255ce3",
   "metadata": {},
   "source": [
    "### Basic operations\n",
    "* TensorFlow has a model of computation that revolves around the use of graphs\n",
    "* A TensorFlow graph contains edges and nodes, where the edges are tensors and the nodes are operations\n",
    "\n",
    "<img src='data/tf_operation_flow.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "### Applying the addition operator\n",
    "* We first import the constant and add operations so that we may now define 0-, 1-, and 2-dimensional tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "957bbee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import constant and add from tensorflow\n",
    "# from tensorflow import constant, add\n",
    "\n",
    "# Define 0-dimensional tensors\n",
    "A0 = constant([1])\n",
    "B0 = constant([2])\n",
    "\n",
    "# Define 1-dimensional tensors\n",
    "A1 = constant([1, 2])\n",
    "B1 = constant([3, 4])\n",
    "\n",
    "# Define 2-dimensional tensors\n",
    "A2 = constant([[1, 2], [3, 4]])\n",
    "B2 = constant([[5, 6], [7, 8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2485f9",
   "metadata": {},
   "source": [
    "### Applying the addition operator\n",
    "* Finally, let's add them together using the operation for tensor addition\n",
    "* Note that we can perform scalar addition with `A0` and `B0`, vector addition with `A1` and `B1`, and matrix addition with `A2` and `B2`\n",
    "* The `add()` operation performs **element-wise addition** with two tensors\n",
    "* **Element-wise addition requires that both tensors have the same shape:**\n",
    "    * Scalar addition: 1 + 2 = 3\n",
    "    * Vector addition: [1, 2] + [3, 4] = [4, 6]\n",
    "    * Matrix addition:\n",
    "\n",
    "```\n",
    "A = [[1, 2],\n",
    "     [3, 4]]\n",
    "B = [[5, 6], \n",
    "     [7, 8]]\n",
    "A + B = [[6, 8],\n",
    "         [10,12]]\n",
    "```\n",
    "* Furthermore, the `add()` operator is **overloaded**\n",
    "    * We can also perform addition using the plus symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4135e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform tensor addition with add()\n",
    "C0 = add(A0, B0)\n",
    "C1 = add(A1, B1)\n",
    "C2 = add(A2, B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4383693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[4 6]\n",
      "[[ 6  8]\n",
      " [10 12]]\n"
     ]
    }
   ],
   "source": [
    "print(C0.numpy())\n",
    "print(C1.numpy())\n",
    "print(C2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec27c0b",
   "metadata": {},
   "source": [
    "### How to perform multiplication in TensorFlow\n",
    "* We will consider both element-wise and matrix multiplication\n",
    "* **Element-wise multiplication** performed using the `multiply()` operation\n",
    "    * Tensors involved **must have the same shape**\n",
    "* **Matrix multiplication** performed with `matmul()` operator \n",
    "    * The `matmul(A, B)` operation multiplies `A` by `B`\n",
    "    * **Note** that number of columns of `A` must equal the number of rows of `B`\n",
    "    \n",
    "#### Applying the multiplication operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73b364d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import operators from tensorflow\n",
    "# from tensorflow import ones, matmul, multiply\n",
    "\n",
    "# Define tensors\n",
    "A0 = ones(1)\n",
    "A31 = ones([3, 1])\n",
    "A34 = ones([3, 4])\n",
    "A43 = ones([4, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25243bf1",
   "metadata": {},
   "source": [
    "* What types of operations are valid on these tensors of ones?\n",
    "    * We can perform element-wise multiplication of any element by itself\n",
    "        * `multiply(A0, A0)`, `multiply(A31, A31)`, and `multiply(A34, A34)`\n",
    "    * We can perform matrix multiplication on `matmul(A43, A34)`\n",
    "        * but **not** matmul(A43, A43)\n",
    "        \n",
    "### Summing over tensor dimensions\n",
    "* The `reduce_sum()` operator sums over the dimensions of a tensor\n",
    "* This can be used to sum over all dimensions of a tensor or just one.\n",
    "* The `reduce_sum()` operator sums over th dimensions of a tensor\n",
    "    * `reduce_sum(A)` sums over all dimensions of A\n",
    "    * `reduce_sum(A, i)` sums over dimension i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18100327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import operations from tensorflow\n",
    "# from tensorflow import ones, reduce_sum\n",
    "\n",
    "# Define a 2x3x4 tensor of ones\n",
    "F = ones([2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a00c5",
   "metadata": {},
   "source": [
    "* If we sum over all elements of A, we get 24, since the tensor contains 24 elements, all of which are 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3622a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum over all dimensions\n",
    "D = reduce_sum(F)\n",
    "\n",
    "# Sum over dimensions 0, 1, and 2\n",
    "D0 = reduce_sum(F, 0)\n",
    "D1 = reduce_sum(F, 1)\n",
    "D2 = reduce_sum(F, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb9ce7",
   "metadata": {},
   "source": [
    "* If we sum over dimension 0, we get a 3 x 4 matrix of 2s\n",
    "* If we sum over 1, we get a 2 by 4 matrix of 3s\n",
    "* If we sum over 2, we get a 2 x3 matrix of 4s\n",
    "* In each case, we reduce the size of the tensor by summing over one of its dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a67708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fdbd2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(D0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "333e9f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f40031fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4. 4. 4.]\n",
      " [4. 4. 4.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(D2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2151d1b",
   "metadata": {},
   "source": [
    "#### Exercises: Making predictions with matrix multiplication\n",
    "In later chapters, you will learn to train linear regression models. This process will yield a vector of parameters that can be multiplied by the input data to generate predictions. In this exercise, you will use input data, `features`, and a target vector, `bill`, which are taken from a credit card dataset we will use later in the course.\n",
    "\n",
    "<img src='data/mat_mult.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "The matrix of input data, `features`, contains two columns: education level and age. The target vector, `bill`, is the size of the credit card borrower's bill.\n",
    "\n",
    "Since we have not trained the model, you will enter a guess for the values of the parameter vector, `params`. You will then use `matmul()` to perform matrix multiplication of `features` by `params` to generate predictions, `billpred`, which you will compare with `bill`. Note that we have imported `matmul()` and `constant()`.\n",
    "\n",
    "```\n",
    "# Define features, params, and bill as constants\n",
    "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
    "params = constant([[1000], [150]])\n",
    "bill = constant([[3913], [2682], [8617], [64400]])\n",
    "\n",
    "# Compute billpred using features and params\n",
    "billpred = matmul(features, params)\n",
    "\n",
    "# Compute and print the error\n",
    "error = bill-billpred\n",
    "print(error.numpy())\n",
    "```\n",
    "\n",
    "### Advanced Operations\n",
    "* In this lesson, we explore advanced operations:\n",
    "    * `gradient()`\n",
    "    * `reshape()`\n",
    "    * `random()`\n",
    "    \n",
    "<img src='data/adv_ops.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "* **`gradient()`:** \n",
    "    * We will use this function in conjuction with gradient tape\n",
    "    * Computes the slope of a function at a point\n",
    "* **`reshape()`:**\n",
    "    * Changes the shape of a tensor (e.g. 10x10 to 100x1)\n",
    "* **`random()`:**\n",
    "    * Generates a tensor out of randomly-drawn values\n",
    "\n",
    "#### Finding the optimum \n",
    "* In many ML problems, we will need to find the optimum (minimum or maximum) of a function \n",
    "    * **Minimum:** Lowest value of a loss function\n",
    "    * **Maximum:** Highest value of objective function\n",
    "* We can do this using the `gradient()` operation, which tells us the slope of a function at a point\n",
    "    * We start this process by passing points to the gradient operation until we find one where the gradient is zero\n",
    "    * **Optimum:** Find a point where gradient = 0\n",
    "    * **Minimum:** Change in gradient > 0 (if it is increasing, we have a minimum)\n",
    "    * **Maximum:** Change in gradient < 0 (if it is decreasing, we have a maximum)\n",
    "  \n",
    "<img src='data/fixed_gradient.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "* The plot above shows the function `y = x`; notice that the gradient (the slope at a given point) is constant\n",
    "* This is not true is we instead consider the function `y = x**2` ($y=x^2$)\n",
    "    * When `x` is less than 0, `y` decreases when `x` increases\n",
    "    * When `x` is greater than 0, `y` increases when `x` increases\n",
    "    * Thus, the gradient is initially negative, but becomes positive for `x` larger than 0.\n",
    "    * This means that `x = 0` **minimizes** `y`\n",
    "\n",
    "<img src='data/varying_gradient.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0981f54",
   "metadata": {},
   "source": [
    "### Gradients in TensorFlow\n",
    "* We define `x` as `-1.0`\n",
    "* We then define `y` as `x**2` *within an instance of gradient tape*.\n",
    "* **Note** that we apply the `watch()` method to an instance of gradient tape and then pass the variable `x`.\n",
    "* This will allow us to compute the rate of change of `y` with respect to `x`\n",
    "* Next, we compute the gradient of `y` with respect to `x` using the tape instance of gradient tape\n",
    "* **Note that y is the first argument and x is the second**\n",
    "* As written, the operation computes the slope of `y` at a point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eb2b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "# Import tensorflow under the alias tf\n",
    "# import tensorflow as tf\n",
    "\n",
    "# Define x\n",
    "x = tf.Variable(-1.0)\n",
    "\n",
    "# Define y within instance of GradientTape\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.multiply(x, x)\n",
    "    \n",
    "# Evaluate the gradient of y at x = -1\n",
    "g = tape.gradient(y, x)\n",
    "print(g.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839c7fd",
   "metadata": {},
   "source": [
    "* Running the code and printing we find that the slope is -2 at `x = -1`, which means that `y` is initially decreasing in `x`, as seen in the graph above. \n",
    "* Much of the differentiation you do in deep learning models will be handled by high level APIs\n",
    "* However, **gradient tape remains an invaluable tool for building advanced and custom models.**\n",
    "\n",
    "### Reshaping images as tensors\n",
    "* A tool that is particularly usseful for image classification problems: **reshaping**\n",
    "* While some algorithms allow you to exploit the shape of the original image, other require you to `reshape` matrices into vectors before using them as inputs, as shown in the diagram\n",
    "\n",
    "#### Reshaping a grayscale image\n",
    "* Below we create a random grayscale image by drawing numbers from the set of integers between 0 and 255 (grayscale pixel scale) and use these to populate a 2x2 matrix\n",
    "* We can then reshape this into a 4x1 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e2cc38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow as alias tf\n",
    "# import tensorflow as tf\n",
    "\n",
    "# Generate grayscale image\n",
    "gray = tf.random.uniform([2, 2], maxval=255, dtype='int32')\n",
    "\n",
    "# Reshape grayscale image\n",
    "gray = tf.reshape(gray, [2*2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046d9fc",
   "metadata": {},
   "source": [
    "<img src='data/reshape_grayscale.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "#### How to reshape a color image\n",
    "* For color images, we generate 3 such matrices to form a 2x2x3 tensor\n",
    "* We could then reshape the image into a 4x3 tensor, as shown in the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b303b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow as alias tf\n",
    "# import tensorflow as tf\n",
    "\n",
    "# Generate color image\n",
    "color = tf.random.uniform([2, 2, 3], maxval= 255, dtype='int32')\n",
    "\n",
    "# Reshape color image\n",
    "color = tf.reshape(color, [2*2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a94f5a",
   "metadata": {},
   "source": [
    "#### Exercises: Reshaping tensors\n",
    "Later in the course, you will classify images of sign language letters using a neural network. In some cases, the network will take 1-dimensional tensors as inputs, but your data will come in the form of images, which will either be either 2- or 3-dimensional tensors, depending on whether they are grayscale or color images.\n",
    "\n",
    "The figure below shows grayscale and color images of the sign language letter A. The two images have been imported for you and converted to the numpy arrays `gray_tensor` and `color_tensor`. Reshape these arrays into 1-dimensional vectors using the `reshape` operation, which has been imported for you from `tensorflow`. Note that the shape of `gray_tensor` is 28x28 and the shape of `color_tensor` is 28x28x3.\n",
    "\n",
    "<img src='data/asl_a.png' width=\"200\" height=\"100\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58800652",
   "metadata": {},
   "source": [
    "```\n",
    "# Reshape the grayscale image tensor into a vector\n",
    "gray_vector = reshape(gray_tensor, (28*28, 1))\n",
    "\n",
    "# Reshape the color image tensor into a vector\n",
    "color_vector = reshape(color_tensor, (28*28*3, 1))\n",
    "```\n",
    "\n",
    "#### Exercises: Optimizing with gradients\n",
    "You are given a loss function, $y = x^2$, which you want to minimize. You can do this by computing the slope using the `GradientTape()` operation at different values of `x`. If the slope is positive, you can decrease the loss by lowering `x`. If it is negative, you can decrease it by increasing `x`. This is how gradient descent works.\n",
    "\n",
    "<img src='data/varying_gradient.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "In practice, you will use a high level `tensorflow` operation to perform gradient descent automatically. In this exercise, however, you will compute the slope at `x` values of -1, 1, and 0. The following operations are available: `GradientTape()`, `multiply()`, and `Variable()`.\n",
    "\n",
    "```\n",
    "def compute_gradient(x0):\n",
    "  \t# Define x as a variable with an initial value of x0\n",
    "\tx = Variable(x0)\n",
    "\twith GradientTape() as tape:\n",
    "\t\ttape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "\t\ty = multiply(x,x)\n",
    "    # Return the gradient of y with respect to x\n",
    "\treturn tape.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))\n",
    "```\n",
    "\n",
    "#### Exercises: Working with image data\n",
    "You are given a black-and-white image of a `letter`, which has been encoded as a tensor, `letter`. You want to determine whether the letter is an X or a K. You don't have a trained neural network, but you do have a simple model, `model`, which can be used to classify `letter`.\n",
    "\n",
    "The 3x3 tensor, `letter`, and the 1x3 tensor, `model`, are available in the Python shell. You can determine whether `letter` is a K by multiplying `letter` by `model`, summing over the result, and then checking if it is equal to 1. As with more complicated models, such as neural networks, `model` is a collection of weights, arranged in a tensor.\n",
    "\n",
    "Note that the functions `reshape()`, `matmul()`, and `reduce_sum()` have been imported from `tensorflow` and are available for use.\n",
    "\n",
    "```\n",
    "# Reshape model from a 1x3 to a 3x1 tensor\n",
    "model = reshape(model, (3, 1))\n",
    "\n",
    "# Multiply letter by model\n",
    "output = matmul(letter, model)\n",
    "\n",
    "# Sum over output and print prediction using the numpy method\n",
    "prediction = reduce_sum(output)\n",
    "print(prediction.numpy())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4581c97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88fe51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe811dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf7da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb2cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59baf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce423b60",
   "metadata": {},
   "source": [
    "<img src='data/mat_mult.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
