{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6bc35c",
   "metadata": {},
   "source": [
    "# Machine Learning for Time Series Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0591d1",
   "metadata": {},
   "source": [
    "Time series data is ubiquitous. Whether it be stock market fluctuations, sensor data recording climate change, or activity in the brain, any signal that changes over time can be described as a time series. Machine learning has emerged as a powerful method for leveraging complexity in data in order to generate predictions and insights into the problem one is trying to solve. This course is an intersection between these two worlds of machine learning and time series data, and covers feature engineering, spectograms, and other advanced techniques in order to classify heartbeat sounds and predict stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ed5a9",
   "metadata": {},
   "source": [
    "## I. Time Series and Machine Learning Primer\n",
    "* Intro to the basics of machine learning, time series data, and the intersection between the two.\n",
    "\n",
    "### Timeseries kinds and applications\n",
    "* Put simply, a **timeseries** means data that changes over time.\n",
    "* This can take many different forms; from atmospheric CO2 over time, to the waveform of spoken word, to climate sensor data, the fluctuation of a stock's value over the year, demographic information about a city\n",
    "* **Timeseries data** consists of at least two things: \n",
    "    * One: an array of numbers that represents the data itself.\n",
    "    * Two: another array that contains a timestamp for each datapoint.\n",
    "* In other words, each datapoint should have a corresponding time point (whether that be a month, year, hour, or any combination of these). Note: multiple data points may have the same time point\n",
    "\n",
    "#### Plotting a pandas timeseries\n",
    "\n",
    "```\n",
    "import matplotlib.pyploy as plt\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "data.plot('date', 'close', ax=ax)\n",
    "ax.set(title='AAPL daily closing price')\n",
    "```\n",
    "* **The amount of time that passes between timestamps defines the *period* of the timeseries.**\n",
    "    * This often helps us infer what kind of timeseries we're dealing with.\n",
    "* One crucial part of machine learning is that we can build a model of the world that formalizes our knowledge of the problem at hand. We can...\n",
    "    * Predict the future\n",
    "    * Automate this process\n",
    "    * can be a critical component of an organization's decision making\n",
    "    \n",
    "* We treat timeseries data slightly differently than other types of datasets\n",
    "    * Timeseries data always change over time, which turns out to be a useful pattern to utilize\n",
    "    * Using timeseries-specific features lets us see a much richer representation of the raw data.\n",
    "    \n",
    "* This course will focus on a simple machine learning pipeline in the context of timeseries data.\n",
    "\n",
    "* **A machine learning pipeline:**\n",
    "    * Feature extraction: What kind of special features leverage a signal that changes over time?\n",
    "    * Model fitting: What kinds of models are suitable for asking questions with timeseries data?\n",
    "    * Prediction and Validation: How can we validate a model that uses timeseries data? What considerations must we make because it changes in time?\n",
    "\n",
    "```\n",
    "# Plot the time series in each dataset\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "data.iloc[:1000].plot(y='data_values', ax=axs[0])\n",
    "data2.iloc[:1000].plot(y='data_values', ax=axs[1])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```\n",
    "# Plot the time series in each dataset\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "data.iloc[:1000].plot(x='time', y='data_values', ax=axs[0])\n",
    "data2.iloc[:1000].plot(x='time', y='data_values', ax=axs[1])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Machine Learning Basics\n",
    "* Always begin by looking at your data:\n",
    "    * `array.shape`\n",
    "    * `array[:3]`\n",
    "    * `dataframe.head()`\n",
    "    * `dataframe.info()`\n",
    "    * `dataframe.describe()`\n",
    "* It is also crucial to visualize your data:\n",
    "\n",
    "```\n",
    "# Using matplotlib\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(...)\n",
    "\n",
    "# Using pandas\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(..., ax=ax)\n",
    "```\n",
    "* The proper visualization will depend on the kind of data you've got, though histograms and scatterplots are a good place to start.\n",
    "\n",
    "* The most popular library for machine-learning in Python is `scikit-learn`.\n",
    "    * Standardized API so that you can fit many different models with a similar code structure\n",
    "    \n",
    "#### Preparing data for scikit-learn\n",
    "* `scikit-learn` expects a particular structure of data:\n",
    "    * **`(samples, features)`**\n",
    "* Make sure that your data is *at least two-dimensional.*\n",
    "* Make sure the first dimension is *samples*.\n",
    "* The first axis should correspond to sample number, and the second axis should correspond to feature number.\n",
    "\n",
    "* If the axes are swapped: **transpose**\n",
    "    * `array.transpose().shape`\n",
    "    * `dataframe.T.shape`\n",
    "    * will swap first and last axis\n",
    "   \n",
    "* Use **`.reshape()`** method:\n",
    "    * lets you specify the shape you want\n",
    "\n",
    "```\n",
    "array.shape\n",
    "array.reshape([-1, 1]).shape\n",
    "```\n",
    "   * `-1` will automatically fill that axis with remaining values\n",
    "   \n",
    "* **Investigating the model:**\n",
    "    * It is often useful to investigate what kind of pattern the model has found.\n",
    "    * Most models will store this information in attributes that are created after calling `.fit()`\n",
    "        * `model.coef_`\n",
    "        * `model.intercept_`\n",
    "    * Call `.predict()` on the model to determine labels for unseen datapoints\n",
    "\n",
    "```\n",
    "# Generate predictions with the model using those inputs\n",
    "predictions = model.predict(new_inputs.reshape(-1, 1))\n",
    "\n",
    "# Visualize the inputs and predicted values\n",
    "plt.scatter(new_inputs, predictions, color='r', s=3)\n",
    "plt.xlabel('inputs')\n",
    "plt.ylabel('predictions')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Combining timeseries data with machine learning\n",
    "* Interaction between ML and timeseries data; introduce why they're worth thinking about in tandem.\n",
    "#### The heartbeat acoustic data\n",
    "* Why acoustic data? Audio is a very common kind of timeseries data\n",
    "* Many recordings of heart sounds from different patients\n",
    "* Some had normally-functioning hearts, others had abnormalities\n",
    "* Data comes in the form of audio files + labels for each file\n",
    "* Goal? Can we find the \"abnormal\" heart beats?\n",
    "\n",
    "* Audio tends to have a very high sampling frequency (often above 20,000 samples per second)\n",
    "* Audio data is often stored in `.wav` files\n",
    "* list all of these files using the `glob` function:\n",
    "    * lists files that match a certain pattern\n",
    "\n",
    "```\n",
    "from glob import glob\n",
    "files = glob('data/heartbeat-sounds/files/*.wav')\n",
    "print(files)\n",
    "```\n",
    "* We'll use a library called **`librosa`** to read in the audio dataset:\n",
    "\n",
    "```\n",
    "import librosa as lr\n",
    "# 'load' accepts a path to an audio file\n",
    "audio, sfreq = lr.load('data/heartbeat-sounds/proc/files/murmur__201101051104.wav')\n",
    "print(sfreq)\n",
    "```\n",
    "* Output: `2205`\n",
    "\n",
    "* **`librosa`** has functions for extracting features, visualizations, and analysis for auditory data\n",
    "* Import the data using the `load` function\n",
    "* The data is stored as `audio` and the sampling frequency is stored in `sfreq`\n",
    "* In this case, the sampling frequency is `2205`, meaning there are `2205` samples per second.\n",
    "\n",
    "#### Inferring time from samples\n",
    "* If we know the sampling rate of a timeseries, then we know the timestamp of each datapoint *relative to the first datapoint*.\n",
    "* Note: this assumes the sampling rate is fixed and also that no data points are lost.\n",
    "* Now, **we can create an array of timestamps for out data:**\n",
    "    * Create an array of indices, one for each sample, and divide by the sample frequency.\n",
    "    * To do so, two options:\n",
    "        * 1. Genereate a range of indices from zero to the number of data points in your audio file; divide each index by the sampling frequency, and you have a timepoint for each data point.\n",
    "        * 2. Calculate the final timepoint of your audio data using a similar method; Find the time stamp for the *N-1*th data point. Then use `linspace()` to interpolate from zero to that time.\n",
    "    \n",
    "```\n",
    "indices = np.arange(0, len(audio))\n",
    "time = indices / sfreq\n",
    "```\n",
    "***\n",
    "\n",
    "```\n",
    "final_time = (len(audio) - 1) / sfreq\n",
    "time = np.linspace(0, final_time, sfreq)\n",
    "```\n",
    "\n",
    "* In either case, you should have an array of numbers of the same length as your audio data\n",
    "\n",
    "#### The New York Stock Exchange dataset\n",
    "* This dataset consists of company stock values for 10 years\n",
    "* This dataset runs over a much longer timespan that the audio data, and has a sampling frequency on the order of one sample per day (compared with 2,205 samples per second with the audio data).\n",
    "* Can we detect any patterns in historical records that allow us to predict the value of companies in the future.\n",
    "* As we are predicting a continuous output value, this is a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ebda8",
   "metadata": {},
   "source": [
    "```\n",
    "import librosa as lr\n",
    "from glob import glob\n",
    "\n",
    "# List all the wav files in the folder\n",
    "audio_files = glob(data_dir + '/*.wav')\n",
    "\n",
    "# Read in the first audio file, create the time array\n",
    "audio, sfreq = lr.load(audio_files[0])\n",
    "time = np.arange(0, len(audio)) / sfreq\n",
    "\n",
    "# Plot audio over time\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, audio)\n",
    "ax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```\n",
    "# Read in the data\n",
    "data = pd.read_csv('prices.csv', index_col=0)\n",
    "\n",
    "# Convert the index of the DataFrame to datetime\n",
    "data.index = pd.to_datetime(data.index)\n",
    "print(data.head())\n",
    "\n",
    "# Loop through each column, plot its values over time\n",
    "fig, ax = plt.subplots()\n",
    "for column in data:\n",
    "    data[column].plot(ax=ax, label=column)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55716e96",
   "metadata": {},
   "source": [
    "### II. Timeseries as Inputs to a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0f0ac",
   "metadata": {},
   "source": [
    "#### Classification and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb546f",
   "metadata": {},
   "source": [
    "* One of the most common categories for machine learning problems is classification.\n",
    "\n",
    "* **Always visualize raw data before fitting models!**\n",
    "* To plot raw audio, we need two things:\n",
    "    * the raw audio waveform, usually in a one- or two- dimensional array.\n",
    "    * we also need the timepoint of each sample\n",
    "    \n",
    "    \n",
    "```\n",
    "ixs = np.arange(audio.shape[-1])\n",
    "time = ixs / sfreq\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, audio)\n",
    "\n",
    "```\n",
    "* We can calculate the time by dividing the index of each sample by the sampling frequency of the timeseries.\n",
    "* This gives us the time for each sample relative to the beginning of the audio:\n",
    "\n",
    "* **What features to use?**\n",
    "* Using raw timeseries data is too noisy for classification\n",
    "* We need to calculate features!\n",
    "* An easy start: summarize your audio data\n",
    "    * summary statistics removes the \"time\" dimension and gives us a more traditional classification dataset.\n",
    "    * For each timeseries, we calculate several summary statistics (min, max, avg, etc)\n",
    "    * We have expanding a single feature (raw audio amplitude) to several features $\\Rightarrow$ min, max, avg of each sample.\n",
    "    \n",
    "* How to calculate multiple features for several timeseries \n",
    "\n",
    "```\n",
    "# print: (n_files, time)\n",
    "print(audio.shape)\n",
    "\n",
    "means = np.mean(audio, axis=-1)\n",
    "maxs = np.max(audio, axis = -1)\n",
    "stds = np.std(audio, axis =-1)\n",
    "\n",
    "# print: (n_files,)\n",
    "print(means.shape)\n",
    "```\n",
    "* By using the \"axis equals -1\" keyword, we collapse across the last dimension, which is time.\n",
    "\n",
    "#### Fitting a classifier with scikit-learn\n",
    "* We've just collapsed a 2-D dataset (samples x time) into several features of a 1-D dataset (samples)\n",
    "* We can combine each feature, and use it as input to a model\n",
    "* If we have a label for each sample, we can use scikit-learn to create and a fit a classifier\n",
    "\n",
    "* **In the case of classification, we also need a label for each timeseries that allows us to build a classifier.**\n",
    "\n",
    "```\n",
    "from sklearn.svm import LinearSVC\n",
    "# Note that means are reshaped to work with sklearn\n",
    "X = np.column_stack([means, maxs, stds])\n",
    "y = labels.reshape([-1, 1])\n",
    "model = LinearSVC()\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "* The **`.column_stack()`** function lets us stack 1-D arrays by turning them into the columns of a 2-D array\n",
    "* Additionally, the labels array is 1-D, so we reshae it so that it is 2-D\n",
    "\n",
    "```\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Different input data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Score our model with % correct\n",
    "# Manually\n",
    "percent_score = sum(predictions == labels_test) / len(labels_test)\n",
    "# Using an sklearn scorer\n",
    "percent_score = accuracy_score(labels_test, predictions)\n",
    "```\n",
    "\n",
    "```\n",
    "# Average across the audio files of each DataFrame\n",
    "mean_normal = np.mean(normal, axis=1)\n",
    "mean_abnormal = np.mean(abnormal, axis=1)\n",
    "\n",
    "# Plot each average over time\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "ax1.plot(time, mean_normal)\n",
    "ax1.set(title=\"Normal Data\")\n",
    "ax2.plot(time, mean_abnormal)\n",
    "ax2.set(title=\"Abnormal Data\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions and score them manually\n",
    "predictions = model.predict(X_test)\n",
    "print(sum(predictions == y_test.squeeze()) / len(y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d7db6",
   "metadata": {},
   "source": [
    "#### Improving the features we use for classification\n",
    "* A few more features that are unique to timeseries data\n",
    "\n",
    "#### The auditory envelope\n",
    "    * Smooth the data to calculate the auditory envelope\n",
    "    * Related to the total amount of audio energy present at each moment\n",
    "    * The envelope throws away information about the fine-grained changes in the signal, focusing on the general shape of the audio waveform \n",
    "    * To do this, we'll need to calculate the audio's amplitude, then smooth it over time. \n",
    "    \n",
    "#### Smoothing over time\n",
    "* Instead of averaging over *all* time can do a *local* average\n",
    "* This is called *smoothing* your timeseries\n",
    "* It removes short-term noise, while retaining the general pattern\n",
    "\n",
    "#### Calculating a rolling window statistic\n",
    "\n",
    "```\n",
    "# Audio is a pandas df\n",
    "print(audio.shape)\n",
    "# (n_times, n_audio_files)\n",
    "```\n",
    "* Output: `(5000, 20)`\n",
    "\n",
    "```\n",
    "# Smooth our data by taking the rolling mean in a window of 50 samples\n",
    "window_size = 50\n",
    "windowed = audio.rollin(window=window_size)\n",
    "audio_smooth = windowed.mean()\n",
    "```\n",
    "* The `.rolling()` method returns **an object that can be used to calculate many different statistics within each window.**\n",
    "* The `window` parameter tells us how many timepoints to include in each window\n",
    "    * The larger the window, the smoother the result will be\n",
    "    \n",
    "#### Calculating the auditory envelope\n",
    "* First *rectify* (calculate absolute value) your audio, then smooth it\n",
    "* Called \"rectification,\" because you ensure that all time points are positive.\n",
    "\n",
    "```\n",
    "audio_rectified = audio.apply(np.abs)\n",
    "audio_envelope = audio_rectified.rolling(50).mean()\n",
    "```\n",
    "* Once we've calculated the acoustic envelope, we can create better features for our classifier:\n",
    "\n",
    "#### Feature engineering the envelope\n",
    "\n",
    "```\n",
    "# Calculate several features of the envelope, one per second\n",
    "envelope_mean = np.mean(audio_envelope, axis=0)\n",
    "envelope_std = np.std(audio_envelope, axis=0)\n",
    "envelope_max = np.max(audio_envelope, axis=0)\n",
    "\n",
    "# Create our training data for a classifier\n",
    "X = np.column_stack([envelope_mean, envelope_std, envelope_max])\n",
    "y = labels.reshape([-1, 1])\n",
    "```\n",
    "\n",
    "* `cross_val_score` automates the process of:\n",
    "    * Splitting data into training/ validation sets\n",
    "    * Fitting the model on training data\n",
    "    * Scoring it on validation data\n",
    "    * Repeating this process\n",
    "    \n",
    "```\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = LinearSVC()\n",
    "scores = cross_val_score(model, X, y, cv=3)\n",
    "print(scores)\n",
    "```\n",
    "\n",
    "#### Auditory features: The Tempogram\n",
    "* We can summarize more complex temporal information with timeseries-specifc functions\n",
    "* `librosa` is a great library for auditory and timeseries feature engineering\n",
    "* Tempogram attempts to detect particular patterns over time, and summarize them statistically\n",
    "* Here we'll caluclate the *tempogram*, which estimates the tempo of a sound over time.\n",
    "* We can calculate summary statistics of tempo in the same way that we can for the envelope\n",
    "\n",
    "#### Computing the Tempogram\n",
    "\n",
    "```\n",
    "# Import librosa and calculate the tempo of a 1-D sound array\n",
    "import librosa as lr\n",
    "audio_tempo = lr.beat.tempo(audio, sr=sfreq, hop_length=2**6, aggregate= None\n",
    "```\n",
    "***\n",
    "\n",
    "```\n",
    "# Plot the raw data first\n",
    "audio.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "\n",
    "# Rectify the audio signal\n",
    "audio_rectified = audio.apply(np.abs)\n",
    "\n",
    "# Plot the result\n",
    "audio_rectified.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "\n",
    "# Smooth by applying a rolling mean\n",
    "audio_rectified_smooth = audio_rectified.rolling(50).mean()\n",
    "\n",
    "# Plot the result\n",
    "audio_rectified_smooth.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "\n",
    "# Calculate stats\n",
    "means = np.mean(audio_rectified_smooth, axis=0)\n",
    "stds = np.std(audio_rectified_smooth, axis=0)\n",
    "maxs = np.max(audio_rectified_smooth, axis=0)\n",
    "\n",
    "# Create the X and y arrays\n",
    "X = np.column_stack([means, stds, maxs])\n",
    "y = labels.reshape([-1, 1])\n",
    "\n",
    "# Fit the model and score on testing data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "percent_score = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(percent_score))\n",
    "\n",
    "# Calculate the tempo of the sounds\n",
    "tempos = []\n",
    "for col, i_audio in audio.items():\n",
    "    tempos.append(lr.beat.tempo(i_audio.values, sr=sfreq, hop_length=2**6, aggregate=None))\n",
    "\n",
    "# Convert the list to an array so you can manipulate it more easily\n",
    "tempos = np.array(tempos)\n",
    "\n",
    "# Calculate statistics of each tempo\n",
    "tempos_mean = tempos.mean(axis=-1)\n",
    "tempos_std = tempos.std(axis=-1)\n",
    "tempos_max = tempos.max(axis=-1)\n",
    "\n",
    "# Create the X and y arrays\n",
    "X = np.column_stack([means, stds, maxs, tempos_mean, tempos_std, tempos_max])\n",
    "y = labels.reshape([-1, 1])\n",
    "\n",
    "# Fit the model and score on testing data\n",
    "percent_score = cross_val_score(model, X, y, cv=5)\n",
    "print(np.mean(percent_score))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d80c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b646952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329f03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2eeadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d463df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bccc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
