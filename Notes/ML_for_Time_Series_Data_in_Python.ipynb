{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69166f22",
   "metadata": {},
   "source": [
    "# Machine Learning for Time Series Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424f0fd",
   "metadata": {},
   "source": [
    "Time series data is ubiquitous. Whether it be stock market fluctuations, sensor data recording climate change, or activity in the brain, any signal that changes over time can be described as a time series. Machine learning has emerged as a powerful method for leveraging complexity in data in order to generate predictions and insights into the problem one is trying to solve. This course is an intersection between these two worlds of machine learning and time series data, and covers feature engineering, spectograms, and other advanced techniques in order to classify heartbeat sounds and predict stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030e456",
   "metadata": {},
   "source": [
    "## I. Time Series and Machine Learning Primer\n",
    "* Intro to the basics of machine learning, time series data, and the intersection between the two.\n",
    "\n",
    "### Timeseries kinds and applications\n",
    "* Put simply, a **timeseries** means data that changes over time.\n",
    "* This can take many different forms; from atmospheric CO2 over time, to the waveform of spoken word, to climate sensor data, the fluctuation of a stock's value over the year, demographic information about a city\n",
    "* **Timeseries data** consists of at least two things: \n",
    "    * One: an array of numbers that represents the data itself.\n",
    "    * Two: another array that contains a timestamp for each datapoint.\n",
    "* In other words, each datapoint should have a corresponding time point (whether that be a month, year, hour, or any combination of these). Note: multiple data points may have the same time point\n",
    "\n",
    "#### Plotting a pandas timeseries\n",
    "\n",
    "```\n",
    "import matplotlib.pyploy as plt\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "data.plot('date', 'close', ax=ax)\n",
    "ax.set(title='AAPL daily closing price')\n",
    "```\n",
    "* **The amount of time that passes between timestamps defines the *period* of the timeseries.**\n",
    "    * This often helps us infer what kind of timeseries we're dealing with.\n",
    "* One crucial part of machine learning is that we can build a model of the world that formalizes our knowledge of the problem at hand. We can...\n",
    "    * Predict the future\n",
    "    * Automate this process\n",
    "    * can be a critical component of an organization's decision making\n",
    "    \n",
    "* We treat timeseries data slightly differently than other types of datasets\n",
    "    * Timeseries data always change over time, which turns out to be a useful pattern to utilize\n",
    "    * Using timeseries-specific features lets us see a much richer representation of the raw data.\n",
    "    \n",
    "* This course will focus on a simple machine learning pipeline in the context of timeseries data.\n",
    "\n",
    "* **A machine learning pipeline:**\n",
    "    * Feature extraction: What kind of special features leverage a signal that changes over time?\n",
    "    * Model fitting: What kinds of models are suitable for asking questions with timeseries data?\n",
    "    * Prediction and Validation: How can we validate a model that uses timeseries data? What considerations must we make because it changes in time?\n",
    "\n",
    "```\n",
    "# Plot the time series in each dataset\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "data.iloc[:1000].plot(y='data_values', ax=axs[0])\n",
    "data2.iloc[:1000].plot(y='data_values', ax=axs[1])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```\n",
    "# Plot the time series in each dataset\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "data.iloc[:1000].plot(x='time', y='data_values', ax=axs[0])\n",
    "data2.iloc[:1000].plot(x='time', y='data_values', ax=axs[1])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Machine Learning Basics\n",
    "* Always begin by looking at your data:\n",
    "    * `array.shape`\n",
    "    * `array[:3]`\n",
    "    * `dataframe.head()`\n",
    "    * `dataframe.info()`\n",
    "    * `dataframe.describe()`\n",
    "* It is also crucial to visualize your data:\n",
    "\n",
    "```\n",
    "# Using matplotlib\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(...)\n",
    "\n",
    "# Using pandas\n",
    "fig, ax = plt.subplots()\n",
    "df.plot(..., ax=ax)\n",
    "```\n",
    "* The proper visualization will depend on the kind of data you've got, though histograms and scatterplots are a good place to start.\n",
    "\n",
    "* The most popular library for machine-learning in Python is `scikit-learn`.\n",
    "    * Standardized API so that you can fit many different models with a similar code structure\n",
    "    \n",
    "#### Preparing data for scikit-learn\n",
    "* `scikit-learn` expects a particular structure of data:\n",
    "    * **`(samples, features)`**\n",
    "* Make sure that your data is *at least two-dimensional.*\n",
    "* Make sure the first dimension is *samples*.\n",
    "* The first axis should correspond to sample number, and the second axis should correspond to feature number.\n",
    "\n",
    "* If the axes are swapped: **transpose**\n",
    "    * `array.transpose().shape`\n",
    "    * `dataframe.T.shape`\n",
    "    * will swap first and last axis\n",
    "   \n",
    "* Use **`.reshape()`** method:\n",
    "    * lets you specify the shape you want\n",
    "\n",
    "```\n",
    "array.shape\n",
    "array.reshape([-1, 1]).shape\n",
    "```\n",
    "   * `-1` will automatically fill that axis with remaining values\n",
    "   \n",
    "* **Investigating the model:**\n",
    "    * It is often useful to investigate what kind of pattern the model has found.\n",
    "    * Most models will store this information in attributes that are created after calling `.fit()`\n",
    "        * `model.coef_`\n",
    "        * `model.intercept_`\n",
    "    * Call `.predict()` on the model to determine labels for unseen datapoints\n",
    "\n",
    "```\n",
    "# Generate predictions with the model using those inputs\n",
    "predictions = model.predict(new_inputs.reshape(-1, 1))\n",
    "\n",
    "# Visualize the inputs and predicted values\n",
    "plt.scatter(new_inputs, predictions, color='r', s=3)\n",
    "plt.xlabel('inputs')\n",
    "plt.ylabel('predictions')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Combining timeseries data with machine learning\n",
    "* Interaction between ML and timeseries data; introduce why they're worth thinking about in tandem.\n",
    "#### The heartbeat acoustic data\n",
    "* Why acoustic data? Audio is a very common kind of timeseries data\n",
    "* Many recordings of heart sounds from different patients\n",
    "* Some had normally-functioning hearts, others had abnormalities\n",
    "* Data comes in the form of audio files + labels for each file\n",
    "* Goal? Can we find the \"abnormal\" heart beats?\n",
    "\n",
    "* Audio tends to have a very high sampling frequency (often above 20,000 samples per second)\n",
    "* Audio data is often stored in `.wav` files\n",
    "* list all of these files using the `glob` function:\n",
    "    * lists files that match a certain pattern\n",
    "\n",
    "```\n",
    "from glob import glob\n",
    "files = glob('data/heartbeat-sounds/files/*.wav')\n",
    "print(files)\n",
    "```\n",
    "* We'll use a library called **`librosa`** to read in the audio dataset:\n",
    "\n",
    "```\n",
    "import librosa as lr\n",
    "# 'load' accepts a path to an audio file\n",
    "audio, sfreq = lr.load('data/heartbeat-sounds/proc/files/murmur__201101051104.wav')\n",
    "print(sfreq)\n",
    "```\n",
    "* Output: `2205`\n",
    "\n",
    "* **`librosa`** has functions for extracting features, visualizations, and analysis for auditory data\n",
    "* Import the data using the `load` function\n",
    "* The data is stored as `audio` and the sampling frequency is stored in `sfreq`\n",
    "* In this case, the sampling frequency is `2205`, meaning there are `2205` samples per second.\n",
    "\n",
    "#### Inferring time from samples\n",
    "* If we know the sampling rate of a timeseries, then we know the timestamp of each datapoint *relative to the first datapoint*.\n",
    "* Note: this assumes the sampling rate is fixed and also that no data points are lost.\n",
    "* Now, **we can create an array of timestamps for out data:**\n",
    "    * Create an array of indices, one for each sample, and divide by the sample frequency.\n",
    "    * To do so, two options:\n",
    "        * 1. Genereate a range of indices from zero to the number of data points in your audio file; divide each index by the sampling frequency, and you have a timepoint for each data point.\n",
    "        * 2. Calculate the final timepoint of your audio data using a similar method; Find the time stamp for the *N-1*th data point. Then use `linspace()` to interpolate from zero to that time.\n",
    "    \n",
    "```\n",
    "indices = np.arange(0, len(audio))\n",
    "time = indices / sfreq\n",
    "```\n",
    "***\n",
    "\n",
    "```\n",
    "final_time = (len(audio) - 1) / sfreq\n",
    "time = np.linspace(0, final_time, sfreq)\n",
    "```\n",
    "\n",
    "* In either case, you should have an array of numbers of the same length as your audio data\n",
    "\n",
    "#### The New York Stock Exchange dataset\n",
    "* This dataset consists of company stock values for 10 years\n",
    "* This dataset runs over a much longer timespan that the audio data, and has a sampling frequency on the order of one sample per day (compared with 2,205 samples per second with the audio data).\n",
    "* Can we detect any patterns in historical records that allow us to predict the value of companies in the future.\n",
    "* As we are predicting a continuous output value, this is a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847249a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b11218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fd250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d528e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d66d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f2e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91e91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6a3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4bfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e2b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
