{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a01bd7",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d3a01",
   "metadata": {},
   "source": [
    "#### Understanding the problem\n",
    "* **Data type:** tabular data, time series, images, text, etc. structured vs. unstructured... a mix\n",
    "* **Problem type:** classification, regression, ranking, etc.\n",
    "* **Evaluation metric:** ROC AUC, F1-score, MAE, MSE, etc.\n",
    "\n",
    "#### Metric definition\n",
    "* Generally, the majority of the metrics can be found in the `sklearn.metrics` library\n",
    "* However, **there are some special competition metrics that are not available in scikit-learn**\n",
    "    * In such cases, we have to create metrics manually\n",
    "    \n",
    "### Kaggle Solution Workflow\n",
    "\n",
    "<img src='data/solution_workflow.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    diffs = np.log(y_true + 1) - np.log(y_pred + 1)\n",
    "    squares = np.power(diffs, 2)\n",
    "    err = np.sqrt(np.mean(squares))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a60322",
   "metadata": {},
   "source": [
    "* Before building any models, we should perform some preliminary steps to understand the data and the problem we're facing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bcbc46",
   "metadata": {},
   "source": [
    "#### Goals of EDA\n",
    "* Size of the data\n",
    "* Properties of the target variable\n",
    "    * high class imblance in classification problem?\n",
    "    * skewed distribution in regression problem?\n",
    "* Properties of the features\n",
    "* Generate ideas for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62ee06",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38627aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle= True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f12e2",
   "metadata": {},
   "source": [
    "* Now we need to train `K` models for each cross-validation split. \n",
    "* To obtain all the splits we call the `split()` method of the KFold object with the `train` data as an argument.\n",
    "* It returns a list of training and testing observations for each split\n",
    "* The observations are given as numeric indices on the train data.\n",
    "* These indices could be used inside the loop to select training and testing folds for the corresponding cross-validation split\n",
    "* For pandas DataFrame, it could be done using the `iloc` operator, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403713ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each cross-validation split\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Get training and testing data for the corresponding split\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c63f9",
   "metadata": {},
   "source": [
    "#### Stratified K-fold\n",
    "* As demonstrated in the image, each fold has the same class distribution as the initial dataset.\n",
    "* It is useful when we have a classification problem with high class imbalance in the target variable or our data size is very small.\n",
    "\n",
    "<img src='data/stratified_kfold.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124caae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=123)\n",
    "\n",
    "# Loop through each cross-validation split\n",
    "for train_index, test_index in str_kf.split(train, train['target']):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb46a9",
   "metadata": {},
   "source": [
    "```\n",
    "# Import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "# Loop through each split\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Obtain training and testing folds\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    print('Fold: {}'.format(fold))\n",
    "    print('CV train shape: {}'.format(cv_train.shape))\n",
    "    print('Medium interest listings in CV train: {}\\n'.format(sum(cv_train.interest_level == 'medium')))\n",
    "    fold += 1\n",
    "    \n",
    "# Import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "str_kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "# Loop through each split\n",
    "fold = 0\n",
    "for train_index, test_index in str_kf.split(train, train['interest_level']):\n",
    "    # Obtain training and testing folds\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    print('Fold: {}'.format(fold))\n",
    "    print('CV train shape: {}'.format(cv_train.shape))\n",
    "    print('Medium interest listings in CV train: {}\\n'.format(sum(cv_train.interest_level == 'medium')))\n",
    "    fold += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35976d7",
   "metadata": {},
   "source": [
    "#### Validation usage\n",
    "* **Leakage** causes a model to seem accurate until we start making predictions in a real-world environment\n",
    "* **Types of data leakage:**\n",
    "    * Leak in **features:** using data that will not be available in the real (production) setting\n",
    "        * Example: predicting sales in US dollars, while having exactly the same sales in UK pounds as a feature.\n",
    "    * Leak in **validation strategy:** validation strategy differs from the real-world situation\n",
    "        * Using kfold for time series data\n",
    "        * Instead, time series kfold should be done as demonstrated in the image below:\n",
    "        \n",
    "<img src='data/time_series_kfold.png' width=\"600\" height=\"300\" align=\"center\"/>        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb93af0",
   "metadata": {},
   "source": [
    "* The underlying idea of time series k-fold crossvalidation is to provide multiple splits in such a manner that we train only on past data while always predicting the future\n",
    "* **Time k-fold crossvalidation** is also available in `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b644ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create a TimeSeriesSplit object\n",
    "time_kfold = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959663f6",
   "metadata": {},
   "source": [
    "* **Note** that **before applying it to the data, we need to sort the train DataFrame by date.**\n",
    "    * Then, as usual, iterate through each crossvalidation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a42575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort train by date\n",
    "train = train.sort_values('date')\n",
    "\n",
    "# Loop through each cross-validation split\n",
    "for train_index, test_index in time_kfold.split(train):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb9cd0",
   "metadata": {},
   "source": [
    "### Validation pipeline\n",
    "* Firstly, create an empty list where we will store the model's results\n",
    "* Split train data into folds \n",
    "* For each crossvalidation split, we perform the following steps:\n",
    "    * Train a model using all except for a single fold\n",
    "    * Make predictions on this single unseen fold\n",
    "    * Calculate the competition metric and append it to the list of folds metrics\n",
    "* As a result, we have a list of K numbers representing model quality for each fold \n",
    "\n",
    "```\n",
    "# List for the results\n",
    "fold_metrics = []\n",
    "for train_index, test_index in CV_STRATEGY.split(train):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    # Train a model\n",
    "    model.fit(cv_train)\n",
    "    # Make predictions\n",
    "    predictions = model.predict(cv_test)\n",
    "    # Calculate the metric\n",
    "    metric = evaluate(cv_test, predictions)\n",
    "    fold_metrics.append(metric)\n",
    "```\n",
    "* Now, we could train two different models and for each model get a list of K numbers\n",
    "\n",
    "<img src='data/mod_comp.png' width=\"300\" height=\"150\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a48029",
   "metadata": {},
   "source": [
    "* For example, above we have models A and B, each with mean squared errors in four folds\n",
    "* Our goal is to select the model with better quality \n",
    "* The next step is to tranform K fold scores into a single overall validation score\n",
    "* The simplest way to obtain a single number is to find the mean over all fold scores\n",
    "    * However, the mean is not always a good choice, as it does *not* take into account **score deviation** from one fold to another\n",
    "    * For example, we could get a very good score for a single fold, while the performance on the rest K-1 folds is poor. \n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "# Simple mean over the folds\n",
    "mean_score = np.mean(fold_metrics)\n",
    "```\n",
    "* **A more reliable overall validation score:** uses the worst-case scenario considering validation score one standard deviation away from the mean\n",
    "* **Note** that we **add** standard deviation if the competition metric is being *minimized* and **subtract** standard deviation if the metric is being *maximized*.\n",
    "\n",
    "```\n",
    "# Overall validation score\n",
    "overall_score_minimizing = np.mean(fold_metrics) + np.std(fold_metrics)\n",
    "\n",
    "# Or\n",
    "overall_score_maximizing = np.mean(fold_metrics) - np.std(fold_metrics)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f021118",
   "metadata": {},
   "source": [
    "#### Exercises: Time K-Fold\n",
    "\n",
    "```\n",
    "# Create TimeSeriesSplit object\n",
    "time_kfold = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Sort train data by date\n",
    "train = train.sort_values(by='date')\n",
    "\n",
    "# Iterate through each split\n",
    "fold = 0\n",
    "for train_index, test_index in time_kfold.split(train):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "    print('Fold :', fold)\n",
    "    print('Train date range: from {} to {}'.format(cv_train.date.min(), cv_train.date.max()))\n",
    "    print('Test date range: from {} to {}\\n'.format(cv_test.date.min(), cv_test.date.max()))\n",
    "    fold += 1\n",
    "```\n",
    "\n",
    "#### Exercises: Overall Validation Score\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# Sort train data by date\n",
    "train = train.sort_values('date')\n",
    "\n",
    "# Initialize 3-fold time cross-validation\n",
    "kf = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Get MSE scores for each cross-validation split\n",
    "mse_scores = get_fold_mse(train, kf)\n",
    "\n",
    "print('Mean validation MSE: {:.5f}'.format(np.mean(mse_scores)))\n",
    "print('MSE by fold: {}'.format(mse_scores))\n",
    "print('Overall validation MSE: {:.5f}'.format(np.mean(mse_scores) + np.std(mse_scores)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3578c0",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 3: Feature Engineering\n",
    "You will now get exposure to different types of features. You will modify existing features and create new ones. Also, you will treat the missing data accordingly.\n",
    "\n",
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53442aa5",
   "metadata": {},
   "source": [
    "<img src='data/mod_process.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10cdeb8",
   "metadata": {},
   "source": [
    "* **Important rule:** tweak only a single a thing at a time, because changing multiple things does not allow us to detect what actually works and what doesn't\n",
    "* **Feature engineering** helps our ML models to get additional information and consequently to better predict the target variable\n",
    "* The ideas for new features can come from prior experience working with similar data.\n",
    "* Also, having looked at the data, we could potentially generate ideas for new valuable features\n",
    "* One more source is domain knowledge of the problem we're solving\n",
    "\n",
    "#### Feature types\n",
    "* Numerical\n",
    "* Categorical\n",
    "* Datetime\n",
    "* Coordinates\n",
    "* Text\n",
    "* Images\n",
    "\n",
    "#### Creating features \n",
    "* There are some situations when we need to generate features for train and tests independently and for each validation split in the k-fold cross-validation\n",
    "* However, in the majority of cases features are created for train and test sets simultaneously\n",
    "    * For this purpose, we concatenate train and test DataFrames from Kaggle into a single DF using pandas\n",
    "    \n",
    "```\n",
    "# Concatenate the train and test data\n",
    "data = pd.concat([train, test])\n",
    "\n",
    "# Generate new features for the full DataFrame\n",
    "\n",
    "# Get the original train and test split back\n",
    "train = data[data.id.isin(train.id)]\n",
    "test = data[data.is.isin(test.id)]\n",
    "```\n",
    "\n",
    "#### Arithmetical features\n",
    "\n",
    "```\n",
    "# Arithmetical features\n",
    "two_sigma['price_per_bedroom'] = two_sigma.price / two_sigma.bedrooms\n",
    "two_sigma['rooms_number'] = two_sigma.bedrooms + two_sigma.bathrooms\n",
    "```\n",
    "\n",
    "#### Datetime features \n",
    "\n",
    "```\n",
    "# Convert date to the datetime object\n",
    "dem['date'] = pd.to_datetime(dem['date'])\n",
    "\n",
    "# Year features\n",
    "dem['year'] = dem['date'].dt.year\n",
    "\n",
    "# Month features\n",
    "dem['month'] = dem['date'].dt.month\n",
    "\n",
    "# Week features\n",
    "dem['week'] = dem['date'].dt.weekofyear\n",
    "\n",
    "# Day features\n",
    "dem['dayofyear'] = dem['date'].dt.dayofyear\n",
    "dem['dayofmonth'] = dem['date'].dt.day\n",
    "dem['dayofweek'] = dem['date'].dt.dayofweek\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80940f",
   "metadata": {},
   "source": [
    "#### Exercises: Arithmetical features\n",
    "\n",
    "```\n",
    "# Look at the initial RMSE\n",
    "print('RMSE before feature engineering:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the total area of the house\n",
    "train['TotalArea'] = train['TotalBsmtSF'] + train['FirstFlrSF'] + train['SecondFlrSF']\n",
    "\n",
    "# Look at the updated RMSE\n",
    "print('RMSE with total area:', get_kfold_rmse(train))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c2241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cc367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc8f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174a779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0404242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105b3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9184a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c14942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9eb4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea6023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71381b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354784f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f637534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e37a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19fa66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbcb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ba1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611fecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065316d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31df9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a661399",
   "metadata": {},
   "source": [
    "<img src='data/course_datasets.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
