{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb2f981",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "### scikit-learn:\n",
    "scikit-learn's built-in datasets are of type `Bunch`, which are dictionary-like objects. \\\n",
    "Use dictionary- or column- notation to to access `Bunch` keys\\\n",
    "(`Bunch.image` or `Bunch['image']`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1d405",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c57626",
   "metadata": {},
   "source": [
    "`from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neightbors=6)\n",
    "kkn.fit(iris['data'], iris['target'])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9886cc8",
   "metadata": {},
   "source": [
    "* fit data, labels/targets, aka x , y\n",
    "* requires data and target to be either NumPy array or pandas DataFrame\n",
    "* requires that the features take on continuous values \n",
    "* requires that there are no missing values \n",
    "* in particular, the scikit-learn api requires that the features are in an array where each column is a feature and each row a different observation or data point\n",
    "* data and target but be of same length of observations \\\n",
    "__Predicting on unlabeled data:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c250f16",
   "metadata": {},
   "source": [
    "`X_new = np.array([[5.6, 2.8, 3.9, 1.1,], [5.7, 2.6, 3.8, 1.3], [4.7, 3.2, 1.3, 0.2]])\n",
    "prediction = knn.predict(X_new)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0d9ed",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc14ea",
   "metadata": {},
   "source": [
    "`#Import KNeighborsClassifier from sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier`\n",
    "\n",
    "`#Create arrays for the features and the response variable\n",
    "y = df['party'].values\n",
    "X = df.drop('party', axis=1).values`\n",
    "\n",
    "`#Create a k-NN classifier with 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)`\n",
    "\n",
    "`#Fit the classifier to the data\n",
    "knn.fit(X,y)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8216181",
   "metadata": {},
   "source": [
    "Having fit a k-NN classifier, you can now use it to predict the label of a new data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bf318",
   "metadata": {},
   "source": [
    "### Measuring model performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83adbda1",
   "metadata": {},
   "source": [
    "### Train test split\n",
    "__`from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, testsize=0.3, random_state=21, stratify=y)`__\n",
    "\n",
    "#Returns four arrays (unpacked into four variables):\n",
    "1) Training data\\\n",
    "2) Test data\\\n",
    "3) Training labels\\\n",
    "4) Test labels\\\n",
    "#By default, `train_test_split` splits the data into 75% training data and 25% testing data.\\\n",
    "#`random_state`= random seed to reproduce results downstream.\\\n",
    "#`test_size` = portion of data you would like to allocate to testing data (here, 30%).\\\n",
    "#`Stratify = y` makes labels distributed in train and test sets as they are in the original data set; where `y` is the list or array containing the labels.\n",
    "\n",
    "To check out the accuract of our model, __`knn.score(X_test, y_test)`__\n",
    "\n",
    "### Model complexity\n",
    "__Larger k__ = smoother decision boundary = less complex model\\\n",
    "__Smaller k__ = more complex model = can lead to overfitting\\\n",
    "See: [Model complexity curve](https://www.analyticsvidhya.com/blog/2020/08/bias-and-variance-tradeoff-machine-learning/), Bias-Variance Tradeoff\\\n",
    "Plot __model complexity curves__ to determine the optimal value for k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3038437",
   "metadata": {},
   "source": [
    "`#Import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split`\n",
    "\n",
    "`#Create feature and target arrays\n",
    "X = digits.data\n",
    "y = digits.target`\n",
    "\n",
    "`#Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)`\n",
    "\n",
    "`#Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)`\n",
    "\n",
    "`#Fit the classifier to the training data\n",
    "knn.fit(X_train,y_train)`\n",
    "\n",
    "`#Print the accuracy\n",
    "print(knn.score(X_test, y_test))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed120253",
   "metadata": {},
   "source": [
    "### Compute and plot the training and testing accuracy scores for a variety of different neighbor values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7401900",
   "metadata": {},
   "source": [
    "`#Setup arrays to store train and test accuracies`\n",
    "```neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))```\n",
    "\n",
    "`#Loop over different values of k`\\\n",
    "`for i, k in enumerate(neighbors):`\\\n",
    "    ```#Setup a k-NN Classifier with k neighbors: knn\n",
    "    `knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    #Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)```\n",
    "\n",
    "```#Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399549c2",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e207fb8d",
   "metadata": {},
   "source": [
    "Scikit-learn wants features and target values in distinct arrays.\n",
    "\n",
    "So first, split DataFrame into separate dfs, X and y:\n",
    "\n",
    "```boston = pd.read_csv\n",
    "X = boston.drop('MEDV', axis=1).values\n",
    "y = boston['MEDV'].values #Using the values attribute returns the numpy arrays we can use```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a90e21",
   "metadata": {},
   "source": [
    "Predicting house value from a single feature:\n",
    "\n",
    "```X_rooms = X[:,5]\n",
    "y = y.reshape(-1, 1)\n",
    "X_rooms = X_rooms.reshape(-1, 1)```\n",
    "\n",
    "__`np.reshape()`__: [numpy.reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) \\\n",
    "numpy.reshape(a, newshape, order='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05050e75",
   "metadata": {},
   "source": [
    "__Fitting a regression model:__\n",
    "```import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_rooms, y)\n",
    "prediction_space = np.linspace(min(X_rooms), max(X_rooms)).reshape(-1, 1)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58ba7e",
   "metadata": {},
   "source": [
    "__Importing data for supervised learning:__\n",
    "* Import the data and get it into the form needed by scikit-learn. \n",
    "* This involves creating feature and target variable arrays. \n",
    "* Since you are going to use only one feature to begin with, you need to do some reshaping using NumPy's .reshape() method.\n",
    "\n",
    "```\n",
    "#Import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Read the CSV file into a DataFrame: df\n",
    "df = pd.read_csv('gapminder.csv')\n",
    "#Create arrays for features and target variable\n",
    "y = df['life']\n",
    "X = df['fertility']\n",
    "#Print the dimensions of y and X before reshaping\n",
    "print(\"Dimensions of y before reshaping: \", y.shape)\n",
    "print(\"Dimensions of X before reshaping: \", X.shape)\n",
    "#Reshape X and y\n",
    "y_reshaped = y.reshape(-1,1)\n",
    "X_reshaped = X.reshape(-1,1)\n",
    "#Print the dimensions of y_reshaped and X_reshaped\n",
    "print(\"Dimensions of y after reshaping: \", y_reshaped.shape)\n",
    "print(\"Dimensions of X after reshaping: \", X_reshaped.shape)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420997f6",
   "metadata": {},
   "source": [
    "Heatmap: \\\n",
    "__`sns.heatmap(df.corr(), square=True, cmap='RdYlGn')`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497471e",
   "metadata": {},
   "source": [
    "## __error__ function = __loss__ function = __cost__ function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c4969",
   "metadata": {},
   "source": [
    "__superscript:__ $R^2$ \\\n",
    "__subscript:__ $R_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701efbe5",
   "metadata": {},
   "source": [
    "__Ordinary Least Squares (OLS):__ Minimize sum of squares of residuals; same as minimizing mean squared error; calling `.fit()` on a linear regression model in scikit-learn performs OLS \"under the hood.\"\n",
    "\n",
    "__$R^2$:__ The default scoring method for accuracy as metric of model performance __for linear regression__; intuitively, this metric quantifies the amount of variance in the target variable that is predicted from the feature variables; use `.score()`\n",
    "\n",
    "__RMSE (Root Mean Squared Error):__ Another popular metric to measure accuracy of model performance.\n",
    "\n",
    "__`reg_all.score(X_test, y_test)`__\n",
    "\n",
    "You will almost never use linear regression straight out of the box; you will almost always want to use __regularization__.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe4578",
   "metadata": {},
   "source": [
    "```#Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Create the regressor: reg\n",
    "reg = LinearRegression()\n",
    "#Create the prediction space\n",
    "prediction_space = np.linspace(min(X_fertility), max(X_fertility)).reshape(-1,1)\n",
    "#Fit the model to the data\n",
    "reg.fit(X_fertility, y)\n",
    "#Compute predictions over the prediction space: y_pred\n",
    "y_pred = reg.predict(prediction_space)\n",
    "#Print R^2 \n",
    "print(reg.score(X_fertility, y))\n",
    "#Plot regression line\n",
    "plt.plot(prediction_space, y_pred, color='black', linewidth=3)\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283a380",
   "metadata": {},
   "source": [
    "__```#Import necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "#Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "#Fit the regressor to the training data\n",
    "reg_all.fit(X_train, y_train)\n",
    "#Predict on the test data: y_pred\n",
    "y_pred = reg_all.predict(X_test)\n",
    "#Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(reg_all.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))```__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d3c1e",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f58ce",
   "metadata": {},
   "source": [
    "Model performance is dependent on the way the data are split.\n",
    "\n",
    "__K-fold cross-validation:__ Cross-validation of data into training and testing splits of K # of folds; for example 5-fold CV = five folds (4 training, 1 test). \n",
    "\n",
    "More folds = more computationally expensive.\n",
    "\n",
    "This method avoids the problem of your metric of choice being dependent on the train test split\n",
    "\n",
    "### Cross-validation in scikit-learn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bf308",
   "metadata": {},
   "source": [
    "```from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "cv_results = cross_val_score(reg, X, y, cv = 5)\n",
    "print(cv_results)\n",
    "print(np.mean(cv_results))```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37397a0e",
   "metadata": {},
   "source": [
    "`cross_val_score()` from scikit learn, uses $R^2$ as metric of choice for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051907f",
   "metadata": {},
   "source": [
    "```\n",
    "#Import the necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Create a linear regression object: reg\n",
    "reg = LinearRegression()\n",
    "#Compute 5-fold cross-validation scores: cv_scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=5)\n",
    "#Print the 5-fold cross-validation scores\n",
    "print(cv_scores)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5db15a",
   "metadata": {},
   "source": [
    "__`%timeit`:__\n",
    "\n",
    "`%timeit cross_val_score(reg, X, y, cv = ____)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06914569",
   "metadata": {},
   "source": [
    "## Regularized regression\n",
    "Why regularize? \n",
    "* Linear regression minimizes a loss function\n",
    "* It chooses a coefficient for each feature variable \n",
    "* Large coefficients can lead to overfitting (especially with many features)\n",
    "* It is common practice to alter the loss function so that it penalizes for large coefficients\n",
    "* __Regulatization:__ penalizing for large coefficients; there are different types of regularized regression.\n",
    "\n",
    "### Ridge regresssion\n",
    "* alpha is a parameter we need to choose\n",
    "* picking alpha for ridge regression is similar to picking k in k-NN <-- __hyperparameter tuning__\n",
    "* alpha sometimes also referred to as lambda\n",
    "* __alpha__ = a parameter that controls model complexity\n",
    "    * when alpha = 0, we get back OLS (can lead to __overfitting__)\n",
    "    * A very large alpha means that large coefficients are significantly penalized\n",
    "    * Very high alpha can lead to __underfitting__.\n",
    "* Also known as __L2 regression__ (becuase the regularization term is the L2 norm of the coefficients). \n",
    "    \n",
    "__Ridge regression in scikit-learn:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46648773",
   "metadata": {},
   "source": [
    "```from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "ridge = Ridge(alpha  = 0.1, normalize = True \n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_pred = Ridge.predict(X_test)\n",
    "ridge.score(X_test, y_test)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17205060",
   "metadata": {},
   "source": [
    "### Function for fitting ridge regression over a range of different alphas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9902ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(cv_scores, cv_scores_std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alpha_space, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "\n",
    "    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a221073",
   "metadata": {},
   "source": [
    "```#Import necessary modules\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Setup the array of alphas and lists to store scores\n",
    "alpha_space = np.logspace(-4, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "#Create a ridge regressor: ridge\n",
    "ridge = Ridge(normalize= True)\n",
    "#Compute scores over range of alphas\n",
    "for alpha in alpha_space:\n",
    "    #Specify the alpha value to use: ridge.alpha\n",
    "    ridge.alpha = alpha    \n",
    "    #Perform 10-fold CV: ridge_cv_scores\n",
    "    ridge_cv_scores = cross_val_score(ridge, X, y, cv= 10)   \n",
    "    #Append the mean of ridge_cv_scores to ridge_scores\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    #Append the std of ridge_cv_scores to ridge_scores_std\n",
    "    ridge_scores_std.append(np.std(ridge_cv_scores))\n",
    "#Display the plot\n",
    "display_plot(ridge_scores, ridge_scores_std)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa41cef",
   "metadata": {},
   "source": [
    "## Lasso regression\n",
    "* mirrors Ridge regression (substitute `Lasso` for `Ridge` in code above)\n",
    "* Lasso regression for feature selection-- can be used to select important features of a dataset\n",
    "* tends to shrink the coefficients of less important features to exactly 0\n",
    "    * the features who coefficients are not shrunk to zero are then selected by the Lasso algorithm\n",
    "* Lasso for feature selection in scikit-learn:\n",
    "\n",
    "```from scikit-learn.linear_model import Lasso\n",
    "names = boston.drop('MEDV', axis = 1).columns\n",
    "lasso = Lasso(alpha = 0.1) #optional parameter: normalize = True\n",
    "lasso_coef = lasso.fit(X, y).coef_\n",
    "_ = plt.plot(range(len(names)), lasso_coef)\n",
    "_ = plt.xticks(range(len(names)), names, rotation = 60)\n",
    "_ = plt.ylabel(\"Coefficients\")\n",
    "plt.show()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8dc0e",
   "metadata": {},
   "source": [
    "Important for communicating important features to bosses and colleagues in a powerful visual tool.\n",
    "\n",
    "Lasso regularization also known as __L1 regression__ (because the regularization term is the L1 norm of the coefficients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef94f8",
   "metadata": {},
   "source": [
    "### Confusion matrices\n",
    "__class imbalance:__ the situation when one class is more frequent. Example: of emails, 99% real and 1% spam; a very common situation in practice that requires a more nuanced metric (than accuracy) to assess the performance of a model.\n",
    "\n",
    "__Accuracy:__ sum of the diagonal, divided by the total sum of the confusion matrix:\n",
    "                    __(tp + tn) / (tp + tn + fp + fn)__ \\\n",
    "(true positive + true negative) / (true positive + true negative + false positive + false negative)\n",
    "\n",
    "__Precision:__ Also called \"Positive Predicted Value\" or PPV: \n",
    "__tp / (tp + fp)__\n",
    "\n",
    "__Recall:__ Also called __sensitivity__, \"hit rate\", or True Positive Rate \n",
    "__tp / (tp + fn)__\n",
    "\n",
    "__F1score:__ the harmonic mean of precision and recall\n",
    "__2 * (precision * recall) / (precision + recall)__\n",
    "\n",
    "\n",
    "__High precision:__ means that our classifier had a low false positive rate; Not many real emails were predicted as spam.\n",
    "\n",
    "__High recall:__ means that our classifier predicted most positive or spam emails correctly \n",
    "\n",
    "__Support column:__ gives the number of samples of the true response that lie in that class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855623cf",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "knn = KNeighborsClasifier(n_neighbors = 8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(x_test, y_pred)) #to print classification matrix\n",
    "print(classification_report(y_test, y_pred)) #to compute the resulting metrics\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb874a22",
   "metadata": {},
   "source": [
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "#Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors= 6)\n",
    "#Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "#Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "#Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92168125",
   "metadata": {},
   "source": [
    "## Logistic Regression and the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53be504",
   "metadata": {},
   "source": [
    "* Also known as log reg (for binary classification)\n",
    "* Log reg outputs probabilities\n",
    "* If 'p' is labeled greater than 0.5:\n",
    "    * the data is labeled '1'\n",
    "* If 'p' is less than 0.5:\n",
    "    * the data is labeled '0'\n",
    "* Log reg produces a linear decision boundary\n",
    "* follows same formula as KNeighbors and LinearRegression\n",
    "* __By default, logistical regression threshold = 0.5__\n",
    "* the set of points we get when trying all possible thresholds is called the __Receiver Operating Characteristic (ROC) Curve__.\n",
    "* Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to visually evaluate models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ddab05",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.metrics import roc_curve\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob) #first argument: actual labels\n",
    "#second argument: predicitive probailities and unpack the results into three variables\n",
    "_ = plt.plot([0,1], [0,1], 'k--')\n",
    "_ = plt.plot(fpr, tpr, label = 'Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c9357",
   "metadata": {},
   "source": [
    "__`predict.proba()`__ returns an array with two columns; each column contains the probabilities for the respective target values (in the above example we chose the second column- column 1- that is, the probabilities of the predicted labels being one). Most classifiers in scikit-learn have a `.predict_proba()` method.\n",
    "\n",
    "scikit-learn makes it very easy to try different models, since the Train-Test-Split/Instantiate/Fit/Predict paradigm applies to all classifiers and regressors - which are known in scikit-learn as 'estimators'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173b086",
   "metadata": {},
   "source": [
    "```\n",
    "#Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "#Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "#Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "#Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c5116",
   "metadata": {},
   "source": [
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "#Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "#Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "#Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03e32d",
   "metadata": {},
   "source": [
    "Like the alpha parameter in Ridge and Lasso Regression, Logistic Regression has a regularization __parameter: *C*__.\\\n",
    "__*C*__ controls the *inverse* of the regularization strength.\\\n",
    "A large __*C*__ can *overfit* a model.\\\n",
    "A small __*C*__ can *underfit* a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d1c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "712b87bc",
   "metadata": {},
   "source": [
    "## AUC in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cfe5f",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.metrics import roc_auc_score\n",
    "logreg = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred_prob)```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b96ab",
   "metadata": {},
   "source": [
    "* To compute the AUC, we first compute the predicted probabilities as above, and then pass the true labels and the predicted probabilities to roc_auc_score.\n",
    "* Also, compute AUC using cross-validation:\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(logreg, X, y, cv = 5, scoring = 'roc_auc')\n",
    "print(cv_scores)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0358986",
   "metadata": {},
   "source": [
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "#Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
    "#Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(logreg, X, y, cv = 5, scoring = 'roc_auc')\n",
    "#Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0ce21",
   "metadata": {},
   "source": [
    "## Grid Search Cross Validation:\n",
    "```\n",
    "sklearn.model_selection import GridSearch CV\n",
    "param_grid = {'n_neighbors' : np.arange(1, 50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = 5)\n",
    "knn_cv.fit(X, y)\n",
    "knn_cv.best_params_\n",
    "knn_cv.best_score_```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d093c",
   "metadata": {},
   "source": [
    "* Specify hyperparameter as a dictionary in which the keys are the hyperparameter names and (such as `n_neighbors` or `alpha`). The values are lists containing the values we wish to tune the relevant hyperparameter or hyperparameters over. \n",
    "* If we specify multiple parameters, all possible combinations will be tried \n",
    "* GridSearchCV returns a GridSearch object that you can then fit to the data and this fit performs the actual GridSearch in place \n",
    "* RandomizedSearchCV, which is similar to Grid Search, except that it is able to jump around the grid\n",
    "* GridSearch can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83167c",
   "metadata": {},
   "source": [
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "#Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "#Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "#Fit it to the data\n",
    "logreg_cv.fit(X, y)\n",
    "#Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce4a3d",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV\n",
    "* GridSearch can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters\n",
    "* A solution to this is to use RandomizedSearchCV, in which __not__ all hyperparameter values are tried out. \n",
    "* Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions. \n",
    "* Decision trees have *many* parameters that can be tuned, such as `max_features`, `max_depth`, and `min_samples_leaf`. This makes Decision trees an ideal use case for RandomizedSearchCV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea8758",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier\n",
    "* Decision trees have many parameters that can be tuned, such as `max_features`, `max_depth`, and `min_samples_leaf`. This makes Decision trees an ideal use case for `RandomizedSearchCV`.\n",
    "\n",
    "```\n",
    "#Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "#Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "#Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv= 5)\n",
    "#Fit it to the data\n",
    "tree_cv.fit(X,y)\n",
    "#Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b5c25",
   "metadata": {},
   "source": [
    "## Hold out set for final evaluation\n",
    "### Hold out set reasoning\n",
    "* How well can the model perform on never before seen data (given your scoring method of choice)?\n",
    "* Using ALL data for cross-validation is not ideal (because estimating model performance on any of it may not provide an accurate picture of how it will perform on unseen data).\n",
    "* __Split data into training and hold-out set at the beginning.__\n",
    "* Perform grid cross validation on the training set to tune model's hyperparameters\n",
    "* Then, select model's best hyperparameters and evaluate on hold-out set. \n",
    "\n",
    "### Hold out set: Classification\n",
    "* In addition to __C__, logistic regression has a 'penalty' hyperparameter which specifies whether to use 'L1' or 'L2' regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742cb8f",
   "metadata": {},
   "source": [
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "#Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "#Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state= 42)\n",
    "#Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv= 5)\n",
    "#Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "#Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523e2f1",
   "metadata": {},
   "source": [
    "## Hold out set: Regression\n",
    "* Remember lasso and ridge regression from the previous chapter? Lasso used the L1 penalty to regularize, while ridge used the L2 penalty. \n",
    "* There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the L1 and L2 penalties: \n",
    "                                    a * L1 + b * L2 \n",
    "* In scikit-learn, this term is represented by the 'l1_ratio' parameter: An 'l1_ratio' of 1 corresponds to an  penalty, and anything lower is a combination of L1 and L2.\n",
    "\n",
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "#Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "#Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "param_grid = {'l1_ratio': l1_space}\n",
    "#Instantiate the ElasticNet regressor: elastic_net\n",
    "elastic_net = ElasticNet()\n",
    "#Setup the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "#Fit it to the training data\n",
    "gm_cv.fit(X_train, y_train)\n",
    "#Predict on the test set and compute metrics\n",
    "y_pred = gm_cv.predict(X_test)\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "print(\"Tuned ElasticNet MSE: {}\".format(mse))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e762c0d",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "* In the real world, data is messy and you'll have to preprocess your data before you can build models. \n",
    "\n",
    "### Dealing with categorical features\n",
    "* Scikit-learn will not accept categorical features by default; you will have to preprocess these features into the correct format. \n",
    "* Need to encode categorical features numerically.\n",
    "* The way we achieve this, is by splitting the feature into a number of binary features called 'dummy variables' (one for each category).\n",
    "    * 0 means the observation was NOT that category.\n",
    "    * 1 means the observation WAS that category.\n",
    "    * In the case that an observation must belong to one of the categories, you only need n-1 number of categories in columns. For example, Cars of origin US, Asia, Europe: you only need two columns. The third is implied. If we don't do this, we are duplicating information, which may be an issue for some models\n",
    "\n",
    "### Dealing with categorical features in Python\n",
    "* scikit-learn: `OneHotEncoder()`\n",
    "* pandas: `get_dummies()`\n",
    "\n",
    "#### Encoding dummy variables\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.read_csv('auto.csv')\n",
    "df_origin = pd.get_dummies(df)\n",
    "print(df_origin.head())\n",
    "```\n",
    "__Note:__ Here, __by default__ pandas creates three dummy variables for the cars origin DataFrame \\\n",
    "* To prevent duplicate information which may cause issues for some models, you must drop (one of the) extra/redundant columns:\n",
    "\n",
    "`df_origin = df_origin.drop(origin_Asia, axis = 1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791e1de",
   "metadata": {},
   "source": [
    "### Linear Regression with dummy variables\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import test_train_split\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "ridge = Ridge(alpha= 0.5, normalize = True).fit(X_train, y_train)\n",
    "ridge.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2235c23",
   "metadata": {},
   "source": [
    "### Boxplots\n",
    "Boxplots are particularly useful for visualizing categorical features:\n",
    "```\n",
    "#Import pandas\n",
    "import pandas as pd\n",
    "# Read 'gapminder.csv' into a DataFrame: df\n",
    "df = pd.read_csv('gapminder.csv')\n",
    "#Create a boxplot of life expectancy per region\n",
    "df.boxplot('life', 'Region', rot=60)\n",
    "#Show the plot\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9260a0",
   "metadata": {},
   "source": [
    "```\n",
    "#Create dummy variables: df_region\n",
    "df_region = pd.get_dummies(df)\n",
    "#Print the columns of df_region\n",
    "print(df_region.columns)\n",
    "#Create dummy variables with drop_first=True: df_region\n",
    "df_region = pd.get_dummies(df, drop_first= True)\n",
    "#Print the new columns of df_region\n",
    "print(df_region.columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11149d2",
   "metadata": {},
   "source": [
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#Instantiate a ridge regressor: ridge\n",
    "ridge = Ridge(alpha= 0.5, normalize=True)\n",
    "#Perform 5-fold cross-validation: ridge_cv\n",
    "ridge_cv = cross_val_score(ridge, X, y, cv=5)\n",
    "#Print the cross-validated scores\n",
    "print(ridge_cv)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a0f59",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "### Turn 0's into NaNs and drop:\n",
    "__Drop all rows containing missing data using `.dropna()`__\n",
    "```\n",
    "df.insulin.replace(0, np.nan, inplace= True)\n",
    "df.triceps.replace(0, np.nan, inplace= True)\n",
    "df.bmi.replace(0, np.nan, inplace= True)\n",
    "df.dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea68d7c",
   "metadata": {},
   "source": [
    "### Imputing missing data\n",
    "* Data imputation is one of several important steps for preprocessing ML models\n",
    "* Imputing missing values = making an educating guess about the values\n",
    "* Use __mean__ and __median__ of non-missing entries.\n",
    "\n",
    "``` \n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy= 'mean', axis = 0)\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)\n",
    "```\n",
    "* Imputers are called transformers\n",
    "* Any model that can transform data in this way is called a transformer\n",
    "* Do both at once with scikit-learn's pipeline\n",
    "\n",
    "```\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values = 'NaN', strategy = 'mean', axis= 1)\n",
    "logreg = LogisticRegression()\n",
    "steps = [('imputation', imp), 'logistic_regression', logreg)]\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= 42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "pipeline.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1a305",
   "metadata": {},
   "source": [
    "* build a pipeline object by constructing a list of steps in the pipeline, where each step is a two-tuple containing the name you wish to give the relevant step and the estimator.\n",
    "* Then pass this list to the Pipeline constructor\n",
    "* Then split data into training and test sets\n",
    "* Then fit the Pipeline to the training set\n",
    "* Then predict on the test set\n",
    "* For good measure, compute accuracy\n",
    "* __NOTE:__ In a pipeline, each step but the last __must__ be a transformer, and the last __must__ be an estimator, such as a classifier, regressor, or transformer\n",
    "\n",
    "```\n",
    "#Convert '?' to NaN\n",
    "df[df == '?'] = np.nan\n",
    "#Print the number of NaNs\n",
    "print(df.isnull().sum())\n",
    "#Print shape of original DataFrame\n",
    "print(\"Shape of Original DataFrame: {}\".format(df.shape))\n",
    "#Drop missing values and print shape of new DataFrame\n",
    "df = df.dropna()\n",
    "#Print shape of new DataFrame\n",
    "print(\"Shape of DataFrame After Dropping All Rows with Missing Values: {}\".format(df.shape))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0557cd",
   "metadata": {},
   "source": [
    "###  Impute missing data in an ML Pipeline:\n",
    "* There are many steps to building a model, from creating training and test sets, to fitting a classifier or regressor, to tuning its parameters, to evaluating its performance on new data. \n",
    "* Imputation can be seen as the first step of this machine learning process, the entirety of which can be viewed within the context of a pipeline. \n",
    "* Scikit-learn provides a pipeline constructor that allows you to piece together these steps into one process and thereby simplify your workflow.\n",
    "* You can practice setting up a pipeline with two steps: the imputation step, followed by the instantiation of a classifier. \n",
    "    * example classifiers: k-NN, logistic regression, and the decision tree, Support Vector Machine (SVM)\n",
    "    * SVC stands for Support Vector Classification, which is a type of SVM.\n",
    "    \n",
    "```\n",
    "#Import the Imputer module\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import SVC\n",
    "#Setup the Imputation transformer: imp\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "#Instantiate the SVC classifier: clf\n",
    "clf = SVC()\n",
    "#Setup the pipeline with the required steps: steps\n",
    "steps = [('imputation', imp),\n",
    "        ('SVM', clf)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d229db4",
   "metadata": {},
   "source": [
    "* What makes pipelines so incredibly useful is the simple interface that they provide. \n",
    "* You can use the .fit() and .predict() methods on pipelines just as with classifiers and regressors!\n",
    "```\n",
    "#Import necessary modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "#Setup the pipeline steps: steps\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n",
    "        ('SVM', SVC())]\n",
    "#Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "#Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= 42)\n",
    "#Fit the pipeline to the train set\n",
    "pipeline.fit(X_train, y_train)\n",
    "#Predict the labels of the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "#Compute metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9765d3",
   "metadata": {},
   "source": [
    "```\n",
    "#Setup the pipeline\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('SVM', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "#Specify the hyperparameter space\n",
    "parameters = {'SVM__C':[1, 10, 100],\n",
    "              'SVM__gamma':[0.1, 0.01]}\n",
    "#Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 21)\n",
    "#Instantiate the GridSearchCV object: cv\n",
    "cv = GridSearchCV(pipeline, param_grid= parameters)\n",
    "#Fit to the training set\n",
    "cv.fit(X_train, y_train)\n",
    "#Predict the labels of the test set: y_pred\n",
    "y_pred = cv.predict(X_test)\n",
    "#Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_test, y_test)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbddbaa",
   "metadata": {},
   "source": [
    "## Bringing it all together: Pipeline for regression\n",
    "* goal: build a pipeline that imputes the missing data, scales the features, and fits an ElasticNet to the Gapminder data. You will then tune the l1_ratio of your ElasticNet using GridSearchCV.\n",
    "```\n",
    "#Setup the pipeline steps: steps\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('elasticnet', ElasticNet())]\n",
    "#Create the pipeline: pipeline \n",
    "pipeline = Pipeline(steps)\n",
    "#Specify the hyperparameter space\n",
    "parameters = {'elasticnet__l1_ratio':np.linspace(0,1,30)}\n",
    "#Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.4, random_state=42)\n",
    "#Create the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(pipeline, param_grid= parameters)\n",
    "#Fit to the training set\n",
    "gm_cv.fit(X_train, y_train)\n",
    "#Compute and print the metrics\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "print(\"Tuned ElasticNet Alpha: {}\".format(gm_cv.best_params_))\n",
    "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9591f04",
   "metadata": {},
   "source": [
    "Book: __Introduction to Machine Learning with Python__ by Andreas Muller and Sarah Guido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e98936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604f637f",
   "metadata": {},
   "source": [
    "## Centering and Scaling\n",
    "* Centering and Scaling is another important preprocessing step in ML\n",
    "* Scaling features can significantly improve the performance of a model (however, this is not always the case: when all features are binary, scaling will have minimal effect) \n",
    "__Why scale your data?__\n",
    "* Many ML models use some sort of distance measurement to inform them\n",
    "* Therefore, differing ranges or scales can be a huge problem \n",
    "* Features on larger scales can unduly influence the model \n",
    "* Example: kNN uses distance explicitly when making predictions\n",
    "* For these reasons, we want features to be on a similar scale\n",
    "* To achieve this, we use __normalizing__ (or __centering and scaling__)\n",
    "__Ways to normalize your data:__\n",
    "* There are several ways to normalize your data\n",
    "* __Standardization:__ Given any column, subtract the mean and divide by the variance\n",
    "    * Makes all features centered around zero \n",
    "    * Makes all features have variance one. \n",
    "\n",
    "* Subtract by the minimum and divide by the range \n",
    "    * Makes dataset have minimum 0 and maximum 1\n",
    "    \n",
    "* Can also normalize so that the data ranges from -1 to +1\n",
    "\n",
    "* See scikit-learn docs for further info on each method above.\n",
    "\n",
    "## Standardization\n",
    "```\n",
    "from sklearn.preprocessing import scale\n",
    "X_scaled = scale(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f8ec5",
   "metadata": {},
   "source": [
    "* Check columns for new mean and standard deviation: \n",
    "```\n",
    "np.mean(X), np.std(X)\n",
    "np.mean(X_scaled), np.std(X_scaled)\n",
    "```\n",
    "\n",
    "### Scaling in a pipeline\n",
    "* Also: put Scaler in a Pipeline object\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "steps = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 21)\n",
    "knn_scaled = pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_score = (y_test, y_pred)\n",
    "```\n",
    "* In the above example from DataCamp, scaling resulted in an improvement in accuracy score from 0.928 to 0.956\n",
    "* So here, scaling did improve our model performance\n",
    "\n",
    "### CV and scaling in a pipeline\n",
    "```\n",
    "steps = [('scaler', StandardScaler()), ('knn', KNeighborsClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {knn__n_neighbors : np.arange(1, 50)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 21)\n",
    "cv = GridSearchCV(pipeline, param_grid= parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n",
    "print(cv.best_params_)\n",
    "print(cv_score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "* Specify hyperparameter space by creating a dictionary \n",
    "* The keys are the pipeline step name, followed by a double underscore, followed by the hyperparameter name\n",
    "* The corresponding value is a list or array of values to try for that particular hyperparameter\n",
    "* train test split\n",
    "* We then perform a grid search over the parameters in the pipeline by instantiating the GridSearchCV object and fitting it to training data\n",
    "\n",
    "```\n",
    "#Import scale\n",
    "from sklearn.preprocessing import scale\n",
    "#Scale the features: X_scaled\n",
    "X_scaled = scale(X)\n",
    "#Print the mean and standard deviation of the unscaled features\n",
    "print(\"Mean of Unscaled Features: {}\".format(np.mean(X))) \n",
    "print(\"Standard Deviation of Unscaled Features: {}\".format(np.std(X)))\n",
    "#Print the mean and standard deviation of the scaled features\n",
    "print(\"Mean of Scaled Features: {}\".format(np.mean(X_scaled))) \n",
    "print(\"Standard Deviation of Scaled Features: {}\".format(np.std(X_scaled)))\n",
    "```\n",
    "***\n",
    "```\n",
    "#Import the necessary modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "#Setup the pipeline steps: steps\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier())]      \n",
    "#Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "#Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state= 42)\n",
    "#Fit the pipeline to the training set: knn_scaled\n",
    "knn_scaled = pipeline.fit(X_train, y_train)\n",
    "#Instantiate and fit a k-NN classifier to the unscaled data\n",
    "knn_unscaled = KNeighborsClassifier().fit(X_train, y_train)\n",
    "#Compute and print metrics\n",
    "print('Accuracy with Scaling: {}'.format(knn_scaled.score(X_test, y_test)))\n",
    "print('Accuracy without Scaling: {}'.format(knn_unscaled.score(X_test, y_test)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2eb72",
   "metadata": {},
   "source": [
    "## Bringing it all together: Pipeline for classification\n",
    "* Goal: build a pipeline that includes scaling and hyperparameter tuning to classify\n",
    "* __SVM classifier__: hyperparameters: \n",
    "    * __*C*__ controls the regularization strength; it is analogous to the *C* of Logistic Regression\n",
    "    * __*gamma*__ controls the kernel coefficient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99628a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281e675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc92c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "660dcfd2",
   "metadata": {},
   "source": [
    "# Notes for Cap2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16086e2",
   "metadata": {},
   "source": [
    "* baseline error of using mean to predict values\n",
    "* train test split\n",
    "* optimal value of k for k-fold cross validation\n",
    "* SCALE / normalize values\n",
    "* Centering/ scaling/ normalizing values-- Standardization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0dab30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627db08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107afb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
