{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca93e89",
   "metadata": {},
   "source": [
    "# Intro to Deep Learning with OpenCV\n",
    "**Instructor**: Jonathan Fernandes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34dc87",
   "metadata": {},
   "source": [
    "* OpenCV $\\Rightarrow$ **BGR** format\n",
    "    * Why?\n",
    "    * Years ago, when OpenCV was created, many cameras were BGR instead of RGB\n",
    "    \n",
    "* OpenCV's deep learning module is known as **dnn**s, or deep neural networks\n",
    "* The dnn model is **not** a full-fledged deep learning framework\n",
    "    * We cannot **train** any deep learning neural network\n",
    "    * **No** backpropagation (and so, no \"learning\")\n",
    "    \n",
    "<img src='data/opencv1.png' width=\"500\" height=\"250\" align=\"center\"/>\n",
    "\n",
    "#### Popular uses of OpenCV:\n",
    "\n",
    "<img src='data/opencv2.png' width=\"200\" height=\"100\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f871c38",
   "metadata": {},
   "source": [
    "#### Expert Systems\n",
    "    * Rules determine actions\n",
    "    \n",
    "#### Machine learning\n",
    "    * Data determines the rules\n",
    "    \n",
    "<img src='data/opencv3.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/opencv4.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "\n",
    "### OpenCV\n",
    "* Makes code simpler\n",
    "* Standard CPUs can do this (no GPUs necessary)\n",
    "* As of OpenCV 4, the dnn module supports:\n",
    "    * Caffe \n",
    "    * Tensorflow\n",
    "    * Torch \n",
    "    * Darknet\n",
    "    * ONNX (format)\n",
    "\n",
    "#### Advantages\n",
    "* OpenCV is framework- independent\n",
    "    * It has no framework-specific limitations\n",
    "* Models are represented internally in OpenCV\n",
    "    * code can be optimized\n",
    "* OpenCV has its own deep learning implementation\n",
    "    * external dependencies are kept to a minimum\n",
    "    \n",
    "<img src='data/opencv5.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* A simple inference engine will simply pass the input data through the network and output the result\n",
    "    * However, there are a lot of optimizations that can be performed that make the inference speed fast(er)\n",
    "    * For instance:\n",
    "        * prune part of the NN that isn't activated\n",
    "        * combine multiple layers into a single computational step\n",
    "* Inference can be done on standard CPUs\n",
    "\n",
    "#### OpenVINO\n",
    "* Open Visual Inferencing and Neural Network Optimization\n",
    "    * designed to speed up neural networks for tasks like image classification and object detection\n",
    "    \n",
    "#### Support for:\n",
    "   * AlexNet\n",
    "   * GoogleNet\n",
    "   * VGG\n",
    "   * ResNet\n",
    "   * SqueezeNet\n",
    "   * DenseNet\n",
    "   * ShuffleNet\n",
    "   \n",
    "### Person identification: OpenFace (Torch)\n",
    "\n",
    "#### Overview of the dnn process\n",
    "\n",
    "* To use webcam instead of saved jpg/mov, in place of file path provide `0`\n",
    "\n",
    "<img src='data/opencv6.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "    \n",
    "    \n",
    "<img src='data/opencv7.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "#### Create a Four-Dimensional Blob\n",
    "\n",
    "```\n",
    "cv2.dnn.readNetFromCaffe(prototxt, caffeModel)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, [scalefactor], [size], [mean], [swapRB], [crop], [ddepth])\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "outp = net.forward()\n",
    "```\n",
    "\n",
    "### Working with Blobs\n",
    "* **Blob**: One or more images with the same width, height, and number of channels that have all been preprocessed in the same way.\n",
    "\n",
    "<img src='data/opencv8.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* **Note** if you have more than one blob, use **`blobFromImages()`**\n",
    "    * The output of `blobFromImage()` is a 4D Tensor (NCHW)\n",
    "        * **NCHW**: **N**umber of images, (number of) **C**hannels, **H**eight of the Tensor, **W**eights \n",
    "        * This is stored in a `blob object` which is then passed to a trained model, which allows us to get the image or video inference\n",
    "        * For images and videos, this (inference) could be:\n",
    "            * **Object detection**\n",
    "            * **Semantic segmentation**\n",
    "            * Much, much more\n",
    "            \n",
    "#### blobFromImage parameters\n",
    "* `blobFromImage` creates a 4D blob\n",
    "\n",
    "<img src='data/opencv9.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134f15b",
   "metadata": {},
   "source": [
    "### Image Classification\n",
    "* The ImageNet image database is organized according to the WordNet hierarchy\n",
    "* Each meaningful concept in wordnet, which could be multiple words, is called a **synonym set** or a **synset**\n",
    "* These 1000 classes are stored in this synset file; if we open the synset file, we can see the 1000 different categories.\n",
    "    * Here, each row corresponds to a category and then one or more words describing the category\n",
    "    * 1000 rows corresponding to 1000 classes\n",
    "    \n",
    "### Classification for an image: inference\n",
    "\n",
    "#### Output of Image Classification\n",
    "* Now we'll use the OpenCV dnn module as an inference engine\n",
    "* We'll pass an image through a pre-trained model that has been trained on the 1,000 clases of ImageNet\n",
    "* The model will then output the probability that the image contains each of the 1,000 classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd0055",
   "metadata": {},
   "source": [
    "## Classification for a video\n",
    "* Here we'll get started with using OpenCV's `dnn` module as an inference engine for a video file\n",
    "* We can reuse many of the concepts used in image classification when working with video files\n",
    "\n",
    "### YOLOv3\n",
    "* \"You Only Look Once\"\n",
    "* In the past, detection algorithms apply a model to an image multiple times at different locations and scales\n",
    "* **YOLO v3 applies model only once to multiple regions of the image.**\n",
    "    * The NN divides the image into regions nad predicts bounding boxes and probabilities for each region\n",
    "    * The network only needs to view the image one time and then the bounding boxes are weighted by the predictive probabilities\n",
    "    * We can also set thresholds (say, 80%) and only if the YOLO algorithm is more than 80& sure that it has detected a particular class will it draw a bounding box around it. \n",
    "    * YOLO v3 has been trained on the **COCO datset which has 80 different classes of objects**\n",
    "* If objects haven't been detected, we can lower the confidence threshold and that might allow them to be picked up by the algorithm (but that also may introduce incorrect classifications).\n",
    "* The YOLO v3 algorithm is a very powerful object-detection algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
