{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9f4ee6",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436cb9f",
   "metadata": {},
   "source": [
    "* Pre-reqs:\n",
    "    * Linear classifiers in Python\n",
    "    * Machine Learning with Tree-Based Models in Python\n",
    "    * Supervised Learning with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323336a4",
   "metadata": {},
   "source": [
    "### CAPSTONE TO DO: choose an evaluation metric for ensemble model: accuracy, sensitivity, specificty, other?\n",
    "* **Accuracy:** shows the percentage of the dataset instances correctly predicted by the model developed by the machine learning algorithm\n",
    "* **Sensitivity:** shows the percentage of COVID-19 positive patients correctly by the models\n",
    "* **Specificity:**  shows the percentage of COVID-19 negative patients correctly by the models\n",
    "\n",
    "* Create cross-val table of: CCI, TP, FP, Precision, Recall, F Measure/F1 Score, ROC/AUC?\n",
    "* **F1 Score for imbalanced data classes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5de746",
   "metadata": {},
   "source": [
    "### Combining multiple models\n",
    "* When you're building a model, you want to choose the one that performs the best according to some evaluation metric\n",
    "* Ensemble methods: form a new model by combining existing ones; the combined responses of different models will likely lead to a better decision than relying on a single response.\n",
    "    * the combined model will have better performance than any of the individual models (or at least be as good as the best individual model)\n",
    "* Ensemble learning is one of the most effective techniques in machine learning\n",
    "* A useful Python library for machine learning called `mlxtend`\n",
    "* Main scikit-learn module: `sklearn.ensemble`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f3846",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.ensemble import MetaEstimator\n",
    "# Base estimators\n",
    "est1 = Model1()\n",
    "est2 = Model1()\n",
    "estN = ModelN()\n",
    "# Meta estimator\n",
    "est_combined = MetaEstimator(estimators=[est1, est2,  ..., estN], \n",
    "                # Additional parameters (specific to the ensemble method)\n",
    ")\n",
    "# Train and test\n",
    "est_combined.fit(X_train, y_train)\n",
    "pred = est_combined.predict(X_test)\n",
    "```\n",
    "* The best feature of the meta estimator is that it works similarly to the scikit-learn estimators you already know, with the standard methods of fit and predict\n",
    "* Decision trees are the building block of many ensemble methods\n",
    "\n",
    "RECAP DT CODE:\n",
    "\n",
    "```\n",
    "# Split into train (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the regressor\n",
    "reg_dt = DecisionTreeRegressor(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "\n",
    "# Fit to the training set\n",
    "reg_dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the test set\n",
    "y_pred = reg_dt.predict(X_test)\n",
    "print('MAE: {:.3f}'.format(mean_absolute_error(y_test, y_pred)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3560a593",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa51ba2",
   "metadata": {},
   "source": [
    "* Concept of \"wisdom of the crowds\": refers to the collective intelligence based on a group of individuals instead of a single expert \n",
    "* Also known as **collective intelligence**\n",
    "* The aggregated opinion of the crowd can be as good as (and is usually superior to) the answer of any individual, even that of an expert.\n",
    "* Useful technique commonly applied to problem solving, decision making, innovation, and prediction (we are particularly interested in prediction)\n",
    "\n",
    "* **Majority voting:** a technique that combines the output of many classifiers using a maority voting approach\n",
    "    * Properties:\n",
    "        * Classification problems\n",
    "        * Majority voting $\\Rightarrow$ Mode of individual predictions\n",
    "        * **It is recommended to use an odd number of classifiers:** Use at least **three** classifiers, and when problem constraints allow it, use five or more\n",
    "        \n",
    "        \n",
    "* **Wise Crowd Characteristics:**\n",
    "    * **The ensemble needs to be diverse:** do this by using different algorithms or different datasets.\n",
    "    * **Independent and uncorrelated:** Each prediction needs to be independent and uncorrelated from the rest.\n",
    "    * **Use individual knowledge:** Each model should be able to make its own predition without relying on the other predictions\n",
    "    * **Aggregate individual predictions:** into a collective one\n",
    "    \n",
    "**NOTE:** Majority Voting can only be applied to classification problems\n",
    "    * For regression problems, see: ensemble voting regressor\n",
    "    \n",
    "```\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "clf_voting = VotingClassifier(\n",
    "       estmators = [\n",
    "           ('label1', clf_1),\n",
    "           ('label2', clf_2),\n",
    "           ('labelN', clf_N)])\n",
    "         \n",
    "```\n",
    "\n",
    "```\n",
    "# Create the individual models\n",
    "clf_knn = KNeightborsClassifier(5) # k=5 nearest neighbors (to avoid multi-modal predictions)\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "# Create voting classifier\n",
    "clf_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('knn', clf_knn),\n",
    "        ('dt', clf_dt),\n",
    "        ('lr', clf_lr)])\n",
    "# Fit combined model to the training set and predict\n",
    "clf_voting.fit(X_train, y_train)\n",
    "y_pred = clf_voting.predict(X_test)\n",
    "```\n",
    "#### Evaluate the performance\n",
    "\n",
    "```\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(X_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))\n",
    "```\n",
    "\n",
    "\n",
    "* The main input- with keyword \"estimators\" - is a list of (string, estimator) tuples.\n",
    "* Each string is a label and each estimtor is an sklearn classifier\n",
    "* **You do not need to fit the classifiers individually, as the voting classifier will take care of that.**\n",
    "    * But you do need to tune hyperparameters? Not sure...\n",
    "    \n",
    "```\n",
    "# Make the invidual predictions\n",
    "pred_lr = clf_lr.predict(X_test)\n",
    "pred_dt = clf_dt.predict(X_test)\n",
    "pred_knn = clf_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of each model\n",
    "score_lr = f1_score(y_test, pred_lr)\n",
    "score_dt = f1_score(y_test, pred_dt)\n",
    "score_knn = f1_score(y_test, pred_knn)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d835ae",
   "metadata": {},
   "source": [
    "* **1) Choose the best model**\n",
    "    * generate predictions as per each model\n",
    "    * get evaluation metric scores for each model's predictions (F1 score, accuracy, precision, recall, etc)\n",
    "    * Decide which model performs the best\n",
    "    \n",
    "* **2) Instantiate models**\n",
    "\n",
    "```\n",
    "# Instantiate the individual models\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_lr = LogisticRegression(class_weight='balanced')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "\n",
    "# Create and fit the voting classifier\n",
    "clf_vote = VotingClassifier(\n",
    "    estimators=[('knn', clf_knn), ('lr', clf_lr), ('dt', clf_dt)]\n",
    ")\n",
    "clf_vote.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "* **3) Evaluate your ensemble**\n",
    "\n",
    "```\n",
    "# Calculate the predictions using the voting classifier\n",
    "pred_vote = clf_vote.predict(X_test)\n",
    "\n",
    "# Calculate the F1-Score of the voting classifier\n",
    "score_vote = f1_score(y_test, pred_vote)\n",
    "print('F1-Score: {:.3f}'.format(score_vote))\n",
    "\n",
    "# Calculate the classification report\n",
    "report = classification_report(y_test, pred_vote)\n",
    "print(report)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f00ff",
   "metadata": {},
   "source": [
    "### Averaging aka \"Soft Voting\"\n",
    "* Averaging is another popular ensemble method\n",
    "* Averaging is also referred to as **soft voting**\n",
    "* Averaging/ Soft Voting can be applied to both classification and regression.\n",
    "* In this technique, the combined prediction is the mean of the individual predictions\n",
    "* **Soft voting: Mean**\n",
    "    * **Regression:** mean of predicted values\n",
    "    * **Classification:** mean of predicted *probabilities*\n",
    "* As the mean doesn't have ambiguous cases (like the mode), we can use any number of estimators (odd or even), as long as we have at least two.\n",
    "\n",
    "* To build an averaging classifier, we'll use the same class as before: **`VotingClassifier()`**\n",
    "    * **Main difference:** we specify an additional parameter: **`voting='soft`**\n",
    "        * Default value of voting is `'hard'`\n",
    "#### Averaging Classifier    \n",
    "    \n",
    "```\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "clf_voting = VotingClassifier(\n",
    "                estimators=[\n",
    "                    ('label1', clf_1),\n",
    "                    ('label2', clf_2),\n",
    "                    ...\n",
    "                    ('labelN', clf_N)],\n",
    "                voting = 'soft', \n",
    "                weights=[w_1, w_2, ..., w_N]\n",
    ")\n",
    "```\n",
    "* parameter `weights` is optional; specifies a weight for each of the estimators\n",
    "    * If specified, the combined prediction is a weighted average of the individual ones\n",
    "    * Otherwise, weights are considered uniform.\n",
    "* To build an **`AveragingRegressor()`:**\n",
    "#### Averaging Regressor:\n",
    "\n",
    "```\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "reg_voting = VotingRegressor(\n",
    "        estimators = [\n",
    "            ('label1', reg_1),\n",
    "            ('label2', reg_2),\n",
    "            ...\n",
    "            ('labelN', reg_N)],\n",
    "        voting = 'soft',\n",
    "        weights = [w_1, w_2, ..., w_N]\n",
    ")\n",
    "```\n",
    "* The first parameter is also a list of the string/estimator tuples, but instead of classifiers, we use regressors\n",
    "\n",
    "\n",
    "***\n",
    "* **Averaging classigier example:**\n",
    "```\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "clf_knn = KNeighborsClassifier(5)\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "clf_voting = VotingClassifier(\n",
    "        estimators = [\n",
    "            ('knn', clf_knn),\n",
    "            ('dt', clf_dt),\n",
    "            ('lr', clf_lr)],\n",
    "        voting='soft',\n",
    "        weights = [1, 2, 1]\n",
    ")\n",
    "```\n",
    "* Assuming we know that Decision Tree has better individual performance, we give it a higher weight\n",
    "* Ideally, the weights should be tuned while training the model, for example, using grid search cross-validation (`GridSearchCV`).\n",
    "\n",
    "```\n",
    "# Build the individual models\n",
    "clf_lr = LogisticRegression(class_weight='balanced')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf_svm = SVC(probability=True, class_weight='balanced', random_state=500)\n",
    "\n",
    "# List of (string, estimator) tuples\n",
    "estimators = [('lr', clf_lr), ('dt', clf_dt), ('svm', clf_svm)]\n",
    "\n",
    "# Build and fit an averaging classifier\n",
    "clf_avg = VotingClassifier(estimators = estimators,voting='soft')\n",
    "clf_avg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "acc_avg = accuracy_score(y_test,  clf_avg.predict(X_test))\n",
    "print('Accuracy: {:.2f}'.format(acc_avg))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76f185",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "#### The strength of weak models\n",
    "* What is a weak model and how to identify one by its properties?\n",
    "* Voting and averaging work by combining the predictions of already trained models\n",
    "    * Small number of estimators\n",
    "    * **Fine-tuned estimators**\n",
    "    * Individually optimized and trained for the problem\n",
    "    \n",
    "#### Weak vs. fine-tuned model\n",
    "\n",
    "#### Weak estimator\n",
    "* A \"weak\" model does not mean that it is a \"bad\" model, just that it is not as strong as a highly-optimized, finely-tuned model.\n",
    "* Performance is slightly better than random guessing\n",
    "* The error rate is less than 50%, but close to it\n",
    "* A weak model should be light in terms of space and computational requirements, and fast during training and modeling.\n",
    "* One good example: a decision tree limited to a depth of two\n",
    "* **The three desired properties:\n",
    "    * Low performance (just above guessing)\n",
    "    * It is light\n",
    "    * Low training and evaluation time\n",
    "* Common examples of weak models:\n",
    "    * decision tree with small depth\n",
    "    * Logistic Regression (makes the assumption that the classes are linearly separable)\n",
    "        * could also limit number of iterations for training\n",
    "        * or, specify a high value of the parameter C to use a weak regularization\n",
    "    * Linear Regression \n",
    "        * Makes the assumption that the output is a linear function of the input features\n",
    "        * could limit the number of iterations or not use normalization\n",
    "    * Other restricted models\n",
    "\n",
    "#### Bagging = Bootstrap Aggregating\n",
    "* Heterogenous vs homogenous ensemble methods\n",
    "#### Heterogenous:\n",
    "* Different algorithms (fine-tuned)\n",
    "* Work well with a small number of estimators\n",
    "* For example, we could combine a decision tree, a logistic regression, and a support vector machine using voting to improve the results\n",
    "* Included: Voting, Averaging, Stacking\n",
    "#### Homogenous\n",
    "* methods such as bagging\n",
    "* work by applying the same algorithm on all the estimators, and this algorithm must be a \"weak\" model\n",
    "* Large number of weak estimators\n",
    "* Bagging and Boosting are some of the most popular of this kind\n",
    "\n",
    "#### Condorcet's Jury Theorem:\n",
    "* **Requirements:**\n",
    "* All models must be independent\n",
    "* Each model performs better than random guessing\n",
    "* All individual models have similar performance\n",
    "\n",
    "* If these three conditions are met, then adding more models increases the probability of the ensemble to be correct, and makes this probability tend to 1 (1 equivalent to 100%)\n",
    "* The second and third requirements can be fulfilled by using the same weak model for all the estimators\n",
    "\n",
    "* To guarantee the first requirement of the theorem, the **bagging algorithm** trains individual models using a random subsample for each (known as **bootstrapping**)\n",
    "\n",
    "* A wise crowd needs to be diverse, either through using different datasets or algorithms\n",
    "\n",
    "* **Bootstrapping** requires:\n",
    "    * Random subsamples $\\Rightarrow$ provides **diversity** of data\n",
    "    * Using replacement\n",
    "    \n",
    "* Bagging helps reduce variance, as the sampling is truly random\n",
    "* Bias can be reduced since we use voting or averaging to combine the models \n",
    "* Bagging provides stablity and robustness\n",
    "* However, **bagging is computationally expensive in terms of space and time**\n",
    "\n",
    "* To take a sample, you'll use pandas' `.sample()` method, which has a replace parameter. For example, the following line of code samples with replacement from the whole DataFrame df:\n",
    "    * `df.sample(frac=1.0, replace=True, random_state=42)`\n",
    "    \n",
    "```\n",
    "# Take a sample with replacement\n",
    "X_train_sample = X_train.sample(frac=1.0, replace=True, random_state=42)\n",
    "y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "# Build a \"weak\" Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=500)\n",
    "\n",
    "# Fit the model to the training sample\n",
    "clf.fit(X_train_sample, y_train_sample)\n",
    "```\n",
    "\n",
    "```\n",
    "def build_decision_tree(X_train, y_train, random_state=None):\n",
    "    # Takes a sample with replacement,\n",
    "    # builds a \"weak\" decision tree,\n",
    "    # and fits it to the train set\n",
    "\n",
    "def predict_voting(classifiers, X_test):\n",
    "    # Makes the individual predictions \n",
    "    # and then combines them using \"Voting\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906daca",
   "metadata": {},
   "source": [
    "#### BaggingClassifier\n",
    "* **Heterogenous Ensemble Functions**\n",
    "* A key difference between the ensemble functions from heterogenous and homogenous methods:\n",
    "\n",
    "```\n",
    "het_est = HeterogenousEnsemble(\n",
    "    estimators= [('est1', est1), ('est2', est2), ...], \n",
    "    # additional parameters\n",
    ")\n",
    "```\n",
    "\n",
    "* **Homogenous Ensemble Functions:**\n",
    "* To build a homogenous ensemble model, instead of a list of estimators, we pass the parameter base_estimator, which is the instantiated \"weak\" model we have chosen for our ensemble:\n",
    "\n",
    "```\n",
    "hom_est = HomogenousEnsemble(\n",
    "            base_estimator= est_base,\n",
    "            n_estimators= chosen_number,\n",
    "            #additional paramters\n",
    ")\n",
    "```\n",
    "\n",
    "#### BaggingClassifier example:\n",
    "\n",
    "```\n",
    "clf_dt = DecisionTreeClassifier(max_depth=3)\n",
    "clf_bag = BaggingClassifer(\n",
    "            base_estimator= clf_dt,\n",
    "            n_estimators=5\n",
    ")\n",
    "clf_bag.fit(X_train, y_train)\n",
    "y_pred = clf_bag.predict(X_test)\n",
    "```\n",
    "\n",
    "#### BaggingRegressor example\n",
    "\n",
    "```\n",
    "reg_lr = LinearRegression(normalization=False)\n",
    "reg_bag = BaggingRegressor(\n",
    "            base_estimator=reg_lr,\n",
    "            oob_score = True # oob_score = out-of-bag score\n",
    ")\n",
    "reg_bag.fit(X_train, y_train)\n",
    "y_pred = reg_bag.predict(X_test)\n",
    "```\n",
    "* Note: default number of estimators is ten, when left undefined as above\n",
    "\n",
    "#### Out-of-bag score\n",
    "* In a bagging ensemble, each estimator is trained on a bootstrap sample. Therefore, each of the samples will leave out some of the instances, which are then used to evaluate each estimator, similar to a train-test split\n",
    "* To get the out-of-bag score for each instance, we calculate the predictions using all the estimators for which it was out of the sample\n",
    "* Then, combine individual predictions\n",
    "* Evaluate the metric on those predictions\n",
    "    * For **classification** the default metric is accuracy\n",
    "    * For **regression** the default metric is R2 (aka **coefficient of determination**)\n",
    "* **Out of bag score helps avoid the need for an independent test set**\n",
    "    * However, it's often lower than the actual performance\n",
    "* To get the out-of-bag score from a Bagging ensemble, we need to set the parameter `oob_score` to True\n",
    "* After training the model, we can access the oob score using the attribute `.oob_score_`\n",
    "* It's good to compare oob score to actual metric (for example, R2 or accuracy)\n",
    "    * The two values being close is a good indicator of the model's ability to generalize to new data\n",
    "    \n",
    "```\n",
    "# Instantiate the base model\n",
    "clf_dt = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Build and train the Bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  base_estimator=clf_dt,\n",
    "  n_estimators=21,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "pred = clf_bag.predict(X_test)\n",
    "\n",
    "# Show the F1-score\n",
    "print('F1-Score: {:.3f}'.format(f1_score(y_test, pred)))\n",
    "```\n",
    "\n",
    "```\n",
    "# Build and train the bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  base_estimator=clf_dt,\n",
    "  n_estimators=21,\n",
    "  oob_score=True,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Print the out-of-bag score\n",
    "print('OOB-Score: {:.3f}'.format(clf_bag.oob_score_))\n",
    "\n",
    "# Evaluate the performance on the test set to compare\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, pred)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3505c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cdaf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fe60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f8f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
