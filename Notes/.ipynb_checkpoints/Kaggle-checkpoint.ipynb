{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191a7a61",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500df5bb",
   "metadata": {},
   "source": [
    "#### Understanding the problem\n",
    "* **Data type:** tabular data, time series, images, text, etc. structured vs. unstructured... a mix\n",
    "* **Problem type:** classification, regression, ranking, etc.\n",
    "* **Evaluation metric:** ROC AUC, F1-score, MAE, MSE, etc.\n",
    "\n",
    "#### Metric definition\n",
    "* Generally, the majority of the metrics can be found in the `sklearn.metrics` library\n",
    "* However, **there are some special competition metrics that are not available in scikit-learn**\n",
    "    * In such cases, we have to create metrics manually\n",
    "    \n",
    "### Kaggle Solution Workflow\n",
    "\n",
    "<img src='data/solution_workflow.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    diffs = np.log(y_true + 1) - np.log(y_pred + 1)\n",
    "    squares = np.power(diffs, 2)\n",
    "    err = np.sqrt(np.mean(squares))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5759f1",
   "metadata": {},
   "source": [
    "* Before building any models, we should perform some preliminary steps to understand the data and the problem we're facing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76543b27",
   "metadata": {},
   "source": [
    "#### Goals of EDA\n",
    "* Size of the data\n",
    "* Properties of the target variable\n",
    "    * high class imblance in classification problem?\n",
    "    * skewed distribution in regression problem?\n",
    "* Properties of the features\n",
    "* Generate ideas for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9be3f",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fe79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle= True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2f035",
   "metadata": {},
   "source": [
    "* Now we need to train `K` models for each cross-validation split. \n",
    "* To obtain all the splits we call the `split()` method of the KFold object with the `train` data as an argument.\n",
    "* It returns a list of training and testing observations for each split\n",
    "* The observations are given as numeric indices on the train data.\n",
    "* These indices could be used inside the loop to select training and testing folds for the corresponding cross-validation split\n",
    "* For pandas DataFrame, it could be done using the `iloc` operator, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141168ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each cross-validation split\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Get training and testing data for the corresponding split\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5dcfe8",
   "metadata": {},
   "source": [
    "#### Stratified K-fold\n",
    "* As demonstrated in the image, each fold has the same class distribution as the initial dataset.\n",
    "* It is useful when we have a classification problem with high class imbalance in the target variable or our data size is very small.\n",
    "\n",
    "<img src='data/stratified_kfold.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "str_kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=123)\n",
    "\n",
    "# Loop through each cross-validation split\n",
    "for train_index, test_index in str_kf.split(train, train['target']):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d3015",
   "metadata": {},
   "source": [
    "```\n",
    "# Import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "# Loop through each split\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Obtain training and testing folds\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    print('Fold: {}'.format(fold))\n",
    "    print('CV train shape: {}'.format(cv_train.shape))\n",
    "    print('Medium interest listings in CV train: {}\\n'.format(sum(cv_train.interest_level == 'medium')))\n",
    "    fold += 1\n",
    "    \n",
    "# Import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "str_kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n",
    "\n",
    "# Loop through each split\n",
    "fold = 0\n",
    "for train_index, test_index in str_kf.split(train, train['interest_level']):\n",
    "    # Obtain training and testing folds\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    print('Fold: {}'.format(fold))\n",
    "    print('CV train shape: {}'.format(cv_train.shape))\n",
    "    print('Medium interest listings in CV train: {}\\n'.format(sum(cv_train.interest_level == 'medium')))\n",
    "    fold += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a5b62",
   "metadata": {},
   "source": [
    "#### Validation usage\n",
    "* **Leakage** causes a model to seem accurate until we start making predictions in a real-world environment\n",
    "* **Types of data leakage:**\n",
    "    * Leak in **features:** using data that will not be available in the real (production) setting\n",
    "        * Example: predicting sales in US dollars, while having exactly the same sales in UK pounds as a feature.\n",
    "    * Leak in **validation strategy:** validation strategy differs from the real-world situation\n",
    "        * Using kfold for time series data\n",
    "        * Instead, time series kfold should be done as demonstrated in the image below:\n",
    "        \n",
    "<img src='data/time_series_kfold.png' width=\"600\" height=\"300\" align=\"center\"/>        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366b0a8",
   "metadata": {},
   "source": [
    "* The underlying idea of time series k-fold crossvalidation is to provide multiple splits in such a manner that we train only on past data while always predicting the future\n",
    "* **Time k-fold crossvalidation** is also available in `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada06ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create a TimeSeriesSplit object\n",
    "time_kfold = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5ba7a",
   "metadata": {},
   "source": [
    "* **Note** that **before applying it to the data, we need to sort the train DataFrame by date.**\n",
    "    * Then, as usual, iterate through each crossvalidation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort train by date\n",
    "train = train.sort_values('date')\n",
    "\n",
    "# Loop through each cross-validation split\n",
    "for train_index, test_index in time_kfold.split(train):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c3001",
   "metadata": {},
   "source": [
    "### Validation pipeline\n",
    "* Firstly, create an empty list where we will store the model's results\n",
    "* Split train data into folds \n",
    "* For each crossvalidation split, we perform the following steps:\n",
    "    * Train a model using all except for a single fold\n",
    "    * Make predictions on this single unseen fold\n",
    "    * Calculate the competition metric and append it to the list of folds metrics\n",
    "* As a result, we have a list of K numbers representing model quality for each fold \n",
    "\n",
    "```\n",
    "# List for the results\n",
    "fold_metrics = []\n",
    "for train_index, test_index in CV_STRATEGY.split(train):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    # Train a model\n",
    "    model.fit(cv_train)\n",
    "    # Make predictions\n",
    "    predictions = model.predict(cv_test)\n",
    "    # Calculate the metric\n",
    "    metric = evaluate(cv_test, predictions)\n",
    "    fold_metrics.append(metric)\n",
    "```\n",
    "* Now, we could train two different models and for each model get a list of K numbers\n",
    "\n",
    "<img src='data/mod_comp.png' width=\"300\" height=\"150\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a57c3",
   "metadata": {},
   "source": [
    "* For example, above we have models A and B, each with mean squared errors in four folds\n",
    "* Our goal is to select the model with better quality \n",
    "* The next step is to tranform K fold scores into a single overall validation score\n",
    "* The simplest way to obtain a single number is to find the mean over all fold scores\n",
    "    * However, the mean is not always a good choice, as it does *not* take into account **score deviation** from one fold to another\n",
    "    * For example, we could get a very good score for a single fold, while the performance on the rest K-1 folds is poor. \n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "# Simple mean over the folds\n",
    "mean_score = np.mean(fold_metrics)\n",
    "```\n",
    "* **A more reliable overall validation score:** uses the worst-case scenario considering validation score one standard deviation away from the mean\n",
    "* **Note** that we **add** standard deviation if the competition metric is being *minimized* and **subtract** standard deviation if the metric is being *maximized*.\n",
    "\n",
    "```\n",
    "# Overall validation score\n",
    "overall_score_minimizing = np.mean(fold_metrics) + np.std(fold_metrics)\n",
    "\n",
    "# Or\n",
    "overall_score_maximizing = np.mean(fold_metrics) - np.std(fold_metrics)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d5caa",
   "metadata": {},
   "source": [
    "#### Exercises: Time K-Fold\n",
    "\n",
    "```\n",
    "# Create TimeSeriesSplit object\n",
    "time_kfold = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Sort train data by date\n",
    "train = train.sort_values(by='date')\n",
    "\n",
    "# Iterate through each split\n",
    "fold = 0\n",
    "for train_index, test_index in time_kfold.split(train):\n",
    "    cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "    \n",
    "    print('Fold :', fold)\n",
    "    print('Train date range: from {} to {}'.format(cv_train.date.min(), cv_train.date.max()))\n",
    "    print('Test date range: from {} to {}\\n'.format(cv_test.date.min(), cv_test.date.max()))\n",
    "    fold += 1\n",
    "```\n",
    "\n",
    "#### Exercises: Overall Validation Score\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "# Sort train data by date\n",
    "train = train.sort_values('date')\n",
    "\n",
    "# Initialize 3-fold time cross-validation\n",
    "kf = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Get MSE scores for each cross-validation split\n",
    "mse_scores = get_fold_mse(train, kf)\n",
    "\n",
    "print('Mean validation MSE: {:.5f}'.format(np.mean(mse_scores)))\n",
    "print('MSE by fold: {}'.format(mse_scores))\n",
    "print('Overall validation MSE: {:.5f}'.format(np.mean(mse_scores) + np.std(mse_scores)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf8c4f",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 3: Feature Engineering\n",
    "You will now get exposure to different types of features. You will modify existing features and create new ones. Also, you will treat the missing data accordingly.\n",
    "\n",
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a15958",
   "metadata": {},
   "source": [
    "<img src='data/mod_process.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae556ae2",
   "metadata": {},
   "source": [
    "* **Important rule:** tweak only a single a thing at a time, because changing multiple things does not allow us to detect what actually works and what doesn't\n",
    "* **Feature engineering** helps our ML models to get additional information and consequently to better predict the target variable\n",
    "* The ideas for new features can come from prior experience working with similar data.\n",
    "* Also, having looked at the data, we could potentially generate ideas for new valuable features\n",
    "* One more source is domain knowledge of the problem we're solving\n",
    "\n",
    "#### Feature types\n",
    "* Numerical\n",
    "* Categorical\n",
    "* Datetime\n",
    "* Coordinates\n",
    "* Text\n",
    "* Images\n",
    "\n",
    "#### Creating features \n",
    "* There are some situations when we need to generate features for train and tests independently and for each validation split in the k-fold cross-validation\n",
    "* However, in the majority of cases features are created for train and test sets simultaneously\n",
    "    * For this purpose, we concatenate train and test DataFrames from Kaggle into a single DF using pandas\n",
    "    \n",
    "```\n",
    "# Concatenate the train and test data\n",
    "data = pd.concat([train, test])\n",
    "\n",
    "# Generate new features for the full DataFrame\n",
    "\n",
    "# Get the original train and test split back\n",
    "train = data[data.id.isin(train.id)]\n",
    "test = data[data.is.isin(test.id)]\n",
    "```\n",
    "\n",
    "#### Arithmetical features\n",
    "\n",
    "```\n",
    "# Arithmetical features\n",
    "two_sigma['price_per_bedroom'] = two_sigma.price / two_sigma.bedrooms\n",
    "two_sigma['rooms_number'] = two_sigma.bedrooms + two_sigma.bathrooms\n",
    "```\n",
    "\n",
    "#### Datetime features \n",
    "\n",
    "```\n",
    "# Convert date to the datetime object\n",
    "dem['date'] = pd.to_datetime(dem['date'])\n",
    "\n",
    "# Year features\n",
    "dem['year'] = dem['date'].dt.year\n",
    "\n",
    "# Month features\n",
    "dem['month'] = dem['date'].dt.month\n",
    "\n",
    "# Week features\n",
    "dem['week'] = dem['date'].dt.weekofyear\n",
    "\n",
    "# Day features\n",
    "dem['dayofyear'] = dem['date'].dt.dayofyear\n",
    "dem['dayofmonth'] = dem['date'].dt.day\n",
    "dem['dayofweek'] = dem['date'].dt.dayofweek\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2071880",
   "metadata": {},
   "source": [
    "#### Exercises: Arithmetical features\n",
    "\n",
    "```\n",
    "# Look at the initial RMSE\n",
    "print('RMSE before feature engineering:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the total area of the house\n",
    "train['TotalArea'] = train['TotalBsmtSF'] + train['FirstFlrSF'] + train['SecondFlrSF']\n",
    "\n",
    "# Look at the updated RMSE\n",
    "print('RMSE with total area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the area of the garden\n",
    "train['GardenArea'] = train['LotArea'] - train['FirstFlrSF']\n",
    "print('RMSE with garden area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find total number of bathrooms\n",
    "train['TotalBath'] = train.FullBath + train.HalfBath\n",
    "print('RMSE with number of bathrooms:', get_kfold_rmse(train))\n",
    "\n",
    "# Concatenate train and test together\n",
    "taxi = pd.concat([train, test])\n",
    "\n",
    "# Convert pickup date to datetime object\n",
    "taxi['pickup_datetime'] = pd.to_datetime(taxi['pickup_datetime'])\n",
    "\n",
    "# Create a day of week feature\n",
    "taxi['dayofweek'] = taxi['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# Create an hour feature\n",
    "taxi['hour'] = taxi['pickup_datetime'].dt.hour\n",
    "\n",
    "# Split back into train and test\n",
    "new_train = taxi[taxi['id'].isin(train['id'])]\n",
    "new_test = taxi[taxi['id'].isin(test['id'])]\n",
    "```\n",
    "\n",
    "### Categorical features\n",
    "* The majority of ML models do not handle string values and categorical features automatically\n",
    "\n",
    "#### Label Encoding\n",
    "\n",
    "```\n",
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode a categorical feature\n",
    "df['cat_encoded'] = le.fit_transform(df['cat'])\n",
    "```\n",
    "* The problem with Label Encoding is that we implicitly assume that there is a ranking dependency between the categories\n",
    "* Such an approach can be harmful to linear models, although it still works for tree-based models.\n",
    "\n",
    "#### One-Hot encoding\n",
    "\n",
    "```\n",
    "# Create One-Hot encoded features\n",
    "ohe = pd.get_dummies(df['cat'], prefix='ohe_cat')\n",
    "\n",
    "# Drop the initial feature\n",
    "df.drop('cat', axis = 1, inplace = True)\n",
    "\n",
    "# Concatenate OHE features to the dataframe\n",
    "df = pd.concat([df, ohe], axis =1)\n",
    "```\n",
    "\n",
    "#### Binary Feature\n",
    "* One special case of categorical features is binary features \n",
    "    * For example: Yes/No, On/Off\n",
    "* For such features, we **always apply label encoding**\n",
    "\n",
    "```\n",
    "le = LabelEncoder()\n",
    "binary_feature['binary_encoded'] = le.fit_transform(binary_feature['binary_feat'])\n",
    "```\n",
    "\n",
    "### Other encoding approaches\n",
    "* Backward Difference Coding\n",
    "* BaseN\n",
    "* Binary\n",
    "* CatBoost Encoder\n",
    "* Hashing\n",
    "* Helmert Coding\n",
    "* James-Stein Encoder\n",
    "* M-estimate\n",
    "* One Hot\n",
    "* Ordinal\n",
    "* Polynomial Coding\n",
    "* Sum Coding\n",
    "* Target Encoder $\\Leftarrow$ **most widely used at Kaggle**\n",
    "* Weight of Evidence\n",
    "\n",
    "#### Exercises: Label Encoding\n",
    "\n",
    "```\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Create new features\n",
    "houses['RoofStyle_enc'] = le.fit_transform(houses['RoofStyle'])\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Look at new features\n",
    "print(houses[['RoofStyle', 'RoofStyle_enc', 'CentralAir', 'CentralAir_enc']].head())\n",
    "```\n",
    "#### Exercises: One-Hot Encoding\n",
    "\n",
    "```\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Look at feature distributions\n",
    "print(houses['RoofStyle'].value_counts(), '\\n')\n",
    "print(houses['CentralAir'].value_counts())\n",
    "\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encode binary 'CentralAir' feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encode binary 'CentralAir' feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Create One-Hot encoded features\n",
    "ohe = pd.get_dummies(houses['RoofStyle'], prefix='RoofStyle')\n",
    "\n",
    "# Concatenate OHE features to houses\n",
    "houses = pd.concat([houses, ohe], axis=1)\n",
    "\n",
    "# Look at OHE features\n",
    "print(houses[[col for col in houses.columns if 'RoofStyle' in col]].head(3))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fabf39",
   "metadata": {},
   "source": [
    "### Target Encoding\n",
    "\n",
    "#### High cardinality categorical features \n",
    "* These are categorical features that have a large number of category values (at least 10+ different category values).\n",
    "    * Example: zipcode\n",
    "* **Target encoding:**\n",
    "    * As a label encoder, it creates only a single column, but it also introduces the correlation between the categories and the target variable\n",
    "    * There are various options for the encoding function\n",
    "    \n",
    "#### Mean target encoding\n",
    "* To apply mean target encoding, we need to follow the following steps:\n",
    "    * Calculate mean on the train, apply to the test\n",
    "    * Split train into K folds. Calculate mean on (K-1) folds, apply to the K-th fold\n",
    "    * Add mean target encoded feature to the model \n",
    "    \n",
    "<img src='data/mte1.png' width=\"300\" height=\"150\" align=\"center\"/>    \n",
    "    \n",
    "* **In this case, for Category A, the mean target code is 0.66**\n",
    "    * 2/3 As are value 1; 1/3 As are value 0\n",
    "* **Category B's mean target code is 0.25**\n",
    "    * 1/4 Bs are value 1; 3/4 Bs are value 0\n",
    "* **Next:** Apply mean target codes to test data; as a result, we've obtained a new feature\n",
    "  \n",
    "<img src='data/mean_target_encoding.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "#### Train encoding using out-of-fold\n",
    "* Now we need to calculate this mean target encoded feature for the train data\n",
    "* We will be using out-of-fold statistics\n",
    "* **First** we'll split the data into 2 folds:\n",
    "\n",
    "<img src='data/mte2.png' width=\"300\" height=\"150\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ed6bd",
   "metadata": {},
   "source": [
    "* Take fold number 1:\n",
    "    * We take the target mean out of this fold, so using only fold # 2 observations\n",
    "    \n",
    "<img src='data/mte4.png' width=\"300\" height=\"150\" align=\"center\"/>\n",
    "\n",
    "* Now we calculate out-of-fold target means for the second fold using only the first fold observtions:\n",
    "\n",
    "<img src='data/mte5.png' width=\"300\" height=\"150\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c389ace",
   "metadata": {},
   "source": [
    "#### Practical guides\n",
    "* Some tips that are always applied together with mean target encoding:\n",
    "    * **Smoothing**\n",
    "    * **New categories**\n",
    "    \n",
    "#### Exercises: Mean Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edf03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Calculate global mean on the train data\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # Group by the categorical feature and calculate its properties\n",
    "    train_groups = train.groupby(categorical)\n",
    "    category_sum = train_groups[target].sum()\n",
    "    category_size = train_groups.size()\n",
    "    \n",
    "    # Calculate smoothed mean target statistics\n",
    "    train_statistics = (category_sum + global_mean * alpha) / (category_size + alpha)\n",
    "    \n",
    "    # Apply statistics to the test data and fill new categories\n",
    "    test_feature = test[categorical].map(train_statistics).fillna(global_mean)\n",
    "    return test_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980bb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mean_target_encoding(train, target, categorical, alpha=5):\n",
    "    # Create 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "    train_feature = pd.Series(index=train.index)\n",
    "    \n",
    "    # For each folds split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "      \n",
    "        # Calculate out-of-fold statistics and apply to cv_test\n",
    "        cv_test_feature = test_mean_target_encoding(cv_train, cv_test, target, categorical, alpha)\n",
    "        \n",
    "        # Save new feature for this particular fold\n",
    "        train_feature.iloc[test_index] = cv_test_feature       \n",
    "    return train_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda9faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "  \n",
    "    # Get the train feature\n",
    "    train_feature = train_mean_target_encoding(train, target, categorical, alpha)\n",
    "  \n",
    "    # Get the test feature\n",
    "    test_feature = test_mean_target_encoding(train, test, target, categorical, alpha)\n",
    "    \n",
    "    # Return new features to add to the model\n",
    "    return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e04eff",
   "metadata": {},
   "source": [
    "#### Exercises: K-fold cross-validation\n",
    "\n",
    "```\n",
    "# Create 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# For each folds split\n",
    "for train_index, test_index in kf.split(bryant_shots):\n",
    "    cv_train, cv_test = bryant_shots.iloc[train_index], bryant_shots.iloc[test_index]\n",
    "\n",
    "    # Create mean target encoded feature\n",
    "    cv_train['game_id_enc'], cv_test['game_id_enc'] = mean_target_encoding(train=cv_train,\n",
    "                                                                           test=cv_test,\n",
    "                                                                           target='shot_made_flag',\n",
    "                                                                           categorical='game_id',\n",
    "                                                                           alpha=5)\n",
    "    # Look at the encoding\n",
    "    print(cv_train[['game_id', 'shot_made_flag', 'game_id_enc']].sample(n=1))\n",
    "    \n",
    "# Create mean target encoded feature\n",
    "train['RoofStyle_enc'], test['RoofStyle_enc'] = mean_target_encoding(train=train,\n",
    "                                                                     test=test,\n",
    "                                                                     target='SalePrice',\n",
    "                                                                     categorical='RoofStyle',\n",
    "                                                                     alpha=10)\n",
    "\n",
    "# Look at the encoding\n",
    "print(test[['RoofStyle', 'RoofStyle_enc']].drop_duplicates())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e843d8",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "* Some machine learning algorithms like XGBoost or LightGBM can treat missing data without any preprocessing \n",
    "* However, it is always a good idea to implement your own missing value imputation in order to improve the model. \n",
    "\n",
    "<img src='data/misdata1.png' width=\"300\" height=\"150\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657dd64",
   "metadata": {},
   "source": [
    "#### Numerical data\n",
    "* Mean/median imputation\n",
    "* Constant value imputation\n",
    "    * **To emphasize that a value was missing, sometimes a special constant value is used.**\n",
    "    * Not a good choice for linear models, but works perfectly for tree-based models\n",
    "    \n",
    "#### Categorical data\n",
    "* Most frequent category imputation\n",
    "* New category imputation\n",
    "    * Create a new category for the missing values \n",
    "    \n",
    "#### Find missing data\n",
    "* `df.isnull()`\n",
    "    * returns the dataframe with boleans as cell values \n",
    "    * If missing, `True`\n",
    "* `df.isnull().sum()`\n",
    "\n",
    "\n",
    "#### Numerical missing data\n",
    "\n",
    "```\n",
    "# Import SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Different types of imputers\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value=-999)\n",
    "\n",
    "# Imputation\n",
    "df[['num']] = mean_imputer.fit_transform(df['num']])\n",
    "```\n",
    "* **Note that even if we want to impute a single column, we have to use double brackets** (though you can also pass a list of columns).\n",
    "\n",
    "#### Categorical missing data\n",
    "\n",
    "```\n",
    "# Import SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Different types of imputers\n",
    "frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value='MISS')\n",
    "\n",
    "# Imputation \n",
    "df[['cat']] = constant_imputer.fit_transform(df[['cat']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7bb87e",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 4: Modeling\n",
    "Time to bring everything together and build some models! In this last chapter, you will build a base model before tuning some hyperparameters and improving your results with ensembles. You will then get some final tips and tricks to help you compete more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6002f89",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "\n",
    "<img src='data/baseline_model.png' width=\"500\" height=\"250\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a3bbc",
   "metadata": {},
   "source": [
    "* To start this loop, we should establish the baseline model.\n",
    "* It's usually a very simple model that allows us to check the whole pipeline we've written, review the local validation process, and generate the first submissions for the test data\n",
    "\n",
    "### Baseline model I: mean\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "#Assign the mean fare amount to all the test observations\n",
    "taxi_test['fare_amount'] = np.mean(taxi_train.fare_amount)\n",
    "\n",
    "# Write the predictions to the file\n",
    "taxi_test[['id', 'fare_amount']].to_csv('mean_sub.csv', index=False)\n",
    "```\n",
    "\n",
    "### Baseline model II: mean grouped by the number of passengers\n",
    "\n",
    "```\n",
    "# Calculate the mean fare amount by group\n",
    "naive_prediction_groups = taxi_train.groupby('passenger_count').fare_amount.mean()\n",
    "\n",
    "# Make predictions on the test set\n",
    "taxi_test['fare_amount'] = taxi_test.passenger_count.map(naive_prediction_groups)\n",
    "\n",
    "# Write predictions to the file\n",
    "taxi_test[['id', 'fare_amount']].to_csv('mean_group_sub.csv', index=False)\n",
    "```\n",
    "* The idea is the same: assign the average value of fare amount to the whole group\n",
    "\n",
    "### Baseline III: out-of-the-box Gradient Boosting model on all numeric features\n",
    "\n",
    "```\n",
    "# Select only numeric features\n",
    "features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(taxi_train[features], taxi_train.fare_amount)\n",
    "\n",
    "# Make predictions on the test data\n",
    "taxi_test['fare_amount'] = gb.predict(taxi_test[features])\n",
    "\n",
    "# Write predictions to the file\n",
    "taxi_test[['id', 'fare_amount']].to_csv('gb_sub.csv', index=False)\n",
    "```\n",
    "\n",
    "### Correlation with Public Leaderboard\n",
    "* Generally, the ideal situation is to observe such correlation between local validation and Public Leaderboard scores.\n",
    "* The values should not be absolutely the same, but if the local score is improving, then we want to see improvements on the Leaderboard.\n",
    "    * If not, it is a sign that something could either be wrong with our models or validation scheme.\n",
    " \n",
    "```\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Calculate the mean fare_amount on the validation_train data\n",
    "naive_prediction = np.mean(validation_train['fare_amount'])\n",
    "\n",
    "# Assign naive prediction to all the holdout observations\n",
    "validation_test['pred'] = naive_prediction\n",
    "\n",
    "# Measure the local RMSE\n",
    "rmse = sqrt(mean_squared_error(validation_test['fare_amount'], validation_test['pred']))\n",
    "print('Validation RMSE for Baseline I model: {:.3f}'.format(rmse))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8edc3a1",
   "metadata": {},
   "source": [
    "```\n",
    "# Get pickup hour from the pickup_datetime column\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "\n",
    "# Calculate average fare_amount grouped by pickup hour \n",
    "hour_groups = train.groupby('hour')['fare_amount'].mean()\n",
    "\n",
    "# Make predictions on the test set\n",
    "test['fare_amount'] = test.hour.map(hour_groups)\n",
    "\n",
    "# Write predictions\n",
    "test[['id','fare_amount']].to_csv('hour_mean_sub.csv', index=False)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Select only numeric features\n",
    "features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "            'dropoff_latitude', 'passenger_count', \"hour\"]\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(train[features], train.fare_amount)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['fare_amount'] = rf.predict(test[features])\n",
    "\n",
    "# Write predictions\n",
    "test[['id','fare_amount']].to_csv('rf_sub.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd0c81",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "* Generally we make Kaggle Leaderboard submissions only after a couple of changes, just to track that our local validation score moves in the same direction as the Public Leaderboard score (usually limt of 5 submissions per day).\n",
    "\n",
    "<img src='data/ml_v_dl.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f8d41",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "\n",
    "```\n",
    "# Possible alpha values\n",
    "alpha_grid = [0.01, 0.1, 1, 10]\n",
    "from sklearn.linear_model import Ridge\n",
    "result ={}\n",
    "\n",
    "# For value in the grid \n",
    "for candidate_alpha in alpha_grid:\n",
    "    # Create a model with a specific alpha value\n",
    "    ridge_regression = Ridge(alpha=candidate_alpha)\n",
    "    # Find the validation score for this model\n",
    "    # Save the results for each alpha value\n",
    "    results[candidate_alpha] = validation_score\n",
    "```\n",
    "\n",
    "```\n",
    "# Possible max depth values\n",
    "max_depth_grid = [3, 6, 9, 12, 15]\n",
    "results = {}\n",
    "\n",
    "# For each value in the grid\n",
    "for max_depth_candidate in max_depth_grid:\n",
    "    # Specify parameters for the model\n",
    "    params = {'max_depth': max_depth_candidate}\n",
    "\n",
    "    # Calculate validation score for a particular hyperparameter\n",
    "    validation_score = get_cv_score(train, params)\n",
    "\n",
    "    # Save the results for each max depth value\n",
    "    results[max_depth_candidate] = validation_score   \n",
    "print(results)\n",
    "```\n",
    "\n",
    "```\n",
    "import itertools\n",
    "\n",
    "# Hyperparameter grids\n",
    "max_depth_grid = [3, 5, 7]\n",
    "subsample_grid = [0.8, 0.9, 1.0]\n",
    "results = {}\n",
    "\n",
    "# For each couple in the grid\n",
    "for max_depth_candidate, subsample_candidate in itertools.product(max_depth_grid, subsample_grid):\n",
    "    params = {'max_depth': max_depth_candidate,\n",
    "              'subsample': subsample_candidate}\n",
    "    validation_score = get_cv_score(train, params)\n",
    "    # Save the results for each couple\n",
    "    results[(max_depth_candidate, subsample_candidate)] = validation_score   \n",
    "print(results)\n",
    "```\n",
    "\n",
    "### Model Ensembling\n",
    "\n",
    "<img src='data/model_ensembling.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### Model blending\n",
    "* The idea of ensemble learning is to build a prediction model by combining the strength of a collection of simpler base models\n",
    "* The so-called blending approach is to just find an average of our multiple models' predictions\n",
    "\n",
    "#### Arithmetic mean\n",
    "* **Arithmetic mean** works for both regression and classification problems.\n",
    "    * However, for classification, it is better to use the geometric mean of the class probabilities predicted\n",
    "\n",
    "<img src='data/argeo_means.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "#### Geometric mean\n",
    "* For classification, it's better to use a geometric mean of the class probabilities predicted\n",
    "\n",
    "### Model stacking\n",
    "* Stacking is a more advanced ensembling approach\n",
    "* The idea is to take multiple single models, take their predictions and use these predictions as features in the 2nd level model.\n",
    "    * 1) Split train data into two parts: Part 1 & Part 2\n",
    "    * 2) Train multiple single models on the first part (Part 1)\n",
    "    * 3) Make predictions on Part 2\n",
    "    * 4) Make predictions on the test data\n",
    "        * (Now we have model predictions for both Part 2 of the train data and for the test data)\n",
    "    * 5) Train a new model on Part 2 using the predictions as features\n",
    "        * This model is called the **2nd level model** or **meta-model**\n",
    "    * 6) Make prediction on the test data using the 2nd level model \n",
    "\n",
    "#### Exercises: Model blending\n",
    "\n",
    "```\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb = GradientBoostingRegressor().fit(train[features], train.fare_amount)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor().fit(train[features], train.fare_amount)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['gb_pred'] = gb.predict(test[features])\n",
    "test['rf_pred'] = rf.predict(test[features])\n",
    "\n",
    "# Find mean of model predictions\n",
    "test['blend'] = (test['gb_pred'] + test['rf_pred']) / 2\n",
    "print(test[['gb_pred', 'rf_pred', 'blend']].head(3))\n",
    "```\n",
    "\n",
    "#### Exercises: Model Stacking I\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Split train data into two parts\n",
    "part_1, part_2 = train_test_split(train, test_size=0.5, random_state=123)\n",
    "\n",
    "# Train a Gradient Boosting model on Part 1\n",
    "gb = GradientBoostingRegressor().fit(part_1[features], part_1.fare_amount)\n",
    "\n",
    "# Train a Random Forest model on Part 1\n",
    "rf = RandomForestRegressor().fit(part_1[features], part_1.fare_amount)\n",
    "\n",
    "# Make predictions on the Part 2 data\n",
    "part_2['gb_pred'] = gb.predict(part_2[features])\n",
    "part_2['rf_pred'] = rf.predict(part_2[features])\n",
    "\n",
    "# Make predictions on the test data\n",
    "test['gb_pred'] = gb.predict(test[features])\n",
    "test['rf_pred'] = rf.predict(test[features])\n",
    "```\n",
    "\n",
    "#### Exercises: Model Stacking II\n",
    "\n",
    "```\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression model without the intercept\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# Train 2nd level model on the Part 2 data\n",
    "lr.fit(part_2[['gb_pred', 'rf_pred']], part_2.fare_amount)\n",
    "\n",
    "# Make stacking predictions on the test data\n",
    "test['stacking'] = lr.predict(test[['gb_pred', 'rf_pred']])\n",
    "\n",
    "# Look at the model coefficients\n",
    "print(lr.coef_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23035c23",
   "metadata": {},
   "source": [
    "### Final Tips\n",
    "#### Save all the information\n",
    "* **Save folds distributions to files**\n",
    "* **Save model runs**\n",
    "* **Save model predictions to the disk**\n",
    "* **Save performance results**\n",
    "\n",
    "#### Kaggle forum and kernels\n",
    "* **Kaggle forum:**\n",
    "    * Competition discussed by the participants\n",
    "    * Open forum\n",
    "* **Kaggle kernels:**\n",
    "    * Scripts and notebooks shared by the participants\n",
    "    * Cloud computational environment\n",
    "    \n",
    "\n",
    "* So, we have an opportunity not only to discuss the competition, but also to look at the code. \n",
    "\n",
    "<img src='data/kaggle_forums_kernels.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec57d98",
   "metadata": {},
   "source": [
    "#### Final submissions (usually 2)\n",
    "* 1) Best submission on the local validation\n",
    "* 2) Best submission on the Public Leaderboard\n",
    "\n",
    "```\n",
    "# Drop passenger_count column\n",
    "new_train_1 = train.drop('passenger_count', axis=1)\n",
    "\n",
    "# Compare validation scores\n",
    "initial_score = get_cv_score(train)\n",
    "new_score = get_cv_score(new_train_1)\n",
    "\n",
    "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))\n",
    "\n",
    "# Create copy of the initial train DataFrame\n",
    "new_train_2 = train.copy()\n",
    "\n",
    "# Find sum of pickup latitude and ride distance\n",
    "new_train_2['weird_feature'] = new_train_2['pickup_latitude'] + new_train_2['distance_km']\n",
    "\n",
    "# Compare validation scores\n",
    "initial_score = get_cv_score(train)\n",
    "new_score = get_cv_score(new_train_2)\n",
    "\n",
    "print('Initial score is {} and the new score is {}'.format(initial_score, new_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
