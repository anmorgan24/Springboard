{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf72fe9",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95553f51",
   "metadata": {},
   "source": [
    "## k-means clustering\n",
    "* Finds clusters of samples\n",
    "* Number of clusters must be specified\n",
    "* Implemented in`sklearn` \n",
    "* `from sklearn.cluster import KMeans`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8afbe",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)\n",
    "```\n",
    "* This fits the model to the data by locating and remembering the regions where the different clusters occur\n",
    "* Then we can use the predict method of the model\n",
    "* This returns a cluster label for each sample indicating to which cluster a sample belongs. \n",
    "\n",
    "```\n",
    "labels = model.predict(samples)\n",
    "print(labels)\n",
    "```\n",
    "\n",
    "* New samples can be assigned to existing clusters.\n",
    "* k-means does this by remembering the mean of the samples in each cluster: called the __centroids.__\n",
    "* k-means then finds the nearest centroid to each new sample. \n",
    "***\n",
    "* Say you have a array of new samples \n",
    "* To assign the new samples to the existing cluster, pass the array of new samples to the predict method of the k-means model\n",
    "\n",
    "```\n",
    "new_labels = model.predict(new_samples)\n",
    "print(new_labels)\n",
    "```\n",
    "\n",
    "### Scatter plots\n",
    "\n",
    "```\n",
    "import mattplotlib.pyplot as plt\n",
    "xs = samples[:,0]\n",
    "ys = samples[:,2]\n",
    "plt.scatter(xs, ys, c=labels)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f8162",
   "metadata": {},
   "source": [
    "1) Visualize data in a scatter plot to visually determine the optimal value of k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2f00d",
   "metadata": {},
   "source": [
    "```\n",
    "#Import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "#Create a KMeans instance with 3 clusters: model\n",
    "model = KMeans(n_clusters=3)\n",
    "#Fit model to points\n",
    "model.fit(points)\n",
    "#Determine the cluster labels of new_points: labels\n",
    "labels = model.predict(new_points)\n",
    "#Print cluster labels of new_points\n",
    "print(labels)\n",
    "```\n",
    "\n",
    "* __`.cluster_centers_`__ : Computes the coordinates of the centroids\n",
    "* parameter __`s`__ refers to marker size\n",
    "\n",
    "```\n",
    "#Import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "#Assign the columns of new_points: xs and ys\n",
    "xs = new_points[:,0]\n",
    "ys = new_points[:,1]\n",
    "#Make a scatter plot of xs and ys, using labels to define the colors\n",
    "plt.scatter(xs, ys, c=labels, alpha= 0.5)\n",
    "#Assign the cluster centers: centroids\n",
    "centroids = model.cluster_centers_\n",
    "#Assign the columns of centroids: centroids_x, centroids_y\n",
    "centroids_x = centroids[:,0]\n",
    "centroids_y = centroids[:,1]\n",
    "#Make a scatter plot of centroids_x and centroids_y\n",
    "plt.scatter(centroids_x, centroids_y, marker='D', s=50)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ddb91d",
   "metadata": {},
   "source": [
    "## Evaluating a clustering\n",
    "* How to evaluate quality of the clustering?\n",
    "    * One approach: check correspondence with e.g. iris species.\n",
    "    * But what if there are no species to check against?\n",
    "* Measure quality of a clustering without requiring pre-determined labels.\n",
    "* A measure of quality then informs choice of how many clusters to look for\n",
    "* \"clusters\" vs \"species\" or \"clusters\" vs. \"labels\" is an example of __cross-tabulation__\n",
    "\n",
    "### Cross-tabulation with pandas\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'labels': labels, 'species': species})\n",
    "```\n",
    "* Create df from data lists where the first column is the cluster labels and the second column is the iris species so that each row gives a cluster label and species of a single sample\n",
    "\n",
    "```\n",
    "ct = pd.crosstab(df['labels'], df['species'])\n",
    "print(ct)\n",
    "```\n",
    "\n",
    "* How to evaluate a clustering if there is no label information?\n",
    "* We need a way to measure cluster quality using only samples and their _cluster_ labels.\n",
    "* A good clustering has tight clusters\n",
    "* Samples in each cluster bunched together\n",
    "* __Inertia:__ measures clustering quality by measuring how spread out the clusters are (_lower_ is better).\n",
    "* Distance from each sample to centroid of its cluster\n",
    "* The inertia of the KMeans model is measured automatically when any of the fit methods are called and is available afterwards in attribute __`.inertia_`__\n",
    "* KMeans aims to place the clusters in a way that minimizes the inertia.\n",
    "* More clusters will always mean more inertia. _However_:\n",
    "    * A good clustering has tight clusters (so low inertia)...\n",
    "    * ...but it also doesn't have too many clusters!\n",
    "    * A good rule of thumb is to choose the __'elbow'__ in the inertia plot. \n",
    "    * That is, a point where the inertia begins to decrease more slowly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2c5a6",
   "metadata": {},
   "source": [
    "```\n",
    "ks = range(1, 6)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    #Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "    #Fit model to samples\n",
    "    model.fit(samples)    \n",
    "    #Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)    \n",
    "#Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b474d8",
   "metadata": {},
   "source": [
    "```\n",
    "#Create a KMeans model with 3 clusters: model\n",
    "model = KMeans(n_clusters=3)\n",
    "#Use fit_predict to fit model and obtain cluster labels: labels\n",
    "labels = model.fit_predict(samples)\n",
    "#Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "#Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "#Display ct\n",
    "print(ct)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58178724",
   "metadata": {},
   "source": [
    "### Transforming features for better clusters\n",
    "#### Feature variances\n",
    "* Wine features have very different variances\n",
    "* Variance of a feature measures spread of its values\n",
    "* __In kmeans: feature variance = feature influence__\n",
    "* To give every feature a chance, the data needs to be transformed so that the feature have equal variance\n",
    "* This can be achieved with `StandardScaler`\n",
    "* `StandardScaler` transforms each feature to have mean 0 and variance 1 \n",
    "* Features are said to be \"standardized\"\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "StandardScaler = (copy=True, with_mean=True, with_std=True)\n",
    "samples_scaled = scaler.transform(samples)\n",
    "```\n",
    "* `StandardScaler` and `KMeans` have similar methods but __important difference:__\n",
    "    * `StandardScaler` transforms the data and so has a transform method: `fit()` / `transform()`\n",
    "    * `KMeans` in contrast assigns cluster labels to samples: `fit()` / `predict()`\n",
    "\n",
    "#### StandardScaler, then KMeans\n",
    "* This can be conveniently achieved combined the two steps using pipeline\n",
    "* Data then flows from one step into the next automatically\n",
    "#### Pipelines combine multiple steps \n",
    "* First steps are the same:\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "scaler = StandardScaler()\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(scaler, kmeans)\n",
    "pipeline.fit(samples)\n",
    "labels = pipeline.predict(samples)\n",
    "```\n",
    "* Feature standardization improves clustering\n",
    "#### sklearn preprocessing steps\n",
    "* `StandardScaler` is a __preprocessing step__\n",
    "* `MaxAbsScaler` and `Normalizer` are other examples of __preprocessing steps__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539fee5",
   "metadata": {},
   "source": [
    "```\n",
    "#Perform the necessary imports\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "#Create scaler: scaler\n",
    "scaler = StandardScaler()\n",
    "#Create KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "#Create pipeline: pipeline\n",
    "pipeline = make_pipeline(scaler, kmeans)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557db4f5",
   "metadata": {},
   "source": [
    "```\n",
    "#Import pandas\n",
    "import pandas as pd\n",
    "#Fit the pipeline to samples\n",
    "pipeline.fit(samples)\n",
    "#Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(samples)\n",
    "#Create a DataFrame with labels and species as columns: df\n",
    "df = pd.DataFrame({'labels':labels, 'species':species})\n",
    "#Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['species'])\n",
    "#Display ct\n",
    "print(ct)\n",
    "```\n",
    "\n",
    "```\n",
    "#Import Normalizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "#Create a normalizer: normalizer\n",
    "normalizer = Normalizer()\n",
    "#Create a KMeans model with 10 clusters: kmeans\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "#Make a pipeline chaining normalizer and kmeans: pipeline\n",
    "pipeline = make_pipeline(normalizer, kmeans)\n",
    "#Fit pipeline to the daily price movements\n",
    "pipeline.fit(movements)\n",
    "```\n",
    "\n",
    "```\n",
    "#Import pandas\n",
    "import pandas as pd\n",
    "#Predict the cluster labels: labels\n",
    "labels = pipeline.predict(movements)\n",
    "#Create a DataFrame aligning labels and companies: df\n",
    "df = pd.DataFrame({'labels': labels, 'companies': companies})\n",
    "#Display df sorted by cluster label\n",
    "print(df.sort_values('labels'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6138c",
   "metadata": {},
   "source": [
    "# Visualizing hierarchies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83ca0a",
   "metadata": {},
   "source": [
    "* Visualizations communicate insights, and are particularly effective with a non-technical audience.\n",
    "* Two unsupervised learning techniques for visualization: __t-SNE__ and __Hierarchical Clustering__\n",
    "* __t-SNE:__ Creates a 2D map of a dataset and conveys useful information about the proximity of the samples to one another. \n",
    "## Hierarchical Clustering\n",
    "* Clusters are contained within one another; like classification of animal kingdom or an ancestry tree\n",
    "* __Dendrogram:__ a tree-like structure \n",
    "* Hierarchical clustering can produce great visualizations with dendrograms\n",
    "* __Agglomerative Hierarchical Clustering:__ At each step, the two closest clusters are merged until eventually there is only one cluster left (unless a smaller threshold is determined)\n",
    "* There is also __Divisive Clustering__, which works the other way around.\n",
    "* Hierarchical clustering using __`SciPy`__:\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "merging = linkage(samples, method='complete')\n",
    "dendrodram(mergings, labels= country_names, leaf_rotation=90, leaf_font_size=6)\n",
    "plt.show\n",
    "```\n",
    "\n",
    "```\n",
    "#Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "#Calculate the linkage: mergings\n",
    "mergings = linkage(samples, method='complete')\n",
    "#Plot the dendrogram, using varieties as labels\n",
    "dendrogram(mergings,\n",
    "           labels=varieties,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=6,\n",
    ")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```\n",
    "#Import normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "#Normalize the movements: normalized_movements\n",
    "normalized_movements = normalize(movements)\n",
    "#Calculate the linkage: mergings\n",
    "mergings = linkage(normalized_movements, method='complete')\n",
    "#Plot the dendrogram\n",
    "dendrogram(mergings, labels=companies, leaf_rotation=90, leaf_font_size=6)\n",
    "plt.show()\n",
    "```\n",
    "### Cluster labels in hierarchical clustering\n",
    "* Not only a visualization tool!\n",
    "* Cluster labels at any intermediate stage can be recovered.\n",
    "* For use in cross-tabulations etc.\n",
    "* Intermediate clusters are defined by height\n",
    "* __Height on dendrogram:__ distance between merging clusters\n",
    "    * So the height that specifies an intermediate clustering on a dendrogram corresponds to a distance\n",
    "    * In this way we can define a threshold.\n",
    "* Complete linkage vs simple linkage vs averaged linkage\n",
    "\n",
    "#### Extracting cluster labels \n",
    "* Use the `fcluster()` function (with specifying the height)\n",
    "* Returns a numpy array of cluster labels\n",
    "\n",
    "```\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "mergings = linkage(samples, method='complete')\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "labels = fcluster(mergings, 15, criterion = 'distance')\n",
    "print(labels)\n",
    "```\n",
    "\n",
    "#### Aligning cluster labels with country names \n",
    "* Given a list of strings `country_names`\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "pairs = pd.DataFrame({'labels':labels, 'countries':country_names})\n",
    "print(pairs.sort_values('labels')\n",
    "```\n",
    "__NOTE: SciPy cluster labels start at 1__\n",
    "\n",
    "```\n",
    "#Perform the necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "#Calculate the linkage: mergings\n",
    "mergings = linkage(samples, method='single')\n",
    "#Plot the dendrogram\n",
    "dendrogram(mergings, labels= country_names, leaf_rotation=90, leaf_font_size= 6)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```\n",
    "#Perform the necessary imports\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "#Use fcluster to extract labels: labels\n",
    "labels = fcluster(mergings, 6, criterion='distance')\n",
    "#Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "#Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "#Display ct\n",
    "print(ct)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5e725",
   "metadata": {},
   "source": [
    "## t-SNE for 2-dimensional maps\n",
    "* __t-SNE:__ \"t-distributed stochastic neighbor embedding\"\n",
    "    * It maps samples from their higher dimensional space into a 2- or 3- dimensional space so they can be visualized. \n",
    "    * While some distortion is inevitable, t-SNE does a great job of approximately representing the distances between the samples.\n",
    "    * t-SNE is an invaluable visual aid for understanding a dataset.\n",
    "* __low inertia:__ tight clusters\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.maniford import TSNE\n",
    "model = TSNE(learning_rate=100)\n",
    "transformed = model.fit_transform(samples)\n",
    "xs = transformed[:,0]\n",
    "ys = transformed[:,1]\n",
    "plt.scatter(xs, ys, c=species)\n",
    "plt.show()\n",
    "```\n",
    "* __t-SNE only has `.fit_transform()` method\n",
    "* Simultaneously fits the model and transforms the data.\n",
    "* You __can't__ extend a t-SNE map to include more samples\n",
    "* You may need to try different learning rates for different datasets\n",
    "* If you choose the wrong choice for learning rate, it will be very clear, because all the samples will be bunched together in the scatterplot.\n",
    "* Try values between 50 and 200.\n",
    "* __The axes of a t-SNE plot do not have any interpretable meaning.__\n",
    "* __t-SNE features are different every time.__\n",
    "* Orientation may/will be different every time you run a t-SNE, but the position of the data will be the same relative to one another. \n",
    "\n",
    "```\n",
    "#Import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "#Create a TSNE instance: model\n",
    "model = TSNE(learning_rate=200)\n",
    "#Apply fit_transform to samples: tsne_features\n",
    "tsne_features = model.fit_transform(samples)\n",
    "#Select the 0th feature: xs\n",
    "xs = tsne_features[:,0]\n",
    "#Select the 1st feature: ys\n",
    "ys = tsne_features[:,1]\n",
    "#Scatter plot, coloring by variety_numbers\n",
    "plt.scatter(xs, ys, c=variety_numbers)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```\n",
    "#Import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "#Create a TSNE instance: model\n",
    "model = TSNE(learning_rate=50)\n",
    "#Apply fit_transform to normalized_movements: tsne_features\n",
    "tsne_features = model.fit_transform(normalized_movements)\n",
    "#Select the 0th feature: xs\n",
    "xs = tsne_features[:,0]\n",
    "#Select the 1th feature: ys\n",
    "ys = tsne_features[:,1]\n",
    "#Scatter plot\n",
    "plt.scatter(xs, ys, alpha = 0.5)\n",
    "#Annotate the points\n",
    "for x, y, company in zip(xs, ys, companies):\n",
    "    plt.annotate(company, (x, y), fontsize=5, alpha=0.75)\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1488489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14fe70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85440c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66609bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
