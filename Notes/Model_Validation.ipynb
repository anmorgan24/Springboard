{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0119a450",
   "metadata": {},
   "source": [
    "# Model Validation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db69d6b",
   "metadata": {},
   "source": [
    "Without proper validation, the results of running new data through a model might not be as accurate as expected. Model validation allows analysts to confidently answer the question, how good is your model? Goal: cover the basics of model validation, discuss various validation techniques, and begin to develop tools for creating validated and high performing models.\n",
    "\n",
    "* **Model Validation** consists of various steps and processes that ensure your model performs as expected on new data. The most common way to do this is to test your model's accuracy (or, insert evaluation metric of your choice) on data it has never seen before (called a **holdout set**). If your model's accuracy is similar for the data it was trained on and the holdout data. You can claim that your model is validated. The ultimate goal of model validation is to end up with the best performing model possible that achieves high accuracy on new data. \n",
    "\n",
    "#### Model validation consists of:\n",
    "    * Ensuring your model performs as expected on new data\n",
    "    * Testing model performance on holdout datasets\n",
    "    * Selecting the best model, parameters, and accuracy metrics\n",
    "    * Achieving the best accuracy for the data given\n",
    "    \n",
    "### Scikit-learn modeling review\n",
    "#### Basic modeling steps\n",
    "* 1. Create a model by specifying model type and its parameters\n",
    "* 2. Fit the model using the `.fit()` method\n",
    "* 3. To assess model accuracy, we generate predictions for data using the `.predict()` method. \n",
    "* 4. Look at accuracy metrics.\n",
    "\n",
    "* **The process of generating a model, fitting, predicting, and then reviewing model accuracy was introduced earlier in:**\n",
    "    * Intermediate Python\n",
    "    * Supervised Learning with scikit-learn\n",
    "\n",
    "```\n",
    "model = RandomForestRegressor(n_estimators=500, random_state=1111)\n",
    "model.fit(X= X_train, y= y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"{0:.2f}\".format(mae(y_true = y_test, y_pred= predictions)))\n",
    "```\n",
    "* **Model validation's main goal is to ensure that a predictive model will perform as expected on new data.**\n",
    "* Training data = seen data\n",
    "\n",
    "```\n",
    "model = RandomForestRegressor(n_estimators=500, random_state=1111)\n",
    "model.fit(X_train, y_train)\n",
    "train_predictions = model.predict(X_train)\n",
    "```\n",
    "\n",
    "* Testing data = unseen data\n",
    "\n",
    "```\n",
    "model = RandomForestRegressor(n_estimators = 500, random_state=1111)\n",
    "model.fit(X_train, y_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "```\n",
    "\n",
    "* If your training and testing errors are vastly different, it may be a sign that your model is overfitted\n",
    "* Use model validation to make sure you get the best testing error possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aead3bbe",
   "metadata": {},
   "source": [
    "### Regression models\n",
    "* More specifically: Random Forest Regression models using scikit-learn\n",
    "* Random forest algorithms have a lot of parameters, but here we focus on three:\n",
    "    * **`n_estimators`:** is the number of trees in the forest\n",
    "    * **`max_depth`:** the maximum depth of the trees (or how many times we can split the data). Also described as the maximum length from the beginning of a tree to the tree's end nodes \n",
    "    * **`random_state`:** random seed; allows us to create reproducible models\n",
    "* The most common way to set model parameters is to do so when initiating the model\n",
    "* However, they can also be set later, by assigning a new value to a model's attribute.\n",
    "    * This second method could be helpful when testing out different sets of parameters\n",
    "    \n",
    "```\n",
    "rfr = RandomForestRegressor(random_state=1111)\n",
    "rfr.n_estimators = 50\n",
    "rfr.max_depth = 10\n",
    "```\n",
    "\n",
    "#### Feature importance\n",
    "* After a model is created, we can assess how important different features (or columns) of the data were in the model by using the **`.feature_importances_`** attribute.\n",
    "\n",
    "* Use code below, so long as data is in pandas DataFrame\n",
    "\n",
    "```\n",
    "for i, item in enumerate(rfr.feature_importances_):\n",
    "    print(\"{0:s}: {1:.2f}\".format(X.columns[i], item))\n",
    "```\n",
    "\n",
    "* **The larger this number is, the more important that column was in the model.\n",
    "\n",
    "```\n",
    "# Set the number of trees\n",
    "rfr.n_estimators = 100\n",
    "\n",
    "# Add a maximum depth\n",
    "rfr.max_depth = 6\n",
    "\n",
    "# Set the random state\n",
    "rfr.random_state = 1111\n",
    "\n",
    "# Fit the model\n",
    "rfr.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068e01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aeda96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6bcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
