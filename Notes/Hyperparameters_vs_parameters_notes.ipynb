{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdfe83a",
   "metadata": {},
   "source": [
    "# Hyperparameters & parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262a77d",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937f0d7",
   "metadata": {},
   "source": [
    "* This subunit is all about hyperparameters and how to optimize them. Unlike standard parameters, which are derived when training occurs, hyperparameters should be set before the learning process. There are several standard methods you can use to set hyperparameters for a model. We'll also cover one out-of-the-box method. \n",
    "\n",
    "#### Parameters vs Hyperparameters\n",
    "* **Parameters** of your model are *W* and $\\beta$\n",
    "* **Hyperparameters:** alpha (learning rate), # of iterations of gradient descent you carry out, # of hidden layers *L*, # of hidden units $n^1$, $n^2$, $n^3$, etc... choice of activation function, momentum term, mini-batch size, various regularization parameters\n",
    "* **Hyperparameters** are \"paramaters\" that control the ultimate parameter values of *W* and $\\beta$. In other words, the hyperparameters determine the final values of the parameters.\n",
    "* Note: in some \"earlier\" versions of ML, alpha $\\alpha$ has been referred to as a parameter and is sometimes still referred to as a parameter.\n",
    "\n",
    "\n",
    "* ML and deep learning are very empirical processes. \n",
    "* $\\Rightarrow$ IDEA $\\Rightarrow$ CODE $\\Rightarrow$ EXPERIMENT $\\Rightarrow$ IDEA $\\Rightarrow$\n",
    "* empirical is (arguably) a fancy word for \"trial and error\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071ff93",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107cb7b",
   "metadata": {},
   "source": [
    "* In the realm of machine learning, hyperparameter tuning is a “meta” learning task.\n",
    "* Machine learning models are basically mathematical functions that represent the relationship between different aspects of data\n",
    "* “Training a model” involves using an optimization procedure to determine the best model parameter that “fits” the data.\n",
    "* There is another set of parameters known as hyperparameters, sometimes also knowns as “nuisance parameters.” These are values that must be specified outside of the training procedure.\n",
    "    * Ridge regression and lasso both add a regularization term to linear regression; the weight for the regularization term is called the regularization parameter\n",
    "    * Decision trees have hyperparameters such as the desired depth and number of leaves in the tree.\n",
    "    * Support vector machines (SVMs) require setting a misclassification penalty term.\n",
    "    * Kernelized SVMs require setting kernel parameters like the width for radial basis function (RBF) kernels. \n",
    "    * ... etc...\n",
    "* A regularization hyperparameter controls the capacity of the model, i.e., how flexible the model is, how many degrees of freedom it has in fitting the data.\n",
    "* Proper control of model capacity can prevent overfitting, which happens when the model is too flexible, and the training process adapts too much to the training data, thereby losing predictive accuracy on new test data. \n",
    "* Another type of hyperparameter comes from the training process itself. Training a machine learning model often involves optimizing a loss function (the training metric).\n",
    "*  A number of mathematical optimization techniques may be employed, some of them having parameters of their own.\n",
    "    * stochastic gradient descent optimization requires a learning rate or a learning schedule. \n",
    "    * Some optimization methods require a convergence threshold.\n",
    "    * Random forests and boosted decision trees require knowing the number of total trees (though this could also be classified as a type of regularization hyperparameter).\n",
    "* Since the training process doesn’t set the hyperparameters, there needs to be a meta process that tunes the hyperparameters. This is what we mean by hyperparameter tuning.\n",
    "* **Hyperparameter tuning is a meta-optimization task.** But, each trial of a particular hyperparameter setting involves training a model—an inner optimization process. **The outcome of hyperparameter tuning is the best hyperparameter setting, and the outcome of model training is the best model parameter setting.**\n",
    "* Tuning hyperparameters: For each proposed hyperparameter setting, the inner model training process comes up with a model for the dataset and outputs evaluation results on hold-out or cross-validation datasets. After evaluating a number of hyperparameter settings, the hyperparameter tuner outputs the setting that yields the best performing model. The last step is to train a new model on the entire dataset (training and validation) under the best hyperparameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a00629",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e62dd",
   "metadata": {},
   "source": [
    "* Conceptually, hyperparameter tuning is an optimization task, just like model training. However, these two tasks are quite different in practice. \n",
    "* When training a model, the quality of a proposed set of model parameters can be written as a mathematical formula (usually called the loss function). When tuning hyperparameters, however, the quality of those hyperparameters cannot be written down in a closed-form formula, because it depends on the outcome of a black box (the model training process).\n",
    "\n",
    "#### GridSearch CV\n",
    "* Grid search, true to its name, picks out a grid of hyperparameter values, evaluates every one of them, and returns the winner (for regularization parameters, it’s common to use exponential scale).\n",
    "* Some guesswork is necessary to specify the minimum and maximum values. \n",
    "* Sometimes people run a small grid, see if the optimum lies at either endpoint, and then expand the grid in that direction. This is called manual grid search.\n",
    "* Grid search is dead simple to set up and trivial to parallelize. It is the most expensive method in terms of total computation time. However, if run in parallel, it is fast in terms of wall clock time.\n",
    "\n",
    "#### Random Search\n",
    "* Random search is a slight variation on grid search. \n",
    "* Instead of searching over the entire grid, random search only evaluates a random sample of points on the grid.\n",
    "* This makes random search a lot cheaper than grid search.\n",
    "* Bergstra and Bengio demonstrated that, in surprisingly many instances, random search performs about as well as grid search. \n",
    "* All in all, trying 60 random points sampled from the grid seems to be good enough; if at least 5% of the points on the grid yield a close-to-optimal solution, then random search with 60 trials will find that region with high probability (95% probability)\n",
    "* The simple probabilistic explanation for this is that for any distribution over a sample space with a finite maximum, the maximum of 60 random observations lies within the top 5% of the true maximum, with 95% probability. \n",
    "* It’s trivially parallelizable, just like grid search, but it takes much fewer tries and performs almost as well most of the time.\n",
    "\n",
    "#### Smart Hyperparamater Tuning\n",
    "* Smarter tuning methods are available. Unlike the “dumb” alternatives of grid search and random search, smart hyperparameter tuning is much less parallelizable. \n",
    "* Instead of generating all the candidate points up front and evaluating the batch in parallel, smart tuning techniques pick a few hyperparameter settings, evaluate their quality, then decide where to sample next. This is an inherently iterative and sequential process. It is not very parallelizable. The goal is to make fewer evaluations overall and save on the overall computation time.\n",
    "* Three smart tuning methods proposed in recent years: derivative-free optimization, Bayesian optimization, and random forest smart tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03242f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeee5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2dc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca184b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
