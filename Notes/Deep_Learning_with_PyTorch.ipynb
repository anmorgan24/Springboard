{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e962141d",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning with PyTorch\n",
    "\n",
    "Neural networks have been at the forefront of Artificial Intelligence research during the last few years, and have provided solutions to many difficult problems like image classification, language translation or Alpha Go. PyTorch is one of the leading deep learning frameworks, being at the same time both powerful and easy to use. In this course you will use PyTorch to first learn about the basic concepts of neural networks, before building your first neural network to predict digits from MNIST dataset. You will then learn about convolutional neural networks, and use them to build much more powerful models which give more accurate results. You will evaluate the results and use different techniques to improve them. Following the course, you will be able to delve deeper into neural networks and start your career in this fascinating field.\n",
    "\n",
    "**Instructor:** Ismail Elezi, PhD researched at Ca' Foscari University of Venice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6fe32",
   "metadata": {},
   "source": [
    "## $\\star$ Chapter 1: Introduction to PyTorch\n",
    "In this first chapter, we introduce basic concepts of neural networks and deep learning using PyTorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712eda4a",
   "metadata": {},
   "source": [
    "* **Why PyTorch?**\n",
    "    * Simplicity\n",
    "    * \"PyThonic\"- easy to use\n",
    "    * Strong GPU support - models run fast\n",
    "    * Many algorithms are already implemented\n",
    "    * Automatic differentiation\n",
    "    * Strong OOP\n",
    "    * Natural choice for many companies like Facebook and SalesForce\n",
    "    * One of the most used deep learning libraries in academical research\n",
    "    * Similar to NumPy, making the switch pretty painless\n",
    "    \n",
    "* Calculating derivatives and gradients is a very important aspect of deep learning algorithms \n",
    "* Luckily, PyTorch is very good at doing it for us\n",
    "\n",
    "#### PyTorch compared to NumPy\n",
    "* PyTorch's equivalent to ndarrays is a `torch.tensor`\n",
    "* Image a tensor as an array with an arbitrary number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ef467fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3cee9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 5],\n",
       "        [1, 2, 9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 3, 5], [1, 2, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2470ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8223, 0.1763],\n",
       "        [0.8878, 0.3068]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cd8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba63d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8539, 0.2192, 0.4255, 0.3891, 0.9884],\n",
      "        [0.7929, 0.6227, 0.6128, 0.2260, 0.3861],\n",
      "        [0.2820, 0.8878, 0.0554, 0.6852, 0.8450]])\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10634240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0363b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70e3e749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8819, 1.2884, 1.5931],\n",
       "        [1.6487, 1.3359, 1.2814],\n",
       "        [1.5481, 1.1524, 1.1297]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d66fdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "756122ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2440, 0.0965, 0.2734, 0.2897, 0.5755],\n",
       "        [0.0186, 0.6216, 0.6122, 0.2168, 0.2859],\n",
       "        [0.0304, 0.1187, 0.0416, 0.4657, 0.7632]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61501d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21fa8488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9a295ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e37507",
   "metadata": {},
   "source": [
    "#### from NumPy to PyTorch\n",
    "* `d_torch = torch.from_numpy(c_numpy)`\n",
    "\n",
    "#### from PyTorch to NumPy\n",
    "* `c_torch.numpy()`\n",
    "\n",
    "<img src='data/basic_torch_functions.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080c2b6",
   "metadata": {},
   "source": [
    "#### Forward Propagation\n",
    "* Also known as \"foward pass\"\n",
    "* Intuitively, a **computational graph** is a network of nodes that represent numbers, scalars, or tensors and are connected via edges that represent functions or operations\n",
    "\n",
    "#### PyTorch Implementation \n",
    "\n",
    "<img src='data/graph1.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9edb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First initialize tensors a, b, c, and d\n",
    "a = torch.Tensor([2])\n",
    "b = torch.Tensor([-4])\n",
    "c = torch.Tensor([-2])\n",
    "d = torch.Tensor([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f640b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = a + b\n",
    "f = c * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fe21984",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = e * f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b31327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.]) tensor([-4.]) tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "print(e, f, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63e99d",
   "metadata": {},
   "source": [
    "* Neural networks (and most other classifiers) can be understood as **computational graphs**\n",
    "    * In fact, your code gets converted to a computational graph\n",
    "    * An additional benefit of computational graphs, is that they make the automatic computation of derivatives (or gradients) much easier.\n",
    "    \n",
    "#### Exercises: Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb80bfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(124.9853)\n"
     ]
    }
   ],
   "source": [
    "# Initialize tensors x, y and z\n",
    "x = torch.rand(1000, 1000)\n",
    "y = torch.rand(1000, 1000)\n",
    "z = torch.rand(1000, 1000)\n",
    "\n",
    "# Multiply x with y\n",
    "q = torch.matmul(x, y)\n",
    "\n",
    "# Multiply elementwise z with q\n",
    "f = z * q\n",
    "\n",
    "mean_f = torch.mean(f)\n",
    "print(mean_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e91a0",
   "metadata": {},
   "source": [
    "### Backpropagation by auto-differentiation\n",
    "* The main algorithm in neural networks: the **backpropagation algorithm**\n",
    "\n",
    "#### Derivatives\n",
    "* Derivatives are one of the central concepts in calculus\n",
    "* In layman's terms, the derivatives represent the rate of change in a function\n",
    "    * Where the function is **rapidly changing**, the absolute value of the **derviatives is high**.\n",
    "    * When the function **is not changing** the derivtives are **close to 0**.\n",
    "    * They could also be interpreted as describing the steepness of a function\n",
    "    \n",
    "<img src='data/derivatives.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e2ece6",
   "metadata": {},
   "source": [
    "* In this graph, points `A` and `C` have large derivatives, while point `B` has a very small derivative\n",
    "* Khan Academy Derivatives course comes highly recommended\n",
    "\n",
    "<img src='data/derivative_rules.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ebfc8",
   "metadata": {},
   "source": [
    "* The **Addition** or **Sum** rule says that for two functions, $f$ and $g$, the derivative of their sum is the sum of their individual derivatives\n",
    "* The **Multiplication** rule says that the derivative of their product is $f$ times derivative of $g$ times derivative of $f$\n",
    "* The derivative of a number times a function is the number\n",
    "    * For example, the derivative of $3x$ is $3$\n",
    "* The derivative of a number itself is always zero\n",
    "* The derivative of something with respect to itself is always 1 \n",
    "* **Chain rule** deals with the composition of functions\n",
    "* A closely related term with derivatives is the gradient\n",
    "* The **gradient** is a multi-variable generalization of the derivative\n",
    "    * Considering that neural networks have many variables, we will typically use the term gradient instead of derivative when working with NNs\n",
    "    \n",
    "#### Backpropagation in PyTorch\n",
    "* The derivatives are calculated in PyTorch using the reverse mode of auto-differentiation, so you will rarely need to write code to calculate derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9f1a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(-3., requires_grad=True)\n",
    "y = torch.tensor(5., requires_grad=True)\n",
    "z = torch.tensor(-2., requires_grad=True)\n",
    "\n",
    "q = x + y\n",
    "f = q * z\n",
    "\n",
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f314216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of z is : tensor(2.)\n",
      "Gradient of y is : tensor(-2.)\n",
      "Gradient of x is : tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient of z is : \" + str(z.grad))\n",
    "print(\"Gradient of y is : \" + str(y.grad))\n",
    "print(\"Gradient of x is : \" + str(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6d1a7",
   "metadata": {},
   "source": [
    "* **Note** that we need to set the `requires_grad` parameter to `True` in order to tell PyTorch that we need their derivatives\n",
    "* `f.backward()` tells PyTorch to compute the derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae09f1f",
   "metadata": {},
   "source": [
    "### Introduction to Neural Networks\n",
    "* The simplest form of modern neural networks is: fully-connected neural networks (Dense)\n",
    "\n",
    "#### Fully connected neural networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69b16def",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbb63e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.rand(10, 20)\n",
    "w2 = torch.rand(20, 20)\n",
    "w3 = torch.rand(20, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609051aa",
   "metadata": {},
   "source": [
    "* In order to get the values of the first hidden layer `h1`, we multiply the vector of features with the first matrix of weights `w1`\n",
    "* Look at the matrix of weights. The first dimension should always correspond to the preceding layer, and the second dimension to the following layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "242cfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = torch.matmul(input_layer, w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f69a54",
   "metadata": {},
   "source": [
    "* Similarly, we continue for the second hidden layer, `h2`, which is the product of the first hidden layer `h1` and the second matrix of weights `w2`.\n",
    "* Finally, we get the results of the `output_layer`, which has 4 classes, by multiplying the second hidden layer `h2` with the third matrix of weights `w3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74b183bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = torch.matmul(h1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "874b46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = torch.matmul(h2, w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6732d7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([199.4510, 194.9810, 236.2898, 185.9965])\n"
     ]
    }
   ],
   "source": [
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7738c55",
   "metadata": {},
   "source": [
    "### Building a neural network- PyTorch style\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.output = nn.Linear(20, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "input_layer = torch.rand(10)\n",
    "net = Net()\n",
    "result = net(input_layer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97385172",
   "metadata": {},
   "source": [
    "* In the `__init__` method, we define our parameters, the tensors of weights.\n",
    "* For fully connected layers, they are called `nn.Linear`\n",
    "    * The first parameter is the number of units of the current layer\n",
    "    * The second parameter is the number of units in the next layer\n",
    "    * In the forward method, we apply all those weights to our input\n",
    " \n",
    "#### Exercises: Your first neural network\n",
    "\n",
    "```\n",
    "# Initialize the weights of the neural network\n",
    "weight_1 = torch.rand(1, 1)\n",
    "weight_2 = torch.rand(1, 1)\n",
    "\n",
    "# Multiply input_layer with weight_1\n",
    "hidden_1 = torch.matmul(input_layer, weight_1)\n",
    "\n",
    "# Multiply hidden_1 with weight_2\n",
    "output_layer = torch.matmul(hidden_1, weight_2)\n",
    "print(output_layer)\n",
    "```\n",
    "***\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Instantiate all 2 linear layers  \n",
    "        self.fc1 = nn.Linear(784, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        # Use the instantiated layers and return x\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db866a20",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daf0a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9696, 0.7527])\n"
     ]
    }
   ],
   "source": [
    "input_layer = torch.tensor([2., 1.])\n",
    "weight_1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]])\n",
    "hidden_layer = torch.matmul(input_layer, weight_1)\n",
    "weight_2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]])\n",
    "output_layer = torch.matmul(hidden_layer, weight_2)\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1df6ed",
   "metadata": {},
   "source": [
    "#### Matrix multiplication is a linear transformation\n",
    "* Now, let's try to do something different\n",
    "* Let's first multiply the matrices with `torch.matmul` and then we'll multiply the input with the product of these matrices\n",
    "* When we print the results, we see something interesting: **the result of the output layer is exactly the same as before.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c66bfcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9696, 0.7527])\n",
      "tensor([[0.4208, 0.2372],\n",
      "        [0.1280, 0.2783]])\n"
     ]
    }
   ],
   "source": [
    "input_layer = torch.tensor([2., 1.])\n",
    "weight_1 = torch.tensor([[0.45, 0.32], [-0.12, 0.29]])\n",
    "weight_2 = torch.tensor([[0.48, -0.12], [0.64, 0.91]])\n",
    "weight = torch.matmul(weight_1, weight_2)\n",
    "output_layer = torch.matmul(input_layer, weight)\n",
    "print(output_layer)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8454d75d",
   "metadata": {},
   "source": [
    "* This means that we can achieve the exact result by using a single layer neural network, with this particular set of weights. \n",
    "* Linear algebra demonstrates that matrix multiplication is actually a linear transformation, meaning that we can simplify any neural network in a single layer neural network\n",
    "* But, this comes with an irritating consequence: our neural nets are not that powerful; using them *alone* only allows us to separate linearly separable datasets (for which there are a host of more intuitive ML algorithms).\n",
    "* To separate non-linearly-separable functions, we use **activation functions.**\n",
    "\n",
    "<img src='data/activation_functions.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618cc3e",
   "metadata": {},
   "source": [
    "* **Activation functions** are non-linear functions which are inserted in each layer of the neural network, making neural networks nonlinear and allowing them to deal with highly non-linear datasets, thus making them much more powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e288e047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 0.])\n",
      "tensor([[2.0000, 0.0000],\n",
      "        [1.2000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "\n",
    "tensor_1 = torch.tensor([2., -4.])\n",
    "print(relu(tensor_1))\n",
    "\n",
    "tensor_2 = torch.tensor([[2., -4.], [1.2, 0.]])\n",
    "print(relu(tensor_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd18696",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "* So far, all neural networks in this course have had random weights (and so they weren't particularly useful)\n",
    "* The recipe for training neural networks is the following:\n",
    "    * Initialize neural networks with random weights\n",
    "    * Do a forward pass\n",
    "    * Calculate loss function (1 number)\n",
    "    * Calculate the gradients using backpropagation\n",
    "    * Change the weights based on gradients\n",
    "* Loss (cost) function for **regression: least squared loss**\n",
    "* Loss (cost) function for **classification: softmax or (categorical) cross-entropy loss**\n",
    "* For more complicated problems (like object detection), more complicated losses\n",
    "* Loss functions should be **differentiable**; otherwise we won't be able to compute gradients\n",
    "* For this reason, instead of using accuracy (which is not differentiable), we need to use some proxy loss functions (in neural nets, a softmax function followed by a cross-entropy function performs really well).\n",
    "* **Softmax** is a function that turns numbers into probabilities\n",
    "\n",
    "<img src='data/softmax_cross_entropy2.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "### CE loss in PyTorch\n",
    "* `logits` = scores for each class\n",
    "* `ground_truth` = cat\n",
    "* `criterion` = loss function\n",
    "* Below we choose `nn.CrossEntropyLoss()` which combines **softmax** with **cross-entropy**\n",
    "* Note that we get the same result from the code below as we do in the illustration above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "686a2c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0404)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[3.2, 5.1, -1.7]])\n",
    "ground_truth = torch.tensor([0])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697b232",
   "metadata": {},
   "source": [
    "What is the cat class prediction had been much higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5660e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0061)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[10.2, 5.1, -1.7]])\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a47592",
   "metadata": {},
   "source": [
    "What is the cat class prediction had been much lower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71d6bbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.1011)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[-10, 5.1, -1.7]])\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580069c",
   "metadata": {},
   "source": [
    "The rule of thumb is that **the more accurate the network is, the smaller the loss (and vice versa).**\n",
    "\n",
    "#### Exercises: Calculating loss function in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e34da0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0117)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scores and ground truth\n",
    "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
    "ground_truth = torch.tensor([2])\n",
    "\n",
    "# Instantiate cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute and print the loss\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f521302",
   "metadata": {},
   "source": [
    "#### Exercises: Loss function of random scores\n",
    "If the neural network predicts random scores, what would be its loss function? Let's find it out in PyTorch. The neural network is going to have 1000 classes, each having a random score. For ground truth, it will have class 111. Calculate the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88ef9496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.3071)\n"
     ]
    }
   ],
   "source": [
    "# Import torch and torch.nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Initialize logits and ground truth\n",
    "logits = torch.rand(1,1000)\n",
    "ground_truth = torch.tensor([111])\n",
    "\n",
    "# Instantiate cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate and print the loss\n",
    "loss = criterion(logits, ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff544e22",
   "metadata": {},
   "source": [
    "### Preparing a dataset in PyTorch\n",
    "* In order to be able to use datasets in PyTorch, they need to be in some PyTorch friendly format that the framework will be able to understand\n",
    "* **`torchvision`:** a package which deals with datasets and pretrained neural nets\n",
    "* **Below we define a transformation of images to torch tensors, usings `transforms`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b013eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.4914, 0.48216, 0.44653),\n",
    "                                  (0.24703, 0.24349, 0.26159))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95810560",
   "metadata": {},
   "source": [
    "* We decide where the path to the dataset will be stored (using `root` parameter), in the case below in the `data` folder.\n",
    "* We also set the `download` flag to `True`, which tells PyTorch that if dataset is not in the specified folder, to download it and put it there.\n",
    "* Finally, we set `transform` to `transform`, essentially transforming images to torch tensors by applying the transformation we defined in the codeblock above.\n",
    "* We build trainloader and testloader, getting the data ready for PyTorch\n",
    "\n",
    "```\n",
    "# Get datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, \n",
    "                                        download=True, transform = transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train = False,\n",
    "                                       download=True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "                                         shuffle = True, num_workers=4)\n",
    "```    \n",
    "\n",
    "#### Inspecting the dataloader\n",
    "* It's possible to inspect the dataloader, for example, we can look at the **shape of the testing or training datasets**, the **minibatch size**, or the **type of the random sampler**\n",
    "\n",
    "```\n",
    "print(testloader.dataset.test_data.shape, trainloader.dataset.train_data.shape)\n",
    "\n",
    "print(testloader.batch_size)\n",
    "\n",
    "print(trainloader.sampler)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf979d5d",
   "metadata": {},
   "source": [
    "### Training neural networks\n",
    "* Here we will go more in depth on how to train neural networks in PyTorch\n",
    "    * 1) **Prepare the dataloaders** for the dataset we want the neural network to train on\n",
    "    * 2) **Build a neural network**\n",
    "            * By default, all parameters of a neural network are initialized with random numbers\n",
    "            * There are other strategies for initialization however\n",
    "* Loop over:\n",
    "    * 3) **Do a forward pass** (using a minibatch)\n",
    "    * 4) **Calculate the loss function** (1 number which tries to measure how good the neural network is in the training set)\n",
    "    * 5) **Calculate the gradients** using backpropagation\n",
    "    * 6) **Change the weights** based on gradients; SGD= **`weight -= weight_gradient * learning_rate`**\n",
    "    \n",
    "#### Neural Network: Recap\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(32 * 32 * 3, 500)\n",
    "    self.fc2 = nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "```\n",
    "* Note that CIFAR10 has images of shape (32, 32, 3) so as input layer we have 32 * 32 * 3 units\n",
    "* We decide to have 500 units in the hidden layer, a decision made by us (hyperparameter)\n",
    "* With the dataset having 10 classes, we put 10ths 0 units in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be16ff6",
   "metadata": {},
   "source": [
    "### Training the Neural Network \n",
    "\n",
    "```\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in range(10): # loop over the dataset multiple times\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "    \n",
    "    # Get the inputs\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 32 * 32 * 3)\n",
    "    \n",
    "    # Zero the parameter gradients \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "* The line `inputs = inputs.view(-1, 32 * 32 * 3)` simply puts all the entries of the images into two vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e79ba3b",
   "metadata": {},
   "source": [
    "#### Using the net to get predictions\n",
    "\n",
    "```\n",
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 32*32*3)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuracy of network is: %d %%' % (100 * correct / total))\n",
    "```\n",
    "* **Note** that we first set the net in test (evaluation) mode using **`net.eval()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678882f8",
   "metadata": {},
   "source": [
    "### Convolution operator\n",
    "* 1) Units should be onnected with only a few untis from the previous layer\n",
    "* 2) Units share weights\n",
    "\n",
    "* The size of a convolutional filter **must** be smaller than the image\n",
    "* A convolutional layer is a layer that contains multiple activation maps.\n",
    "\n",
    "<img src='data/conv1.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa445f3",
   "metadata": {},
   "source": [
    "#### Using the `torch.nn` package\n",
    "\n",
    "```\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "conv_filter = torch.nn.Conv2d(in_channels=3,\n",
    "                              out_channels=1,\n",
    "                              kernel_size= 5,\n",
    "                              stride=1,\n",
    "                              padding=0)\n",
    "output_feature = conv_filter(image)\n",
    "\n",
    "print(output_feature.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4458af7",
   "metadata": {},
   "source": [
    "#### Using the torch functional package\n",
    "\n",
    "```\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "filter = torch.rand(1, 3, 5, 5)\n",
    "out_feat_F = F.conv2d(image, filter, stride = 1, padding = 0)\n",
    "\n",
    "print(out_feat_F.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713af141",
   "metadata": {},
   "source": [
    "#### Exercises: Convolution operator - OOP way\n",
    "\n",
    "```\n",
    "# Create 10 random images of shape (1, 28, 28)\n",
    "images = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Build 6 conv. filters\n",
    "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Convolve the image with the filters \n",
    "output_feature = conv_filters(images)\n",
    "print(output_feature.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96e8a2",
   "metadata": {},
   "source": [
    "#### Exercises: Convolution operator - Functional way\n",
    "\n",
    "```\n",
    "# Create 10 random images\n",
    "image = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Create 6 filters\n",
    "filters = torch.rand(6, 1, 3, 3)\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
    "print(output_feature.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aad4ac",
   "metadata": {},
   "source": [
    "### Pooling operators\n",
    "* The convolutional operator is the main building block in CNNs\n",
    "* Another very important layer in CNNs is the pooling operator, which can come in in two different ways:\n",
    "    * While convolutions are used to extract features from the image, **pooling is the way of feature selection**, choosing the most dominant features from the image, or combining different features\n",
    "    * Additionally, pooling lowers the resolution of the images, **making the computations more efficient.**\n",
    "* **Pooling** is simply lowering the spatial dimension\n",
    "\n",
    "<img src='data/pooling1.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "* The two most important pooling operators are max-pooling and average-pooling\n",
    "#### Max-Pooling\n",
    "* Max pooling takes the maximum number in a given region of a given region, as show below\n",
    "* Note that typically for pooling, we consider filters with size 2x2 and strides of size 2\n",
    "* By considering only the largest values in patches of the image, we make learning invariant to small shifting/translation.\n",
    "\n",
    "<img src='data/maxpooling1.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e4403",
   "metadata": {},
   "source": [
    "#### Average-Pooling\n",
    "* Typically used in later stages of deep networks\n",
    "\n",
    "<img src='data/avgpooling1.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f29aa",
   "metadata": {},
   "source": [
    "### Max-Pooling in PyTorch: OOP\n",
    "* Multiple brackets are need because the image needs to have 4 dimensions (for minibatch size, depth, height, and width)\n",
    "\n",
    "```\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], \n",
    "                     [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "max_pooling = torch.nn.MaxPool2d(2)   \n",
    "output_feature = max_pooling(im)\n",
    "print(output_feature)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcf5df",
   "metadata": {},
   "source": [
    "### Max-Pooling in PyTorch: Functional\n",
    "\n",
    "```\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9],\n",
    "                     [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "output_feature_F = F.max_pool2d(im, 2)\n",
    "print(output_feature_F)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014cecf",
   "metadata": {},
   "source": [
    "* **In order to apply Average-Pooling we do exactly the same thing, only replace `MaxPool2d()` with `AvgPool2d()`.**\n",
    "\n",
    "#### Exercises: Max-pooling operator - Both ways\n",
    "\n",
    "```\n",
    "# Build a pooling operator with size `2`.\n",
    "max_pooling = torch.nn.MaxPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = max_pooling(im)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.max_pool2d(im, 2)\n",
    "\n",
    "# print the results of both cases\n",
    "print(output_feature)\n",
    "print(output_feature_F)\n",
    "```\n",
    "\n",
    "#### Exercises: Average-Pooling operator- Both ways\n",
    "\n",
    "```\n",
    "# Build a pooling operator with size `2`.\n",
    "avg_pooling = torch.nn.AvgPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = avg_pooling(im)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.avg_pool2d(im, 2)\n",
    "\n",
    "# print the results of both cases\n",
    "print(output_feature)\n",
    "print(output_feature_F)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfdf34b",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks \n",
    "* While CNNs have existed for decades, their resurgence happened in 2012, when Alex Krizhevsky, Ily Sutskever, and Geoffrey Hinton published the so-called **AlexNet** paper and smashed every record in image classification.\n",
    "* Until that time, people were aware of the existence on CNNs, but they didn't take them seriously\n",
    "\n",
    "<img src='data/alexnet.png' width=\"700\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "* **Almost everything in computer vision is empowered by CNNs.** (If not, they at least play a large part in it)\n",
    "* Coding AlexNet in PyTorch is surprisingly easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c4dd422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 11, stride = 4, padding = 2)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size = 5, padding = 2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size = 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size = 3, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size = 3, padding = 1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9930a4",
   "metadata": {},
   "source": [
    "**Now all that remains is implementing the forward method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6b65d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.relu(self.conv1(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.relu(self.conv2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.relu(self.conv3(x))\n",
    "    x = self.relu(self.conv4(x))\n",
    "    x = self.relu(self.conv5(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6e20254",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f8f1e",
   "metadata": {},
   "source": [
    "**Of course, in order for AlexNet to make a correct prediction, it needs to be trained first.**\n",
    "\n",
    "Building the net is simply a matter of creatinf an object from this class.\n",
    "\n",
    "### Training CNNs\n",
    "* The number of channels for convolutional filters is arbitrary\n",
    "* It is very common to progressively increase the number of channels in the convolutional layers of a CNN\n",
    "#### Instantiate model, define loss and opt\n",
    "\n",
    "```\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "```\n",
    "\n",
    "#### Training\n",
    "\n",
    "```\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print('Finished Training')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc64a86",
   "metadata": {},
   "source": [
    "#### Evaluating the results\n",
    "\n",
    "```\n",
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('The testing set accuract of the network is: %d %%' % (100 * correct / total))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f0aa1",
   "metadata": {},
   "source": [
    "# $\\star$ Chapter 4: Using Convolutional Neural Networks\n",
    "In this last chapter, we learn how to make neural networks work well in practice, using concepts like regularization, batch-normalization and transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228187c",
   "metadata": {},
   "source": [
    "### The sequential module\n",
    "* Here we will examine some more advanced techniques\n",
    "* While the effect of these techniques is small in simple neural networks, perhaps making it hard to appreciate them, they are a must when working with big neural networks, and knowing them will make a *big* difference.\n",
    "\n",
    "<img src='data/alexnet_seq.png' width=\"700\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "<img src='data/seq_forward.png' width=\"700\" height=\"350\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af62fe",
   "metadata": {},
   "source": [
    "* The **sequential module** is very useful for feedforward networks (where the flow goes in one direction)\n",
    "* By using this module, you can divide your nework into part which logically make sense\n",
    "* You can also reuse the modules to create similar blocks in the neural network\n",
    "* As you can see above, we define all the convolutions, poolings, fully-connected layers, etc, (same as before), but now the order of operators also matters in the declaration.\n",
    "* Additionally, we **encapsulate them with an `nn.Sequential()`**\n",
    "* In the case above we are using one sequential module for the feature extraction part (convolutions and poolings), and one for the classification part (fully connected layers)\n",
    "* This is a very optimized OOP way of doing things and allows you to change parts of the network independently from each other. \n",
    "* By using the sequential module, instead of applying each operation, we actually need to apply each sequential module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5f45fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5b59d",
   "metadata": {},
   "source": [
    "### The problem of overfitting\n",
    "* Arguably the biggest problem in ML is overfitting:\n",
    "\n",
    "<img src='data/overfitting1.png' width=\"400\" height=\"200\" align=\"center\"/>\n",
    "\n",
    "* We detect overfitting by plotting the accuracy of your algorithm in both the training and testing set.\n",
    "* If there is a large gap in accuracy between training and testing is large, we have a case of **overfitting**, also called **high variance**\n",
    "\n",
    "<img src='data/overfitting2.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309f873",
   "metadata": {},
   "source": [
    "#### PyTorch validation sets\n",
    "\n",
    "<img src='data/pytorch_val.png' width=\"700\" height=\"350\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a6490",
   "metadata": {},
   "source": [
    "```\n",
    "# Shuffle the indices\n",
    "indices = np.arange(60000)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Build the train loader\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('mnist', download=True, train=True,\n",
    "                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                     batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
    "\n",
    "# Build the validation loader\n",
    "val_loader = torch.utils.data.DataLoader(datasets.MNIST('mnist', download=True, train=True,\n",
    "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                   batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[55000:]))\n",
    "```\n",
    "\n",
    "### Regularization techniques\n",
    "\n",
    "#### L2 Regularization\n",
    "* **`optimizer = optim.Adam(net.parameters(), lr=3e-4, weight_decay=0.0001)`**\n",
    "* (All you need to do is add the `weight_decay` argument\n",
    "\n",
    "#### Dropout\n",
    "* Typically dropout is used in fully-connected layers, while it is rarely used in convolutional layers\n",
    "\n",
    "<img src='data/alexnet_dropout.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecee0b8",
   "metadata": {},
   "source": [
    "#### Batch normalization \n",
    "* Very important technique used nowadays in practically every neural network \n",
    "* In layman's terms, it computes the mean and the variance of the minibatch for each feature, and then it normalizes the features based on those stats\n",
    "* Nowadays its \"unthinkable\" to train large neural networks without batch normalization (and is highly recommended for small batches as well)\n",
    "* **`self.bn = nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.9)`**\n",
    "\n",
    "#### Early-stopping\n",
    "* Simply checks the accuracy of the network in the validation set at the end of each epoch and if, after $n$ epochs, the performance of the net hasn't increased (or if it's decreased), then training is terminated\n",
    "\n",
    "<img src='data/early_stopping.png' width=\"400\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f1481",
   "metadata": {},
   "source": [
    "**Some of the techniques mentioned above (like dropout and batch-norm) behave differently when the net is getting trained and when the net is getting evaluated.**\n",
    "* We need to manually tell PyTorch if we are training or evaluating the net with:\n",
    "    * `model.train()`\n",
    "    * `model.eval()`\n",
    "* **It is very important to set te net in the correct mode, otherwise the training and evaluation will be broken.**\n",
    "\n",
    "```\n",
    "# Instantiate the network\n",
    "model = Net()\n",
    "\n",
    "# Instantiate the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate the Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)\n",
    "```\n",
    "***\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Define all the parameters of the net\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(200, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(500, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "    \t# Do the forward pass\n",
    "        return self.classifier(x)\n",
    "```\n",
    "***\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Implement the sequential module for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(10),\n",
    "            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(20))\n",
    "        \n",
    "        # Implement the fully connected layer for classification\n",
    "        self.fc = nn.Linear(in_features=20 * 7 * 7, out_features=10)\n",
    "```\n",
    "\n",
    "### Transfer learning\n",
    "* An interesting discovery in CNN research was that the deeper you progress in the network, the more abstract the features become.\n",
    "* A nice consequence of this is that the low-level features are very general and to a large degree dataset independent\n",
    "\n",
    "<img src='data/transfer_learning.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* So far we have trained all nets from scratch, initializing them with random weights.\n",
    "* However, in practice, this isn't usually how things are done.\n",
    "* **Instead of training the net from scratch, we download a net trained on another dataset (typically a big dataset like ImageNet containing 1-2 million images) and then we retrain the net in our dataset.**\n",
    "* **This allows us not only to achieve significantly better results in less training time, but also to train networks on very small datasets (containing only hundreds of images).**\n",
    "* **With this technique, you can train large neural networks on very small datasets.**\n",
    "\n",
    "<img src='data/transfer_learning2.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* In the literature, this \"retraining\" is typically called **finetuning**, but the essence is the same \n",
    "\n",
    "#### Finetuning\n",
    "* There are two ways of finetuning neural networks:\n",
    "    * **Freeze most of the layers**: (not updated them during propagation) and finetuning only the last few layers (or only the very last one\n",
    "    * **Finetune everything**\n",
    "* Typically if your dataset is extremely small, it is a good idea to freeze most of the layers, in order to avoid overfitting\n",
    "\n",
    "#### Finetuning in PyTorch\n",
    "* Let's say we have trained a net on CIFAR-10, which we have saved as `cifar10_net.pth`\n",
    "* **Torchvision is a PyTorch library with many pretrained networks, ready to be used for your dataset.**\n",
    "\n",
    "```\n",
    "# Create a new model\n",
    "model = Net()\n",
    "\n",
    "# Change the number of out channels\n",
    "model.fc = nn.Linear(7 * 7 * 512, 26)\n",
    "\n",
    "# Train and evaluate the model\n",
    "model.train()\n",
    "train_net(model, optimizer, criterion)\n",
    "print(\"Accuracy of the net is: \" + str(model.eval()))\n",
    "\n",
    "# Create a model using\n",
    "model = Net()\n",
    "\n",
    "# Load the parameters from the old model\n",
    "model.load_state_dict(torch.load('my_net.pth'))\n",
    "\n",
    "# Change the number of out channels\n",
    "model.fc = nn.Linear(7 * 7 * 512, 26)\n",
    "\n",
    "# Train and evaluate the model\n",
    "model.train()\n",
    "train_net(model, optimizer, criterion)\n",
    "print(\"Accuracy of the net is: \" + str(model.eval()))\n",
    "\n",
    "# Import the module\n",
    "import torchvision\n",
    "\n",
    "# Download resnet18\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all the layers bar the last one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Change the number of output units\n",
    "model.fc = nn.Linear(512, 7)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fd96d",
   "metadata": {},
   "source": [
    "<img src='data/finetuning.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/freezing.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "<img src='data/torchvision_lib.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
